<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="ch-summarizing-data" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Summarizing data</title>

  <introduction>
    <p>
      This chapter focuses on the mechanics and construction of summary statistics and graphs.
      We use statistical software for generating the summaries and graphs presented in this chapter and book.
      However, since this might be your first exposure to these concepts, we take our time in this chapter to detail
      how to create them.
      Mastery of the content presented in this chapter will be crucial for understanding the methods and
      techniques introduced in rest of the book.
    </p>
  </introduction>

  <!-- Section 2.1: Examining numerical data -->
  <section xml:id="sec-numerical-data">
    <title>Examining numerical data</title>

    <introduction>
      <p>
        In this section we will explore techniques for summarizing numerical variables.
        For example, consider the <c>loan_amount</c> variable from the <c>loan50</c> data set,
        which represents the loan size for all 50 loans in the data set.
        This variable is numerical since we can sensibly discuss the numerical difference of the size of two loans.
        On the other hand, area codes and zip codes are not numerical, but rather they are categorical variables.
      </p>

      <p>
        Throughout this section and the next, we will apply these methods using the <c>loan50</c> and <c>county</c>
        data sets, which were introduced in <xref ref="sec-data-basics"/>.
        If you'd like to review the variables from either data set, see the relevant data description figures.
      </p>
    </introduction>

    <!-- Subsection 2.1.1: Scatterplots for paired data -->
    <subsection xml:id="subsec-scatterplots">
      <title>Scatterplots for paired data</title>

      <p>
        A <term>scatterplot</term> provides a case-by-case view of data for two numerical variables.
        In a previous figure, a scatterplot was used to examine the homeownership rate against the fraction
        of housing units that were part of multi-unit properties (e.g. apartments) in the <c>county</c> data set.
        Another scatterplot is shown in <xref ref="fig-loan50-amt-vs-income"/>, comparing the total income of
        a borrower (<c>total_income</c>) and the amount they borrowed (<c>loan_amount</c>) for the <c>loan50</c> data set.
        In any scatterplot, each point represents a single case.
        Since there are 50 cases in <c>loan50</c>, there are 50 points in <xref ref="fig-loan50-amt-vs-income"/>.
      </p>

      <figure xml:id="fig-loan50-amt-vs-income">
        <caption>A scatterplot of <c>total_income</c> versus <c>loan_amount</c> for the <c>loan50</c> data set</caption>
        <image source="ch_summarizing_data/figures/loan50_amt_vs_interest/loan50_amt_vs_interest.png" width="80%">
          <description>
            A scatterplot is shown with "Total Income" along the horizontal axis (range from $0 to $325,000) and
            "Loan Amount" along the vertical axis (range from $0 to $40,000). The points lie in a range from $2,000
            to $33,000 in loan amount when total income is smaller than $150,000 (representing most of the points).
            The range of loan amounts is higher when total income is greater than $175,000, with the range of
            observations being about $15,000 to $40,000.
          </description>
        </image>
      </figure>

      <p>
        Looking at <xref ref="fig-loan50-amt-vs-income"/>, we see that there are many borrowers with an income
        below $100,000 on the left side of the graph, while there are a handful of borrowers with income above $250,000.
      </p>

      <example xml:id="ex-nonlinear-relationship">
        <title>Nonlinear relationships in scatterplots</title>
        <statement>
          <p>
            <xref ref="fig-median-income-poverty"/> shows a plot of median household income against the poverty
            rate for 3,142 counties. What can be said about the relationship between these variables?
          </p>
        </statement>
        <solution>
          <p>
            The relationship is evidently <term>nonlinear</term>, as highlighted by the dashed line.
            This is different from previous scatterplots we've seen, which show relationships that do not show
            much, if any, curvature in the trend.
          </p>
        </solution>
      </example>

      <figure xml:id="fig-median-income-poverty">
        <caption>A scatterplot of the median household income against the poverty rate for the <c>county</c> data set</caption>
        <image source="ch_summarizing_data/figures/medianHHIncomePoverty/medianHHIncomePoverty.png" width="80%">
          <description>
            A scatterplot of a few thousand points is shown with "Poverty Rate" along the horizontal axis
            (range from 0% to 55%) and "Median Household Income" along the vertical axis (range from $0 to $130,000).
            A curved trend line is overlaid on the points starting higher on the left and decreasing as it moves right,
            but it starts flattening the further right it goes. Below 10% poverty rate, points range from about $40,000
            to $130,000. Between 10% to 20%, the range is lower at about $25,000 to close to $100,000. For 20% to 30%,
            the points range from about $22,000 to just over $60,000. For 30% to 50%, the trend is mostly flat with
            values ranging from about $20,000 to $50,000.
          </description>
        </image>
      </figure>

      <exercise xml:id="ex-scatterplot-usefulness">
        <title>Value of scatterplots</title>
        <statement>
          <p>
            What do scatterplots reveal about the data, and how are they useful?
          </p>
        </statement>
        <solution>
          <p>
            Answers may vary. Scatterplots are helpful in quickly spotting associations relating variables,
            whether those associations come in the form of simple trends or whether those relationships are more complex.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="ex-horseshoe-association">
        <title>Horseshoe-shaped associations</title>
        <statement>
          <p>
            Describe two variables that would have a horseshoe-shaped association in a scatterplot
            (<m>\cap</m> or <m>\frown</m>).
          </p>
        </statement>
        <solution>
          <p>
            Consider the case where your vertical axis represents something "good" and your horizontal axis
            represents something that is only good in moderation. Health and water consumption fit this description:
            we require some water to survive, but consume too much and it becomes toxic and can kill a person.
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- Subsection 2.1.2: Dot plots and the mean -->
    <subsection xml:id="subsec-dot-plots-mean">
      <title>Dot plots and the mean</title>

      <p>
        Sometimes two variables are one too many: only one variable may be of interest.
        In these cases, a dot plot provides the most basic of displays.
        A <term>dot plot</term> is a one-variable scatterplot; an example using the interest rate of 50 loans
        is shown in <xref ref="fig-loan-int-rate-dot-plot"/>.
        A stacked version of this dot plot is shown in <xref ref="fig-loan-int-rate-dot-plot-stacked"/>.
      </p>

      <figure xml:id="fig-loan-int-rate-dot-plot">
        <caption>A dot plot of <c>interest_rate</c> for the <c>loan50</c> data set</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_dot_plot/loan_int_rate_dot_plot.png" width="76%">
          <description>
            A dot plot is shown for the variable "Interest Rate". There is a horizontal axis ranging from about 5%
            to a bit over 25%, and then several points are shown horizontally above the axis, scattered over the range.
            There is a higher density of points between 5% to 11%, with a moderate density of points from 12% to about 20%,
            and then a few more observations at about 22%, 25%, and 26%. A red triangle is also shown at approximately 12%.
          </description>
        </image>
      </figure>

      <figure xml:id="fig-loan-int-rate-dot-plot-stacked">
        <caption>A stacked dot plot of <c>interest_rate</c> for the <c>loan50</c> data set</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_dot_plot/loan_int_rate_dot_plot_stacked.png" width="76%">
          <description>
            A stacked dot plot is shown for the variable "Interest Rate". There is a horizontal axis ranging from about 5%
            to a bit over 25%, and then several stacks of points are shown at values 5%, 6%, 7%, and so on. There are 3 points
            stacked at 5%, 3 points stacked at 6%, 5 at 7%, 4 at 8%, 5 at 9%, 8 at 10%, 5 at 11%, 1 at 11%, 3 at 12%, then
            1 each at 14%, 15%, and 16%, 3 at 17%, 2 at 18%, and then 1 each at 19%, 20%, 21%, 25%, and 26%. A red triangle
            is also shown at approximately 12%. The rates have been rounded to the nearest percent in this plot.
          </description>
        </image>
      </figure>

      <p>
        The <term>mean</term>, often called the <term>average</term>, is a common way to measure the center of a
        <term>distribution</term> of data. To compute the mean interest rate, we add up all the interest rates and
        divide by the number of observations:
        <md>
          <mrow>\bar{x} = \frac{10.90\% + 9.92\% + 26.30\% + \cdots + 6.08\%}{50} = 11.57\%</mrow>
        </md>
        The sample mean is often labeled <m>\bar{x}</m>. The letter <m>x</m> is being used as a generic placeholder
        for the variable of interest, <c>interest_rate</c>, and the bar over the <m>x</m> communicates we're looking
        at the average interest rate, which for these 50 loans was 11.57%. It is useful to think of the mean as the
        balancing point of the distribution, and it's shown as a triangle in <xref ref="fig-loan-int-rate-dot-plot"/>
        and <xref ref="fig-loan-int-rate-dot-plot-stacked"/>.
      </p>

      <assemblage xml:id="def-mean">
        <title>Mean</title>
        <p>
          The sample mean can be computed as the sum of the observed values divided by the number of observations:
          <md>
            <mrow>\bar{x} = \frac{x_1 + x_2 + \cdots + x_n}{n}</mrow>
          </md>
          where <m>x_1</m>, <m>x_2</m>, <m>\dots</m>, <m>x_n</m> represent the <m>n</m> observed values.
        </p>
      </assemblage>

      <exercise xml:id="ex-mean-notation">
        <title>Understanding mean notation</title>
        <statement>
          <p>
            Examine the equation for the mean. What does <m>x_1</m> correspond to? And <m>x_2</m>?
            Can you infer a general meaning to what <m>x_i</m> might represent?
          </p>
        </statement>
        <solution>
          <p>
            <m>x_1</m> corresponds to the interest rate for the first loan in the sample (10.90%),
            <m>x_2</m> to the second loan's interest rate (9.92%), and <m>x_i</m> corresponds to the
            interest rate for the <m>i^{th}</m> loan in the data set. For example, if <m>i = 4</m>,
            then we're examining <m>x_4</m>, which refers to the fourth observation in the data set.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="ex-sample-size-n">
        <title>Sample size</title>
        <statement>
          <p>
            What was <m>n</m> in this sample of loans?
          </p>
        </statement>
        <solution>
          <p>
            The sample size was <m>n = 50</m>.
          </p>
        </solution>
      </exercise>

      <p>
        The <c>loan50</c> data set represents a sample from a larger population of loans made through Lending Club.
        We could compute a mean for this population in the same way as the sample mean.
        However, the population mean has a special label: <m>\mu</m>.
        The symbol <m>\mu</m> is the Greek letter <em>mu</em> and represents the average of all observations in the population.
        Sometimes a subscript, such as <m>_x</m>, is used to represent which variable the population mean refers to,
        e.g. <m>\mu_x</m>. Often times it is too expensive to measure the population mean precisely, so we often
        estimate <m>\mu</m> using the sample mean, <m>\bar{x}</m>.
      </p>

      <example xml:id="ex-estimating-population-mean">
        <title>Estimating a population mean</title>
        <statement>
          <p>
            The average interest rate across all loans in the population can be estimated using the sample data.
            Based on the sample of 50 loans, what would be a reasonable estimate of <m>\mu_x</m>, the mean interest
            rate for all loans in the full data set?
          </p>
        </statement>
        <solution>
          <p>
            The sample mean, 11.57%, provides a rough estimate of <m>\mu_x</m>. While it's not perfect,
            this is our single best guess of the average interest rate of all the loans in the population under study.
            In later chapters, we will develop tools to characterize the accuracy of <term>point estimates</term>
            like the sample mean. As you might have guessed, point estimates based on larger samples tend to be
            more accurate than those based on smaller samples.
          </p>
        </solution>
      </example>

      <example xml:id="ex-mean-for-comparison">
        <title>Using the mean for comparisons</title>
        <statement>
          <p>
            The mean is useful because it allows us to rescale or standardize a metric into something more easily
            interpretable and comparable. Provide 2 examples where the mean is useful for making comparisons.
          </p>
        </statement>
        <solution>
          <p>
            <ol>
              <li>
                <p>
                  We would like to understand if a new drug is more effective at treating asthma attacks than
                  the standard drug. A trial of 1500 adults is set up, where 500 receive the new drug, and 1000
                  receive a standard drug in the control group. The results show 200 asthma attacks in the new
                  drug group and 300 in the standard drug group. Comparing the raw counts of 200 to 300 asthma
                  attacks would make it appear that the new drug is better, but this is an artifact of the
                  imbalanced group sizes. Instead, we should look at the average number of asthma attacks per
                  patient in each group: New drug: <m>200 / 500 = 0.4</m>, Standard drug: <m>300 / 1000 = 0.3</m>.
                  The standard drug has a lower average number of asthma attacks per patient than the average in
                  the treatment group.
                </p>
              </li>
              <li>
                <p>
                  Emilio opened a food truck last year where he sells burritos, and his business has stabilized
                  over the last 3 months. Over that 3 month period, he has made $11,000 while working 625 hours.
                  Emilio's average hourly earnings provides a useful statistic for evaluating whether his venture is,
                  at least from a financial perspective, worth it: <m>\$11000 / 625 \text{ hours} = \$17.60 \text{ per hour}</m>.
                  By knowing his average hourly wage, Emilio now has put his earnings into a standard unit that is
                  easier to compare with many other jobs that he might consider.
                </p>
              </li>
            </ol>
          </p>
        </solution>
      </example>

      <example xml:id="ex-weighted-mean">
        <title>Weighted means</title>
        <statement>
          <p>
            Suppose we want to compute the average income per person in the US. To do so, we might first think
            to take the mean of the per capita incomes across the 3,142 counties in the <c>county</c> data set.
            What would be a better approach?
          </p>
        </statement>
        <solution>
          <p>
            The <c>county</c> data set is special in that each county actually represents many individual people.
            If we were to simply average across the income variable, we would be treating counties with 5,000 and
            5,000,000 residents equally in the calculations. Instead, we should compute the total income for each
            county, add up all the counties' totals, and then divide by the number of people in all the counties.
            If we completed these steps with the <c>county</c> data, we would find that the per capita income for
            the US is $30,861. Had we computed the simple mean of per capita income across counties, the result
            would have been just $26,093! This example used what is called a <term>weighted mean</term>.
            For more information on this topic, check out online supplements regarding weighted means.
          </p>
        </solution>
      </example>
    </subsection>

    <!-- Subsection 2.1.3: Histograms and shape -->
    <subsection xml:id="subsec-histograms-shape">
      <title>Histograms and shape</title>

      <p>
        Dot plots show the exact value for each observation. This is useful for small data sets, but they can
        become hard to read with larger samples. Rather than showing the value of each observation, we prefer
        to think of the value as belonging to a <em>bin</em>. For example, in the <c>loan50</c> data set, we
        created a table of counts for the number of loans with interest rates between 5.0% and 7.5%, then the
        number of loans with rates between 7.5% and 10.0%, and so on. Observations that fall on the boundary
        of a bin (e.g. 10.00%) are allocated to the lower bin. This tabulation is shown in
        <xref ref="table-binned-int-rate"/>. These binned counts are plotted as bars in
        <xref ref="fig-loan50-int-rate-hist"/> into what is called a <term>histogram</term>, which resembles
        a more heavily binned version of the stacked dot plot.
      </p>

      <table xml:id="table-binned-int-rate">
        <title>Counts for the binned <c>interest_rate</c> data</title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell>Interest Rate</cell>
            <cell>5.0%-7.5%</cell>
            <cell>7.5%-10.0%</cell>
            <cell>10.0%-12.5%</cell>
            <cell>12.5%-15.0%</cell>
            <cell><m>\cdots</m></cell>
            <cell>25.0%-27.5%</cell>
          </row>
          <row>
            <cell>Count</cell>
            <cell>11</cell>
            <cell>15</cell>
            <cell>8</cell>
            <cell>4</cell>
            <cell><m>\cdots</m></cell>
            <cell>1</cell>
          </row>
        </tabular>
      </table>

      <figure xml:id="fig-loan50-int-rate-hist">
        <caption>A histogram of <c>interest_rate</c>. This distribution is strongly skewed to the right.</caption>
        <image source="ch_summarizing_data/figures/loan50IntRateHist/loan50IntRateHist.png" width="76%">
          <description>
            A histogram with a horizontal axis of "Interest Rate" and a vertical axis showing the frequency of
            occurrence of different bins of interest rate. The first bin is from 5%-7.5% with a frequency (count)
            of 11 observations, 7.5%-10% has a frequency of 15, 10%-12.5% has 8, 12.5%-15% has 4, 15%-17.5% has 5,
            17.5%-20% has 4, and then the 20%-22.5%, 22.5%-25%, and 25%-27.5% bins each have a frequency of 1.
          </description>
        </image>
      </figure>

      <p>
        Histograms provide a view of the <term>data density</term>. Higher bars represent where the data are
        relatively more common. For instance, there are many more loans with rates between 5% and 10% than loans
        with rates between 20% and 25% in the data set. The bars make it easy to see how the density of the data
        changes relative to the interest rate.
      </p>

      <p>
        Histograms are especially convenient for understanding the shape of the data distribution.
        <xref ref="fig-loan50-int-rate-hist"/> suggests that most loans have rates under 15%, while only a
        handful of loans have rates above 20%. When data trail off to the right in this way and has a longer
        right tail, the shape is said to be <term>right skewed</term>.<fn>Other ways to describe data that are
        right skewed: skewed to the right, skewed to the high end, or skewed to the positive end.</fn>
      </p>

      <p>
        Data sets with the reverse characteristic <mdash/> a long, thinner tail to the left <mdash/> are said
        to be <term>left skewed</term>. We also say that such a distribution has a long left tail. Data sets
        that show roughly equal trailing off in both directions are called <term>symmetric</term>.
      </p>

      <assemblage xml:id="assemblage-long-tails">
        <title>Long tails to identify skew</title>
        <p>
          When data trail off in one direction, the distribution has a <term>long tail</term>. If a distribution
          has a long left tail, it is left skewed. If a distribution has a long right tail, it is right skewed.
        </p>
      </assemblage>

      <exercise xml:id="ex-skew-in-plots">
        <title>Identifying skew</title>
        <statement>
          <p>
            Take a look at the dot plots in earlier figures. Can you see the skew in the data? Is it easier to
            see the skew in this histogram or the dot plots?
          </p>
        </statement>
        <solution>
          <p>
            The skew is visible in all three plots, though the flat dot plot is the least useful. The stacked
            dot plot and histogram are helpful visualizations for identifying skew.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="ex-histogram-vs-dotplot">
        <title>Histogram limitations</title>
        <statement>
          <p>
            Besides the mean (since it was labeled), what can you see in the dot plots that you cannot see in
            the histogram?
          </p>
        </statement>
        <solution>
          <p>
            The interest rates for individual loans.
          </p>
        </solution>
      </exercise>

      <p>
        In addition to looking at whether a distribution is skewed or symmetric, histograms can be used to
        identify modes. A <term>mode</term> is represented by a prominent peak in the distribution. There is
        only one prominent peak in the histogram of <c>loan_amount</c>.
      </p>

      <p>
        A definition of <em>mode</em> sometimes taught in math classes is the value with the most occurrences
        in the data set. However, for many real-world data sets, it is common to have <em>no</em> observations
        with the same value in a data set, making this definition impractical in data analysis.
      </p>

      <p>
        <xref ref="fig-modal-plots"/> shows histograms that have one, two, or three prominent peaks. Such
        distributions are called <term>unimodal</term>, <term>bimodal</term>, and <term>multimodal</term>,
        respectively. Any distribution with more than 2 prominent peaks is called multimodal. Notice that there
        was one prominent peak in the unimodal distribution with a second less prominent peak that was not
        counted since it only differs from its neighboring bins by a few observations.
      </p>

      <figure xml:id="fig-modal-plots">
        <caption>Distributions showing different numbers of modes</caption>
        <image source="ch_summarizing_data/figures/singleBiMultiModalPlots/singleBiMultiModalPlots.png" width="90%">
          <description>
            Three histograms are shown. The first histogram shows bins of width 2 between 0 to 18 (this is along
            the horizontal axis), and the frequencies are 3, 16, 16, 7, 11, 6, 4, 1, and 1. The second histogram,
            representing a different data set, shows bins of width 2 with values ranging from 0 to 20, where the
            bin counts in order are 2, 9, 5, 2, 2, 2, 2, 10, 19, and 9. The third histogram, representing yet
            another data set, shows bins of width 2 with values ranging from 0 to 22, where the bin counts in
            order are 10, 8, 4, 3, 1, 20, 15, 3, 15, 18, and 5.
          </description>
        </image>
      </figure>

      <example xml:id="ex-unimodal-classification">
        <title>Identifying modality</title>
        <statement>
          <p>
            <xref ref="fig-loan50-int-rate-hist"/> reveals only one prominent mode in the interest rate. Is the
            distribution unimodal, bimodal, or multimodal?
          </p>
        </statement>
        <solution>
          <p>
            Unimodal. Remember that <em>uni</em> stands for 1 (think <em>uni</em>cycles). Similarly, <em>bi</em>
            stands for 2 (think <em>bi</em>cycles). We're hoping a <em>multicycle</em> will be invented to
            complete this analogy.
          </p>
        </solution>
      </example>

      <exercise xml:id="ex-height-modes">
        <title>Expected modes in height data</title>
        <statement>
          <p>
            Height measurements of young students and adult teachers at a K-3 elementary school were taken. How
            many modes would you expect in this height data set?
          </p>
        </statement>
        <solution>
          <p>
            There might be two height groups visible in the data set: one of the students and one of the adults.
            That is, the data are probably bimodal.
          </p>
        </solution>
      </exercise>

      <p>
        Looking for modes isn't about finding a clear and correct answer about the number of modes in a
        distribution, which is why <em>prominent</em> is not rigorously defined in this book. The most important
        part of this examination is to better understand your data.
      </p>
    </subsection>

    <!-- Subsection 2.1.4: Variance and standard deviation -->
    <subsection xml:id="subsec-variance-sd">
      <title>Variance and standard deviation</title>

      <p>
        The mean was introduced as a method to describe the center of a data set, and variability in the data
        is also important. Here, we introduce two measures of variability: the variance and the standard
        deviation. Both of these are very useful in data analysis, even though their formulas are a bit tedious
        to calculate by hand. The standard deviation is the easier of the two to comprehend, and it roughly
        describes how far away the typical observation is from the mean.
      </p>

      <p>
        We call the distance of an observation from its mean its <term>deviation</term>. Below are the deviations
        for the 1<m>^{st}</m>, 2<m>^{nd}</m>, 3<m>^{rd}</m>, and 50<m>^{th}</m> observations in the
        <c>interest_rate</c> variable:
        <md>
          <mrow>x_1 - \bar{x} \amp = 10.90 - 11.57 = -0.67</mrow>
          <mrow>x_2 - \bar{x} \amp = 9.92 - 11.57 = -1.65</mrow>
          <mrow>x_3 - \bar{x} \amp = 26.30 - 11.57 = 14.73</mrow>
          <mrow>\amp \vdots</mrow>
          <mrow>x_{50} - \bar{x} \amp = 6.08 - 11.57 = -5.49</mrow>
        </md>
        If we square these deviations and then take an average, the result is equal to the sample
        <term>variance</term>, denoted by <m>s^2</m>:
        <md>
          <mrow>s^2 \amp = \frac{(-0.67)^2 + (-1.65)^2 + (14.73)^2 + \cdots + (-5.49)^2}{50-1}</mrow>
          <mrow>\amp = \frac{0.45 + 2.72 + 216.97 + \cdots + 30.14}{49}</mrow>
          <mrow>\amp = 25.52</mrow>
        </md>
        We divide by <m>n - 1</m>, rather than dividing by <m>n</m>, when computing a sample's variance; there's
        some mathematical nuance here, but the end result is that doing this makes this statistic slightly more
        reliable and useful.
      </p>

      <p>
        Notice that squaring the deviations does two things. First, it makes large values relatively much larger,
        seen by comparing <m>(-0.67)^2</m>, <m>(-1.65)^2</m>, <m>(14.73)^2</m>, and <m>(-5.49)^2</m>. Second, it
        gets rid of any negative signs.
      </p>

      <p>
        The <term>standard deviation</term> is defined as the square root of the variance:
        <md>
          <mrow>s = \sqrt{25.52} = 5.05</mrow>
        </md>
        While often omitted, a subscript of <m>_x</m> may be added to the variance and standard deviation, i.e.
        <m>s_x^2</m> and <m>s_x</m>, if it is useful as a reminder that these are the variance and standard
        deviation of the observations represented by <m>x_1</m>, <m>x_2</m>, ..., <m>x_n</m>.
      </p>

      <assemblage xml:id="def-variance-sd">
        <title>Variance and standard deviation</title>
        <p>
          The variance is the average squared distance from the mean. The standard deviation is the square root
          of the variance. The standard deviation is useful when considering how far the data are distributed
          from the mean.
        </p>
        <p>
          The standard deviation represents the typical deviation of observations from the mean. Usually about
          70% of the data will be within one standard deviation of the mean and about 95% will be within two
          standard deviations. However, these percentages are not strict rules.
        </p>
      </assemblage>

      <p>
        Like the mean, the population values for variance and standard deviation have special symbols: <m>\sigma^2</m>
        for the variance and <m>\sigma</m> for the standard deviation. The symbol <m>\sigma</m> is the Greek
        letter <em>sigma</em>.
      </p>

      <figure xml:id="fig-sd-rule-int-rate">
        <caption>Standard deviations in the interest rate distribution</caption>
        <image source="ch_summarizing_data/figures/sdRuleForIntRate/sdRuleForIntRate.png" width="73%">
          <description>
            A dot plot of 50 observations is shown with values ranging from about 5% to 26%. The data set is the
            same as that shown in earlier dot plots, where the data is more dense from 5% to about 11%, has medium
            density from about 12% to 20%, and then there are a few more values scattered in the 20% to 27% range.
            Shading is shown to represent the regions within 1, 2, and 3 standard deviations. The region within 1
            standard deviation is from 6.5% to 16.7%, representing 34 of the 50 data points. The region within 2
            standard deviations runs left off of the chart (but would be from about 1.4%) to 21.8% and contains 48
            of the 50 data points. The third standard deviation is shown to extend out to 26.9%, and all 50
            observations are contained within the 3 standard deviations.
          </description>
        </image>
      </figure>

      <p>
        For the <c>interest_rate</c> variable, 34 of the 50 loans (68%) had interest rates within 1 standard
        deviation of the mean, and 48 of the 50 loans (96%) had rates within 2 standard deviations. Usually about
        70% of the data are within 1 standard deviation of the mean and 95% within 2 standard deviations, though
        this is far from a hard rule.
      </p>

      <figure xml:id="fig-different-dists-same-sd">
        <caption>Three very different population distributions with the same mean <m>\mu=0</m> and standard deviation <m>\sigma=1</m></caption>
        <image source="ch_summarizing_data/figures/severalDiffDistWithSdOf1/severalDiffDistWithSdOf1.png" width="60%">
          <description>
            Three histograms are shown (upper, middle, lower). Each distribution also shows shading -- dark gray
            between -1 to 1, lighter gray between -2 and 2, and light gray between -3 and 3, and then very light
            gray further out. The upper plot shows only two bins with non-zero values and of equal height at -1 and
            1. The middle plot shows a bell-shaped curve, where most of the higher bin values are between -1 and 1,
            middling heights are between -2 to -1 and 1 to 2, and the data trails off in each direction with
            ever-smaller values further out. The lower histogram shows no data below about -1.6, a quick increase to
            a peak at about -0.7 and then a slow decline of values to about half the max height at 1 and further
            trails off to ever smaller values to a horizontal location of 3 and beyond.
          </description>
        </image>
      </figure>

      <exercise xml:id="ex-shape-importance">
        <title>Importance of shape description</title>
        <statement>
          <p>
            The concept of shape of a distribution was introduced earlier. A good description of the shape of a
            distribution should include modality and whether the distribution is symmetric or skewed to one side.
            Using <xref ref="fig-different-dists-same-sd"/> as an example, explain why such a description is important.
          </p>
        </statement>
        <solution>
          <p>
            <xref ref="fig-different-dists-same-sd"/> shows three distributions that look quite different, but all
            have the same mean, variance, and standard deviation. Using modality, we can distinguish between the first
            plot (bimodal) and the last two (unimodal). Using skewness, we can distinguish between the last plot (right
            skewed) and the first two. While a picture, like a histogram, tells a more complete story, we can use
            modality and shape (symmetry/skew) to characterize basic information about a distribution.
          </p>
        </solution>
      </exercise>

      <example xml:id="ex-describe-interest-distribution">
        <title>Describing a distribution</title>
        <statement>
          <p>
            Describe the distribution of the <c>interest_rate</c> variable using the histogram in
            <xref ref="fig-loan50-int-rate-hist"/>. The description should incorporate the center, variability, and
            shape of the distribution, and it should also be placed in context. Also note any especially unusual cases.
          </p>
        </statement>
        <solution>
          <p>
            The distribution of interest rates is unimodal and skewed to the high end. Many of the rates fall near
            the mean at 11.57%, and most fall within one standard deviation (5.05%) of the mean. There are a few
            exceptionally large interest rates in the sample that are above 20%.
          </p>
        </solution>
      </example>

      <p>
        In practice, the variance and standard deviation are sometimes used as a means to an end, where the "end"
        is being able to accurately estimate the uncertainty associated with a sample statistic. For example, in
        later chapters the standard deviation is used in calculations that help us understand how much a sample
        mean varies from one sample to the next.
      </p>
    </subsection>

    <!-- Subsection 2.1.5: Box plots, quartiles, and the median -->
    <subsection xml:id="subsec-boxplots-quartiles">
      <title>Box plots, quartiles, and the median</title>

      <p>
        A <term>box plot</term> summarizes a data set using five statistics while also plotting unusual
        observations. <xref ref="fig-loan-int-rate-boxplot"/> provides a vertical dot plot alongside a box plot
        of the <c>interest_rate</c> variable from the <c>loan50</c> data set.
      </p>

      <figure xml:id="fig-loan-int-rate-boxplot">
        <caption>A vertical dot plot next to a labeled box plot for the interest rates of the 50 loans</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_box_plot_layout/loan_int_rate_box_plot_layout.png" width="86%">
          <description>
            What is shown is a dot plot adjacent to what is called a "box plot". The data values are the same ones
            used in past dot plots, where the data shows greatest density from 5% to 11%, moderate density from 12%
            to 20%, and then a few more values at about 22%, 25%, and 26%. The box plot adjacent to the data shows
            a box that would encapsulate the middle 50% of the data, from about 8% to 13%. The median is also
            annotated with a line through the center of the box. From here, the data extend out with "whiskers" up
            to a distance up to 1.5 times IQR below and above the box to capture as much data as possible. There are
            two observations that extend beyond this range at 25% and 26%.
          </description>
        </image>
      </figure>

      <p>
        The first step in building a box plot is drawing a dark line denoting the <term>median</term>, which
        splits the data in half. <xref ref="fig-loan-int-rate-boxplot"/> shows 50% of the data falling below
        the median and other 50% falling above the median. There are 50 loans in the data set (an even number)
        so the data are perfectly split into two groups of 25. We take the median in this case to be the average
        of the two observations closest to the 50<m>^{th}</m> percentile, which happen to be the same value in
        this data set: <m>(9.93\% + 9.93\%) / 2 = 9.93\%</m>. When there are an odd number of observations,
        there will be exactly one observation that splits the data into two halves, and in such a case that
        observation is the median (no average needed).
      </p>

      <assemblage xml:id="def-median">
        <title>Median: the number in the middle</title>
        <p>
          If the data are ordered from smallest to largest, the <term>median</term> is the observation right in
          the middle. If there are an even number of observations, there will be two values in the middle, and
          the median is taken as their average.
        </p>
      </assemblage>

      <p>
        The second step in building a box plot is drawing a rectangle to represent the middle 50% of the data.
        The total length of the box, shown vertically in <xref ref="fig-loan-int-rate-boxplot"/>, is called the
        <term>interquartile range</term> (<term>IQR</term>, for short). It, like the standard deviation, is a
        measure of variability in data. The more variable the data, the larger the standard deviation and IQR
        tend to be. The two boundaries of the box are called the <term>first quartile</term> (the 25<m>^{th}</m>
        percentile, i.e. 25% of the data fall below this value) and the <term>third quartile</term> (the
        75<m>^{th}</m> percentile), and these are often labeled <m>Q_1</m> and <m>Q_3</m>, respectively.
      </p>

      <assemblage xml:id="def-iqr">
        <title>Interquartile range (IQR)</title>
        <p>
          The IQR is the length of the box in a box plot. It is computed as
          <md>
            <mrow>IQR = Q_3 - Q_1</mrow>
          </md>
          where <m>Q_1</m> and <m>Q_3</m> are the 25<m>^{th}</m> and 75<m>^{th}</m> percentiles.
        </p>
      </assemblage>

      <exercise xml:id="ex-quartile-percentages">
        <title>Data between quartiles</title>
        <statement>
          <p>
            What percent of the data fall between <m>Q_1</m> and the median? What percent is between the median
            and <m>Q_3</m>?
          </p>
        </statement>
        <solution>
          <p>
            Since <m>Q_1</m> and <m>Q_3</m> capture the middle 50% of the data and the median splits the data in
            the middle, 25% of the data fall between <m>Q_1</m> and the median, and another 25% falls between the
            median and <m>Q_3</m>.
          </p>
        </solution>
      </exercise>

      <p>
        Extending out from the box, the <term>whiskers</term> attempt to capture the data outside of the box.
        However, their reach is never allowed to be more than <m>1.5 \times IQR</m>. They capture everything
        within this reach. In <xref ref="fig-loan-int-rate-boxplot"/>, the upper whisker does not extend to the
        last two points, which is beyond <m>Q_3 + 1.5 \times IQR</m>, and so it extends only to the last point
        below this limit. The lower whisker stops at the lowest value, 5.31%, since there is no additional data
        to reach; the lower whisker's limit is not shown in the figure because the plot does not extend down to
        <m>Q_1 - 1.5 \times IQR</m>. In a sense, the box is like the body of the box plot and the whiskers are
        like its arms trying to reach the rest of the data.
      </p>

      <p>
        Any observation lying beyond the whiskers is labeled with a dot. The purpose of labeling these points
        <mdash/> instead of extending the whiskers to the minimum and maximum observed values <mdash/> is to
        help identify any observations that appear to be unusually distant from the rest of the data. Unusually
        distant observations are called <term>outliers</term>. In this case, it would be reasonable to classify
        the interest rates of 24.85% and 26.30% as outliers since they are numerically distant from most of the
        data.
      </p>

      <assemblage xml:id="def-outliers">
        <title>Outliers are extreme</title>
        <p>
          An <term>outlier</term> is an observation that appears extreme relative to the rest of the data.
        </p>
        <p>
          Examining data for outliers serves many useful purposes, including:
          <ol>
            <li><p>Identifying strong skew in the distribution.</p></li>
            <li><p>Identifying possible data collection or data entry errors.</p></li>
            <li><p>Providing insight into interesting properties of the data.</p></li>
          </ol>
        </p>
      </assemblage>

      <exercise xml:id="ex-estimate-quartiles">
        <title>Estimating quartiles from a box plot</title>
        <statement>
          <p>
            Using <xref ref="fig-loan-int-rate-boxplot"/>, estimate the following values for <c>interest_rate</c>
            in the <c>loan50</c> data set:
            (a) <m>Q_1</m>, (b) <m>Q_3</m>, and (c) IQR.
          </p>
        </statement>
        <solution>
          <p>
            These visual estimates will vary a little from one person to the next: <m>Q_1 \approx</m> 8%,
            <m>Q_3 \approx</m> 14%, <m>IQR = Q_3 - Q_1 \approx</m> 6%. (The true values: <m>Q_1 = 7.96\%</m>,
            <m>Q_3 = 13.72\%</m>, <m>IQR = 5.76\%</m>.)
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- Subsection 2.1.6: Robust statistics -->
    <subsection xml:id="subsec-robust-stats">
      <title>Robust statistics</title>

      <p>
        How are the sample statistics of the <c>interest_rate</c> data set affected by the observation, 26.3%?
        What would have happened if this loan had instead been only 15%? What would happen to these summary
        statistics if the observation at 26.3% had been even larger, say 35%? These scenarios are plotted
        alongside the original data in <xref ref="fig-loan-int-rate-robust"/>, and sample statistics are computed
        under each scenario in <xref ref="table-robust-comparison"/>.
      </p>

      <figure xml:id="fig-loan-int-rate-robust">
        <caption>Dot plots of the original interest rate data and two modified data sets</caption>
        <image source="ch_summarizing_data/figures/loan_int_rate_robust_ex/loan_int_rate_robust_ex.png" width="100%">
          <description>
            Three dot plots are shown in the same plot. The largest observation from the original data set
            (discussed in previous dot plots) at about 26% is moved to 15% in the second dot plot and instead
            to 35% in the third dot plot.
          </description>
        </image>
      </figure>

      <table xml:id="table-robust-comparison">
        <title>Comparison of statistics under different scenarios</title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell>Scenario</cell>
            <cell colspan="2" halign="center">Robust</cell>
            <cell colspan="2" halign="center">Not Robust</cell>
          </row>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell>Median</cell>
            <cell>IQR</cell>
            <cell><m>\bar{x}</m></cell>
            <cell><m>s</m></cell>
          </row>
          <row>
            <cell>Original <c>interest_rate</c> data</cell>
            <cell>9.93%</cell>
            <cell>5.76%</cell>
            <cell>11.57%</cell>
            <cell>5.05%</cell>
          </row>
          <row>
            <cell>Move 26.3% <m>\to</m> 15%</cell>
            <cell>9.93%</cell>
            <cell>5.76%</cell>
            <cell>11.34%</cell>
            <cell>4.61%</cell>
          </row>
          <row>
            <cell>Move 26.3% <m>\to</m> 35%</cell>
            <cell>9.93%</cell>
            <cell>5.76%</cell>
            <cell>11.74%</cell>
            <cell>5.68%</cell>
          </row>
        </tabular>
      </table>

      <exercise xml:id="ex-robustness-comparison">
        <title>Comparing robustness of statistics</title>
        <statement>
          <p>
            (a) Which is more affected by extreme observations, the mean or median? <xref ref="table-robust-comparison"/>
            may be helpful. (b) Is the standard deviation or IQR more affected by extreme observations?
          </p>
        </statement>
        <solution>
          <p>
            (a) Mean is affected more. (b) Standard deviation is affected more. Complete explanations are provided
            below.
          </p>
        </solution>
      </exercise>

      <p>
        The median and IQR are called <term>robust statistics</term> because extreme observations have little
        effect on their values: moving the most extreme value generally has little influence on these statistics.
        On the other hand, the mean and standard deviation are more heavily influenced by changes in extreme
        observations, which can be important in some situations.
      </p>

      <example xml:id="ex-why-robust-stable">
        <title>Stability of robust statistics</title>
        <statement>
          <p>
            The median and IQR did not change under the three scenarios in <xref ref="table-robust-comparison"/>.
            Why might this be the case?
          </p>
        </statement>
        <solution>
          <p>
            The median and IQR are only sensitive to numbers near <m>Q_1</m>, the median, and <m>Q_3</m>. Since
            values in these regions are stable in the three data sets, the median and IQR estimates are also stable.
          </p>
        </solution>
      </example>

      <exercise xml:id="ex-mean-vs-median-choice">
        <title>Choosing between mean and median</title>
        <statement>
          <p>
            The distribution of loan amounts in the <c>loan50</c> data set is right skewed, with a few large loans
            lingering out into the right tail. If you were wanting to understand the typical loan size, should you
            be more interested in the mean or median?
          </p>
        </statement>
        <solution>
          <p>
            Answers will vary! If we're looking to simply understand what a typical individual loan looks like, the
            median is probably more useful. However, if the goal is to understand something that scales well, such
            as the total amount of money we might need to have on hand if we were to offer 1,000 loans, then the
            mean would be more useful.
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- Subsection 2.1.7: Transforming data (special topic) -->
    <subsection xml:id="subsec-transforming-data">
      <title>Transforming data (special topic)</title>

      <p>
        When data are very strongly skewed, we sometimes transform them so they are easier to model.
      </p>

      <figure xml:id="fig-county-pop-transformed">
        <caption>County population distributions: (a) original data showing extreme skew, (b) log-transformed data</caption>
        <image source="ch_summarizing_data/figures/county_pop_transformed/county_pop_transformed.png" width="90%">
          <description>
            Two histograms are shown side by side. The first histogram has a horizontal axis of Population with
            possible data ranging from 0 to about 10 million. The first bar representing 0 to 400,000 shows a
            frequency (bar height) of about 3000, the second bar for 400,000 to 800,000 shows about frequency of
            about 100. All other bars are sufficiently small that they are virtually indistinguishable from 0. The
            second histogram shows the horizontal axis represents log-base-10 of the population. The horizontal axis
            runs from about 2 to 7, and frequency (bin/box height) peaks at a little over 1000. The data show an
            approximate bell shape, peaking in the middle between 4 to 4.5, then showing lower frequencies the
            further out from 4-4.5 with frequencies being close to zero outside of 2.5 to 6.5.
          </description>
        </image>
      </figure>

      <example xml:id="ex-extreme-skew-problem">
        <title>Issues with extreme skew</title>
        <statement>
          <p>
            Consider the histogram of county populations shown in <xref ref="fig-county-pop-transformed"/> (left
            panel), which shows extreme skew. What isn't useful about this plot?
          </p>
        </statement>
        <solution>
          <p>
            Nearly all of the data fall into the left-most bin, and the extreme skew obscures many of the
            potentially interesting details in the data.
          </p>
        </solution>
      </example>

      <p>
        There are some standard transformations that may be useful for strongly right skewed data where much of
        the data is positive but clustered near zero. A <term>transformation</term> is a rescaling of the data
        using a function. For instance, a plot of the logarithm (base 10) of county populations results in the
        new histogram in <xref ref="fig-county-pop-transformed"/> (right panel). This data is symmetric, and any
        potential outliers appear much less extreme than in the original data set. By reigning in the outliers
        and extreme skew, transformations like this often make it easier to build statistical models against the
        data.
      </p>

      <p>
        Transformations can also be applied to one or both variables in a scatterplot. A scatterplot of the
        population change from 2010 to 2017 against the population in 2010 is shown in
        <xref ref="fig-pop-change-transform"/>. In the first scatterplot, it's hard to decipher any interesting
        patterns because the population variable is so strongly skewed. However, if we apply a log<m>_{10}</m>
        transformation to the population variable, as shown in the second panel, a positive association between
        the variables is revealed.
      </p>

      <figure xml:id="fig-pop-change-transform">
        <caption>Scatterplots of population change vs. population: (a) original data, (b) log-transformed population</caption>
        <image source="ch_summarizing_data/figures/county_pop_change_v_pop_transform/county_pop_change_v_pop_transform.png" width="90%">
          <description>
            Two scatterplots are shown side by side. The first scatterplot has population on the horizontal axis
            (ranging from 0 to 10 million) and population change as a percent on the vertical axis (ranging from
            -35% to positive 40%). The data is particularly concentrated on the left of the graph below 1 million.
            There is no discernible trend in the data. The second scatterplot has log-base-10 of the population on
            the horizontal axis (ranging from 2 to 7) and population change as a percent on the vertical axis. The
            data is well distributed and shows a cloud of points with a slight upward trend.
          </description>
        </image>
      </figure>

      <p>
        Transformations other than the logarithm can be useful, too. For instance, the square root and inverse are
        commonly used by data scientists. Common goals in transforming data are to see the data structure
        differently, reduce skew, assist in modeling, or straighten a nonlinear relationship in a scatterplot.
      </p>
    </subsection>

    <!-- Subsection 2.1.8: Mapping data (special topic) -->
    <subsection xml:id="subsec-mapping-data">
      <title>Mapping data (special topic)</title>

      <p>
        The <c>county</c> data set offers many numerical variables that we could plot using dot plots,
        scatterplots, or box plots, but these miss the true nature of the data. Rather, when we encounter
        geographic data, we should create an <term>intensity map</term>, where colors are used to show higher and
        lower values of a variable. Figures throughout this book demonstrate a variety of intensity maps for
        county-level data including poverty rate (<c>poverty</c>), unemployment rate (<c>unemployment_rate</c>),
        homeownership rate (<c>homeownership</c>), and median household income (<c>median_hh_income</c>).
        The color key indicates which colors correspond to which values.
        The intensity maps are not generally very helpful for getting precise values in any given county, but
        they are very helpful for seeing geographic trends and generating interesting research questions or hypotheses.
      </p>

      <example xml:id="ex-poverty-unemployment-maps">
        <title>Features in poverty and unemployment intensity maps</title>
        <statement>
          <p>
            What interesting features are evident in the <c>poverty</c> and <c>unemployment_rate</c> intensity maps?
          </p>
        </statement>
        <solution>
          <p>
            Poverty rates are evidently higher in a few locations. Notably, the deep south shows higher poverty rates,
            as does much of Arizona and New Mexico. High poverty rates are evident in the Mississippi flood plains a
            little north of New Orleans and also in a large section of Kentucky.
          </p>
          <p>
            The unemployment rate follows similar trends, and we can see correspondence between the two variables. In
            fact, it makes sense for higher rates of unemployment to be closely related to poverty rates. One observation
            that stands out when comparing the two maps: the poverty rate is much higher than the unemployment rate,
            meaning while many people may be working, they are not making enough to break out of poverty.
          </p>
        </solution>
      </example>

      <exercise xml:id="guided-practice-median-income-map">
        <title>Features in median household income map</title>
        <statement>
          <p>
            What interesting features are evident in the <c>median_hh_income</c> intensity map?
          </p>
        </statement>
        <solution>
          <p>
            Note: answers will vary. There is some correspondence between high earning and metropolitan areas, where we
            can see darker spots (higher median household income), though there are several exceptions. You might look
            for large cities you are familiar with and try to spot them on the map as dark spots.
          </p>
        </solution>
      </exercise>
    </subsection>

    <!-- End of Section 2.1 subsections -->

  </section>

  <!-- Section 2.2: Considering categorical data -->
  <section xml:id="sec-categorical-data">
    <title>Considering categorical data</title>

    <introduction>
      <p>
        In this section, we will introduce tables and other basic tools for categorical data that are used
        throughout this book. The <c>loan50</c> data set represents a sample from a larger loan data set called
        <c>loans</c>. This larger data set contains information on 10,000 loans made through Lending Club. We will
        examine the relationship between <c>homeownership</c>, which for the <c>loans</c> data can take a value of
        <c>rent</c>, <c>mortgage</c> (owns but has a mortgage), or <c>own</c>, and <c>app_type</c>, which
        indicates whether the loan application was made with a partner or whether it was an individual application.
      </p>
    </introduction>

    <!-- Subsection 2.2.1: Contingency tables and bar plots -->
    <subsection xml:id="subsec-contingency-tables">
      <title>Contingency tables and bar plots</title>

      <p>
        <xref ref="table-loan-app-homeownership"/> summarizes two variables: <c>app_type</c> and
        <c>homeownership</c>. A table that summarizes data for two categorical variables in this way is called a
        <term>contingency table</term>. Each value in the table represents the number of times a particular
        combination of variable outcomes occurred. For example, the value 3,496 corresponds to the number of loans
        in the data set where the borrower rents their home and the application type was by an individual. Row and
        column totals are also included. The <term>row totals</term> provide the total counts across each row
        (e.g. <m>3496 + 3839 + 1170 = 8505</m>), and <term>column totals</term> are total counts down each column.
        We can also create a table that shows only the overall percentages or proportions for each combination of
        categories, or we can create a table for a single variable, such as the one shown in
        <xref ref="table-homeownership-freq"/> for the <c>homeownership</c> variable.
      </p>

      <table xml:id="table-loan-app-homeownership">
        <title>A contingency table for <c>app_type</c> and <c>homeownership</c></title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell></cell>
            <cell></cell>
            <cell colspan="3" halign="center"><c>homeownership</c></cell>
            <cell></cell>
          </row>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell>rent</cell>
            <cell>mortgage</cell>
            <cell>own</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell><c>app_type</c></cell>
            <cell>individual</cell>
            <cell>3,496</cell>
            <cell>3,839</cell>
            <cell>1,170</cell>
            <cell>8,505</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell>joint</cell>
            <cell>362</cell>
            <cell>950</cell>
            <cell>183</cell>
            <cell>1,495</cell>
          </row>
          <row bottom="medium">
            <cell></cell>
            <cell>Total</cell>
            <cell>3,858</cell>
            <cell>4,789</cell>
            <cell>1,353</cell>
            <cell>10,000</cell>
          </row>
        </tabular>
      </table>

      <table xml:id="table-homeownership-freq">
        <title>A table summarizing the frequencies of each value for the <c>homeownership</c> variable</title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell><c>homeownership</c></cell>
            <cell>Count</cell>
          </row>
          <row>
            <cell>rent</cell>
            <cell>3,858</cell>
          </row>
          <row>
            <cell>mortgage</cell>
            <cell>4,789</cell>
          </row>
          <row bottom="minor">
            <cell>own</cell>
            <cell>1,353</cell>
          </row>
          <row bottom="medium">
            <cell>Total</cell>
            <cell>10,000</cell>
          </row>
        </tabular>
      </table>

      <p>
        A bar plot is a common way to display a single categorical variable. <xref ref="fig-homeownership-barplot"/>
        shows a <term>bar plot</term> for the <c>homeownership</c> variable. In the left panel, the bar plot shows
        counts. In the right panel, the counts are converted into proportions, showing the proportion of
        observations that are in each level (e.g. <m>3858 / 10000 = 0.3858</m> for <c>rent</c>).
      </p>

      <figure xml:id="fig-homeownership-barplot">
        <caption>Two bar plots of homeownership: (left) counts, (right) proportions</caption>
        <image source="ch_summarizing_data/figures/loan_homeownership_bar_plot/loan_homeownership_bar_plot.png" width="90%">
          <description>
            Two bar plots are shown side by side. The left bar plot has Homeownership on the horizontal axis and
            Frequency (count) on the vertical axis. Each level of homeownership has its own "bar" (which looks like
            a tall rectangle resting on the horizontal axis) with a height corresponding to the frequency of that
            bar in the data set. For example, the "Rent" bar extends from the horizontal axis up to a frequency of
            about 3900. The "Mortgage" bar extends from the horizontal axis up to about 4700, and the bar for "Own"
            extends up to about 1300. Moving to the next plot, the right bar plot, it looks very similar to the left
            bar plot except that it reports the proportion of cases on the vertical axis instead of the frequency
            (count). The values in this bar plot are: about 0.39 for Rent, about 0.47 for Mortgage, and about 0.13
            for Own.
          </description>
        </image>
      </figure>
    </subsection>

    <!-- Subsection 2.2.2: Row and column proportions -->
    <subsection xml:id="subsec-row-column-proportions">
      <title>Row and column proportions</title>

      <p>
        Sometimes it is useful to understand the fractional breakdown of one variable in another, and we can
        modify our contingency table to provide such a view. <xref ref="table-row-props-app-homeownership"/> shows
        the <term>row proportions</term> for <xref ref="table-loan-app-homeownership"/>, which are computed as the
        counts divided by their row totals. The value 3,496 at the intersection of <c>individual</c> and
        <c>rent</c> is replaced by <m>3496/8505 = 0.411</m>, i.e. 3,496 divided by its row total, 8,505. So what
        does 0.411 represent? It corresponds to the proportion of individual applicants who rent.
      </p>

      <table xml:id="table-row-props-app-homeownership">
        <title>A contingency table with row proportions for <c>app_type</c> and <c>homeownership</c></title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell></cell>
            <cell>rent</cell>
            <cell>mortgage</cell>
            <cell>own</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>individual</cell>
            <cell>0.411</cell>
            <cell>0.451</cell>
            <cell>0.138</cell>
            <cell>1.000</cell>
          </row>
          <row bottom="minor">
            <cell>joint</cell>
            <cell>0.242</cell>
            <cell>0.635</cell>
            <cell>0.122</cell>
            <cell>1.000</cell>
          </row>
          <row bottom="medium">
            <cell>Total</cell>
            <cell>0.386</cell>
            <cell>0.479</cell>
            <cell>0.135</cell>
            <cell>1.000</cell>
          </row>
        </tabular>
      </table>

      <p>
        A contingency table of the column proportions is computed in a similar way, where each <term>column
        proportion</term> is computed as the count divided by the corresponding column total.
        <xref ref="table-col-props-app-homeownership"/> shows such a table, and here the value 0.906 indicates
        that 90.6% of renters applied as individuals for the loan. This rate is higher compared to loans from
        people with mortgages (80.2%) or who own their home (86.5%). Because these rates vary between the three
        levels of <c>homeownership</c>, this provides evidence that the <c>app_type</c> and <c>homeownership</c>
        variables are associated.
      </p>

      <table xml:id="table-col-props-app-homeownership">
        <title>A contingency table with column proportions for <c>app_type</c> and <c>homeownership</c></title>
        <tabular>
          <row header="yes" bottom="medium">
            <cell></cell>
            <cell>rent</cell>
            <cell>mortgage</cell>
            <cell>own</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>individual</cell>
            <cell>0.906</cell>
            <cell>0.802</cell>
            <cell>0.865</cell>
            <cell>0.851</cell>
          </row>
          <row bottom="minor">
            <cell>joint</cell>
            <cell>0.094</cell>
            <cell>0.198</cell>
            <cell>0.135</cell>
            <cell>0.150</cell>
          </row>
          <row bottom="medium">
            <cell>Total</cell>
            <cell>1.000</cell>
            <cell>1.000</cell>
            <cell>1.000</cell>
            <cell>1.000</cell>
          </row>
        </tabular>
      </table>

      <p>
        We could also have checked for an association between <c>app_type</c> and <c>homeownership</c> using row
        proportions. When comparing these row proportions, we would look down columns to see if the fraction of
        loans where the borrower rents, has a mortgage, or owns varied across the individual to joint application
        types.
      </p>

      <exercise xml:id="ex-interpret-row-col-props">
        <title>Interpreting proportions</title>
        <statement>
          <p>
            (a) What does 0.451 represent in <xref ref="table-row-props-app-homeownership"/>?
            (b) What does 0.802 represent in <xref ref="table-col-props-app-homeownership"/>?
          </p>
        </statement>
        <solution>
          <p>
            (a) 0.451 represents the proportion of individual applicants who have a mortgage.
            (b) 0.802 represents the fraction of applicants with mortgages who applied as individuals.
          </p>
        </solution>
      </exercise>

      <example xml:id="ex-spam-email-classification">
        <title>Email spam classification</title>
        <statement>
          <p>
            Data scientists use statistics to filter spam from incoming email messages. By noting specific
            characteristics of an email, a data scientist may be able to classify some emails as spam or not spam
            with high accuracy. One such characteristic is the email format, which indicates whether or not an
            email has any HTML content. We'll focus on email format and spam status using the <c>email</c> data
            set, and these variables are summarized in a contingency table. Which would be more helpful to someone
            hoping to classify email as spam or regular email: row or column proportions?
          </p>
        </statement>
        <solution>
          <p>
            A data scientist would be interested in how the proportion of spam changes within each email format.
            This corresponds to column proportions: the proportion of spam in plain text emails and the proportion
            of spam in HTML emails. If we generate the column proportions, we can see that a higher fraction of
            plain text emails are spam (17.5%) than compared to HTML emails (5.8%). This information on its own is
            insufficient to classify an email as spam or not spam, as over 80% of plain text emails are not spam.
            Yet, when we carefully combine this information with many other characteristics, we stand a reasonable
            chance of being able to classify some emails as spam or not spam with confidence.
          </p>
        </solution>
      </example>

      <p>
        Example <xref ref="ex-spam-email-classification"/> points out that row and column proportions are not
        equivalent. Before settling on one form for a table, it is important to consider each to ensure that the most
        useful table is constructed. However, sometimes it simply isn't clear which, if either, is more useful.
      </p>

      <example xml:id="ex-app-type-homeownership-usefulness">
        <title>Determining table usefulness</title>
        <statement>
          <p>
            Look back to the row and column proportion tables for <c>app_type</c> and <c>homeownership</c>. Are there
            any obvious scenarios where one might be more useful than the other?
          </p>
        </statement>
        <solution>
          <p>
            None that we thought were obvious! What is distinct about <c>app_type</c> and <c>homeownership</c> versus
            the email example is that these two variables don't have a clear explanatory-response variable relationship
            that we might hypothesize. Usually it is most useful to "condition" on the explanatory variable. For
            instance, in the email example, the email format was seen as a possible explanatory variable of whether the
            message was spam, so we would find it more interesting to compute the relative frequencies (proportions) for
            each email format.
          </p>
        </solution>
      </example>
    </subsection>

    <!-- Subsection 2.2.3: Using a bar plot with two variables -->
    <subsection xml:id="subsec-bar-plot-two-vars">
      <title>Using a bar plot with two variables</title>

      <p>
        Contingency tables using row or column proportions are especially useful for examining how two categorical
        variables are related. Stacked bar plots provide a way to visualize the information in these tables.
      </p>

      <p>
        A <term>stacked bar plot</term> is a graphical display of contingency table information. For example, a
        stacked bar plot is shown in <xref ref="fig-bar-plot-variants"/> (left panel), where we have first created
        a bar plot using the <c>homeownership</c> variable and then divided each group by the levels of
        <c>app_type</c>. One related visualization is the <term>side-by-side bar plot</term>, shown in
        <xref ref="fig-bar-plot-variants"/> (middle panel). For the last type, the column proportions have been
        translated into a standardized stacked bar plot in <xref ref="fig-bar-plot-variants"/> (right panel).
        This type of visualization is helpful in understanding the fraction of individual or joint loan
        applications for borrowers in each level of <c>homeownership</c>. Since the proportions vary across the
        groups, we can conclude that the two variables are associated.
      </p>

      <figure xml:id="fig-bar-plot-variants">
        <caption>Bar plot variants: (left) stacked, (middle) side-by-side, (right) standardized stacked</caption>
        <image source="ch_summarizing_data/figures/loan_app_type_home_seg_bar/loan_app_type_home_seg_bar.png" width="95%">
          <description>
            Three bar plots are shown side by side showing different representations of the same data. All plots
            show homeownership on the horizontal axis with levels rent, mortgage, and own. The first plot shows a
            stacked bar plot with frequency counts, the second shows bars side-by-side for each homeownership level,
            and the third shows standardized bars all reaching to 1.0 on the vertical axis.
          </description>
        </image>
      </figure>

      <example xml:id="ex-when-use-bar-variants">
        <title>Choosing bar plot variants</title>
        <statement>
          <p>
            Examine the three bar plots in <xref ref="fig-bar-plot-variants"/>. When is the stacked, side-by-side,
            or standardized stacked bar plot the most useful?
          </p>
        </statement>
        <solution>
          <p>
            The stacked bar plot is most useful when it's reasonable to assign one variable as the explanatory
            variable and the other as the response. Side-by-side bar plots are more agnostic about which variable
            represents the explanatory and which the response variable. The standardized stacked bar plot is helpful
            if the primary variable is relatively imbalanced, making the simple stacked bar plot less useful for
            checking for an association. The major downside is that we lose all sense of how many cases each bar
            represents.
          </p>
        </solution>
      </example>
    </subsection>

    <!-- Subsection 2.2.4: Mosaic plots -->
    <subsection xml:id="subsec-mosaic-plots">
      <title>Mosaic plots</title>

      <p>
        A <term>mosaic plot</term> is a visualization technique suitable for contingency tables that resembles a
        standardized stacked bar plot with the benefit that we still see the relative group sizes of the primary
        variable as well.
      </p>

      <p>
        To get started in creating our first mosaic plot, we'll break a square into columns for each category of
        the <c>homeownership</c> variable. Each column represents a level of <c>homeownership</c>, and the column
        widths correspond to the proportion of loans in each of those categories. In general, mosaic plots use box
        <em>areas</em> to represent the number of cases in each category.
      </p>

      <figure xml:id="fig-mosaic-plots">
        <caption>Mosaic plots: (left) one-variable for homeownership, (right) two-variable with app_type</caption>
        <image source="ch_summarizing_data/figures/loan_app_type_home_mosaic_plot/loan_app_type_home_mosaic_plot.png" width="85%">
          <description>
            Two mosaic plots are shown. The left plot shows a square divided vertically into three sections for
            rent (about 40%), mortgage (about 48%), and own (about 12%). The right plot further subdivides each
            vertical section horizontally to show the breakdown by application type (individual and joint).
          </description>
        </image>
      </figure>

      <p>
        To create a completed mosaic plot, the single-variable mosaic plot is further divided using the
        <c>app_type</c> variable. Each column is split proportional to the number of loans from individual and joint
        borrowers. For example, the second column represents loans where the borrower has a mortgage, and it was
        divided into individual loans (upper) and joint loans (lower). As another example, the bottom segment of the
        third column represents loans where the borrower owns their home and applied jointly, while the upper segment
        of this column represents borrowers who are homeowners and filed individually. We can again use this plot to
        see that the <c>homeownership</c> and <c>app_type</c> variables are associated, since some columns are divided
        in different vertical locations than others, which was the same technique used for checking an association in
        the standardized stacked bar plot.
      </p>

      <p>
        In the mosaic plots shown, we chose to first split by the homeowner status of the borrower. However, we could
        have instead first split by the application type. Like with the bar plots, it's common to use the explanatory
        variable to represent the first split in a mosaic plot, and then for the response to break up each level of the
        explanatory variable, if these labels are reasonable to attach to the variables under consideration.
      </p>
    </subsection>

    <!-- Subsection 2.2.5: The only pie chart you will see in this book -->
    <subsection xml:id="subsec-pie-charts">
      <title>The only pie chart you will see in this book</title>

      <p>
        A <term>pie chart</term> is shown alongside a bar plot representing the same information. Pie charts can
        be useful for giving a high-level overview to show how a set of cases break down. However, it is also
        difficult to decipher details in a pie chart. For example, it takes a couple seconds longer to recognize
        that there are more loans where the borrower has a mortgage than rent when looking at the pie chart, while
        this detail is very obvious in the bar plot. While pie charts can be useful, we prefer bar plots for their
        ease in comparing groups.
      </p>

      <figure xml:id="fig-pie-vs-bar">
        <caption>A pie chart and bar plot of homeownership</caption>
        <image source="ch_summarizing_data/figures/loan_homeownership_pie_chart/loan_homeownership_pie_chart.png" width="85%">
          <description>
            Two plots are shown side by side. The left is a pie chart divided into three slices: mortgage (blue,
            about 48%), rent (green, about 39%), and own (red, about 13%). The right is a bar plot with the same
            information showing three bars with frequencies around 3900, 4700, and 1300 respectively.
          </description>
        </image>
      </figure>
    </subsection>

    <!-- Subsection 2.2.6: Comparing numerical data across groups -->
    <subsection xml:id="subsec-comparing-across-groups">
      <title>Comparing numerical data across groups</title>

      <p>
        Some of the more interesting investigations can be considered by examining numerical data across groups. The
        methods required here aren't really new: all that's required is to make a numerical plot for each group in the
        same graph. Here two convenient methods are introduced: side-by-side box plots and hollow histograms.
      </p>

      <p>
        We will take a look again at the <c>county</c> data set and compare the median household income for counties
        that gained population from 2010 to 2017 versus counties that had no gain. While we might like to make a causal
        connection here, remember that these are observational data and so such an interpretation would be, at best,
        half-baked.
      </p>

      <p>
        There were 1,454 counties where the population increased from 2010 to 2017, and there were 1,672 counties with
        no gain (all but one were a loss). A random sample of 100 counties from the first group and 50 from the second
        group are shown in <xref ref="table-county-income-by-pop-gain"/> to give a better sense of some of the raw
        median income data.
      </p>

      <table xml:id="table-county-income-by-pop-gain">
        <title>Median Income for 150 Counties, in $1000s</title>
        <tabular>
          <row header="yes" bottom="minor">
            <cell colspan="6" halign="center">Population Gain</cell>
            <cell></cell>
            <cell colspan="3" halign="center">No Population Gain</cell>
          </row>
          <row>
            <cell>38.2</cell><cell>43.6</cell><cell>42.2</cell><cell>61.5</cell><cell>51.1</cell><cell>45.7</cell>
            <cell></cell>
            <cell>48.3</cell><cell>60.3</cell><cell>50.7</cell>
          </row>
          <row>
            <cell>44.6</cell><cell>51.8</cell><cell>40.7</cell><cell>48.1</cell><cell>56.4</cell><cell>41.9</cell>
            <cell></cell>
            <cell>39.3</cell><cell>40.4</cell><cell>40.3</cell>
          </row>
          <row>
            <cell>40.6</cell><cell>63.3</cell><cell>52.1</cell><cell>60.3</cell><cell>49.8</cell><cell>51.7</cell>
            <cell></cell>
            <cell>57.0</cell><cell>47.2</cell><cell>45.9</cell>
          </row>
          <row>
            <cell>51.1</cell><cell>34.1</cell><cell>45.5</cell><cell>52.8</cell><cell>49.1</cell><cell>51.0</cell>
            <cell></cell>
            <cell>42.3</cell><cell>41.5</cell><cell>46.1</cell>
          </row>
          <row>
            <cell>80.8</cell><cell>46.3</cell><cell>82.2</cell><cell>43.6</cell><cell>39.7</cell><cell>49.4</cell>
            <cell></cell>
            <cell>44.9</cell><cell>51.7</cell><cell>46.4</cell>
          </row>
          <row>
            <cell>75.2</cell><cell>40.6</cell><cell>46.3</cell><cell>62.4</cell><cell>44.1</cell><cell>51.3</cell>
            <cell></cell>
            <cell>29.1</cell><cell>51.8</cell><cell>50.5</cell>
          </row>
          <row>
            <cell>51.9</cell><cell>34.7</cell><cell>54.0</cell><cell>42.9</cell><cell>52.2</cell><cell>45.1</cell>
            <cell></cell>
            <cell>27.0</cell><cell>30.9</cell><cell>34.9</cell>
          </row>
          <row>
            <cell>61.0</cell><cell>51.4</cell><cell>56.5</cell><cell>62.0</cell><cell>46.0</cell><cell>46.4</cell>
            <cell></cell>
            <cell>40.7</cell><cell>51.8</cell><cell>61.1</cell>
          </row>
          <row>
            <cell>53.8</cell><cell>57.6</cell><cell>69.2</cell><cell>48.4</cell><cell>40.5</cell><cell>48.6</cell>
            <cell></cell>
            <cell>43.4</cell><cell>34.7</cell><cell>45.7</cell>
          </row>
          <row>
            <cell>53.1</cell><cell>54.6</cell><cell>55.0</cell><cell>46.4</cell><cell>39.9</cell><cell>56.7</cell>
            <cell></cell>
            <cell>33.1</cell><cell>21.0</cell><cell>37.0</cell>
          </row>
          <row>
            <cell>63.0</cell><cell>49.1</cell><cell>57.2</cell><cell>44.1</cell><cell>50.0</cell><cell>38.9</cell>
            <cell></cell>
            <cell>52.0</cell><cell>31.9</cell><cell>45.7</cell>
          </row>
          <row>
            <cell>46.6</cell><cell>46.5</cell><cell>38.9</cell><cell>50.9</cell><cell>56.0</cell><cell>34.6</cell>
            <cell></cell>
            <cell>56.3</cell><cell>38.7</cell><cell>45.7</cell>
          </row>
          <row>
            <cell>74.2</cell><cell>63.0</cell><cell>49.6</cell><cell>53.7</cell><cell>77.5</cell><cell>60.0</cell>
            <cell></cell>
            <cell>56.2</cell><cell>43.0</cell><cell>21.7</cell>
          </row>
          <row>
            <cell>63.2</cell><cell>47.6</cell><cell>55.9</cell><cell>39.1</cell><cell>57.8</cell><cell>42.6</cell>
            <cell></cell>
            <cell>44.5</cell><cell>34.5</cell><cell>48.9</cell>
          </row>
          <row>
            <cell>50.4</cell><cell>49.0</cell><cell>45.6</cell><cell>39.0</cell><cell>38.8</cell><cell>37.1</cell>
            <cell></cell>
            <cell>50.9</cell><cell>42.1</cell><cell>43.2</cell>
          </row>
          <row>
            <cell>57.2</cell><cell>44.7</cell><cell>71.7</cell><cell>35.3</cell><cell>100.2</cell><cell></cell>
            <cell></cell>
            <cell>35.4</cell><cell>41.3</cell><cell>33.6</cell>
          </row>
          <row>
            <cell>42.6</cell><cell>55.5</cell><cell>38.6</cell><cell>52.7</cell><cell>63.0</cell><cell></cell>
            <cell></cell>
            <cell>43.4</cell><cell>56.5</cell><cell></cell>
          </row>
        </tabular>
      </table>

      <p>
        The <term>side-by-side box plot</term> is a traditional tool for comparing across groups. An example is shown
        in a figure, where there are two box plots, one for each group, placed into one plotting window and drawn on
        the same scale.
      </p>

      <p>
        Another useful plotting method uses <term>hollow histograms</term> to compare numerical data across groups.
        These are just the outlines of histograms of each group put on the same plot.
      </p>

      <exercise xml:id="guided-practice-compare-income-by-pop">
        <title>Comparing income by population change</title>
        <statement>
          <p>
            Use the plots to compare the incomes for counties across the two groups. What do you notice about the
            approximate center of each group? What do you notice about the variability between groups? Is the shape
            relatively consistent between groups? How many <em>prominent</em> modes are there for each group?
          </p>
        </statement>
        <solution>
          <p>
            Answers may vary a little. The counties with population gains tend to have higher income (median of about
            $45,000) versus counties without a gain (median of about $40,000). The variability is also slightly larger
            for the population gain group. This is evident in the IQR, which is about 50% bigger in the <em>gain</em>
            group. Both distributions show slight to moderate right skew and are unimodal. There is a secondary small
            bump visible in the hollow histograms, though this is an artifact of the small sample sizes chosen for
            these examples.
          </p>
        </solution>
      </exercise>

      <exercise xml:id="guided-practice-plot-components">
        <title>Useful plot components</title>
        <statement>
          <p>
            What components of each plot do you find most useful?
          </p>
        </statement>
        <solution>
          <p>
            Answers will vary. The side-by-side box plots are especially useful for comparing centers and spreads,
            while the hollow histograms are more useful for seeing distribution shape, skew, and potential anomalies.
          </p>
        </solution>
      </exercise>
    </subsection>

  </section>

  <!-- Section 2.3: Case study: Malaria vaccine -->
  <section xml:id="sec-malaria-vaccine">
    <title>Case study: malaria vaccine</title>
    
    <example xml:id="ex-class-right-left-side-apple">
      <title>Class seating and Apple ownership</title>
      <statement>
        <p>
          Suppose your professor splits the students in class into two groups: students on the left and students on
          the right. If <m>\hat{p}_L</m> and <m>\hat{p}_R</m> represent the proportion of students who own an Apple
          product on the left and right, respectively, would you be surprised if <m>\hat{p}_L</m> did not exactly equal
          <m>\hat{p}_R</m>?
        </p>
      </statement>
      <solution>
        <p>
          While the proportions would probably be close to each other, it would be unusual for them to be exactly the
          same. We would probably observe a small difference due to chance.
        </p>
      </solution>
    </example>

    <exercise xml:id="guided-practice-apple-independence">
      <title>Independence between seating and ownership</title>
      <statement>
        <p>
          If we don't think the side of the room a person sits on in class is related to whether the person owns an
          Apple product, what assumption are we making about the relationship between these two variables?
        </p>
      </statement>
      <solution>
        <p>We would be assuming that these two variables are independent.</p>
      </solution>
    </exercise>

    <subsection xml:id="subsec-variability-within-data">
      <title>Variability within data</title>

      <p>
        We consider a study on a new malaria vaccine called PfSPZ. In this study, volunteer patients were randomized
        into one of two experiment groups: 14 patients received an experimental vaccine and 6 patients received a
        placebo vaccine. Nineteen weeks later, all 20 patients were exposed to a drug-sensitive malaria parasite
        strain; the motivation of using a drug-sensitive strain of parasite here is for ethical considerations,
        allowing any infections to be treated effectively. The results are summarized in
        <xref ref="table-malaria-vaccine-summary"/>, where 9 of the 14 treatment patients remained free of signs of
        infection while all of the 6 patients in the control group patients showed some baseline signs of infection.
      </p>

      <table xml:id="table-malaria-vaccine-summary">
        <title>Summary results for the malaria vaccine experiment</title>
        <tabular>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell colspan="2" halign="center"><c>outcome</c></cell>
            <cell>Total</cell>
          </row>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell>infection</cell>
            <cell>no infection</cell>
            <cell></cell>
          </row>
          <row>
            <cell rowspan="2" valign="middle"><c>treatment</c></cell>
            <cell>vaccine</cell>
            <cell>5</cell>
            <cell>9</cell>
            <cell>14</cell>
          </row>
          <row bottom="minor">
            <cell>placebo</cell>
            <cell>6</cell>
            <cell>0</cell>
            <cell>6</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell>Total</cell>
            <cell>11</cell>
            <cell>9</cell>
            <cell>20</cell>
          </row>
        </tabular>
      </table>

      <exercise xml:id="guided-practice-malaria-study-type">
        <title>Study design and implications</title>
        <statement>
          <p>
            Is this an observational study or an experiment? What implications does the study type have on what can be
            inferred from the results?
          </p>
        </statement>
        <solution>
          <p>
            The study is an experiment, as patients were randomly assigned an experiment group. Since this is an
            experiment, the results can be used to evaluate a causal relationship between the malaria vaccine and
            whether patients showed signs of an infection.
          </p>
        </solution>
      </exercise>

      <p>
        In this study, a smaller proportion of patients who received the vaccine showed signs of an infection (35.7%
        versus 100%). However, the sample is very small, and it is unclear whether the difference provides
        <em>convincing evidence</em> that the vaccine is effective.
      </p>

      <example xml:id="ex-malaria-vaccine-convincing">
        <title>Assessing the evidence</title>
        <statement>
          <p>
            Data scientists are sometimes called upon to evaluate the strength of evidence. When looking at the rates
            of infection for patients in the two groups in this study, what comes to mind as we try to determine
            whether the data show convincing evidence of a real difference?
          </p>
        </statement>
        <solution>
          <p>
            The observed infection rates (35.7% for the treatment group versus 100% for the control group) suggest the
            vaccine may be effective. However, we cannot be sure if the observed difference represents the vaccine's
            efficacy or is just from random chance. Generally there is a little bit of fluctuation in sample data, and
            we wouldn't expect the sample proportions to be <em>exactly</em> equal, even if the truth was that the
            infection rates were independent of getting the vaccine. Additionally, with such small samples, perhaps
            it's common to observe such large differences when we randomly split a group due to chance alone!
          </p>
        </solution>
      </example>

      <p>
        Example <xref ref="ex-malaria-vaccine-convincing"/> is a reminder that the observed outcomes in the data
        sample may not perfectly reflect the true relationships between variables since there is <term>random
        noise</term>. While the observed difference in rates of infection is large, the sample size for the study is
        small, making it unclear if this observed difference represents efficacy of the vaccine or whether it is simply
        due to chance. We label these two competing claims, <m>H_0</m> and <m>H_A</m>, which are spoken as
        "H-nought" and "H-A":
      </p>

      <p>
        <ul>
          <li>
            <p>
              <m>H_0</m>: <term>Independence model.</term> The variables <c>treatment</c> and <c>outcome</c> are
              independent. They have no relationship, and the observed difference between the proportion of patients who
              developed an infection in the two groups, 64.3%, was due to chance.
            </p>
          </li>
          <li>
            <p>
              <m>H_A</m>: <term>Alternative model.</term> The variables are <em>not</em> independent. The difference in
              infection rates of 64.3% was not due to chance, and vaccine affected the rate of infection.
            </p>
          </li>
        </ul>
      </p>

      <p>
        What would it mean if the independence model, which says the vaccine had no influence on the rate of infection,
        is true? It would mean 11 patients were going to develop an infection <em>no matter which group they were
        randomized into</em>, and 9 patients would not develop an infection <em>no matter which group they were
        randomized into</em>. That is, if the vaccine did not affect the rate of infection, the difference in the
        infection rates was due to chance alone in how the patients were randomized.
      </p>

      <p>
        Now consider the alternative model: infection rates were influenced by whether a patient received the vaccine
        or not. If this was true, and especially if this influence was substantial, we would expect to see some
        difference in the infection rates of patients in the groups.
      </p>

      <p>
        We choose between these two competing claims by assessing if the data conflict so much with <m>H_0</m> that the
        independence model cannot be deemed reasonable. If this is the case, and the data support <m>H_A</m>, then we
        will reject the notion of independence and conclude the vaccine was effective.
      </p>
    </subsection>

    <subsection xml:id="subsec-simulating-the-study">
      <title>Simulating the study</title>

      <p>
        We're going to implement <term>simulations</term>, where we will pretend we know that the malaria vaccine
        being tested does <em>not</em> work. Ultimately, we want to understand if the large difference we observed is
        common in these simulations. If it is common, then maybe the difference we observed was purely due to chance.
        If it is very uncommon, then the possibility that the vaccine was helpful seems more plausible.
      </p>

      <p>
        <xref ref="table-malaria-vaccine-summary"/> shows that 11 patients developed infections and 9 did not. For our
        simulation, we will suppose the infections were independent of the vaccine and we were able to <em>rewind</em>
        back to when the researchers randomized the patients in the study. If we happened to randomize the patients
        differently, we may get a different result in this hypothetical world where the vaccine doesn't influence the
        infection. Let's complete another <term>randomization</term> using a simulation.
      </p>

      <p>
        In this <term>simulation</term>, we take 20 notecards to represent the 20 patients, where we write down
        "infection" on 11 cards and "no infection" on 9 cards. In this hypothetical world, we believe each patient
        that got an infection was going to get it regardless of which group they were in, so let's see what happens if
        we randomly assign the patients to the treatment and control groups again. We thoroughly shuffle the notecards
        and deal 14 into a <em>vaccine</em> pile and 6 into a <em>placebo</em> pile. Finally, we tabulate the results,
        which are shown in <xref ref="table-malaria-vaccine-sim-1"/>.
      </p>

      <table xml:id="table-malaria-vaccine-sim-1">
        <title>Simulation results, where any difference in infection rates is purely due to chance</title>
        <tabular>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell colspan="2" halign="center"><c>outcome</c></cell>
            <cell>Total</cell>
          </row>
          <row header="yes" bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell>infection</cell>
            <cell>no infection</cell>
            <cell></cell>
          </row>
          <row>
            <cell rowspan="2" valign="middle">treatment (simulated)</cell>
            <cell>vaccine</cell>
            <cell>7</cell>
            <cell>7</cell>
            <cell>14</cell>
          </row>
          <row bottom="minor">
            <cell>placebo</cell>
            <cell>4</cell>
            <cell>2</cell>
            <cell>6</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell>Total</cell>
            <cell>11</cell>
            <cell>9</cell>
            <cell>20</cell>
          </row>
        </tabular>
      </table>

      <exercise xml:id="guided-practice-malaria-sim-diff">
        <title>Simulated difference</title>
        <statement>
          <p>
            What is the difference in infection rates between the two simulated groups in
            <xref ref="table-malaria-vaccine-sim-1"/>? How does this compare to the observed 64.3% difference in the
            actual data?
          </p>
        </statement>
        <solution>
          <p>
            <m>4/6 - 7/14 = 0.167</m> or about 16.7% in favor of the vaccine. This difference due to chance is much
            smaller than the difference observed in the actual groups.
          </p>
        </solution>
      </exercise>
    </subsection>

    <subsection xml:id="subsec-checking-independence">
      <title>Checking for independence</title>

      <p>
        We computed one possible difference under the independence model in Guided Practice
        <xref ref="guided-practice-malaria-sim-diff"/>, which represents one difference due to chance. While in this
        first simulation, we physically dealt out notecards to represent the patients, it is more efficient to perform
        this simulation using a computer. Repeating the simulation on a computer, we get another difference due to
        chance:
        <me>2/6 - 9/14 = -0.310</me>
        And another:
        <me>3/6 - 8/14 = -0.071</me>
        And so on until we repeat the simulation enough times that we have a good idea of what represents the
        <em>distribution of differences from chance alone</em>. <xref ref="fig-malaria-rand-dot-plot"/> shows a stacked
        plot of the differences found from 100 simulations, where each dot represents a simulated difference between
        the infection rates (control rate minus treatment rate).
      </p>

      <figure xml:id="fig-malaria-rand-dot-plot">
        <caption>Differences from 100 simulations under the independence model</caption>
        <image source="ch_summarizing_data/figures/malaria_rand_dot_plot/malaria_rand_dot_plot.png" width="85%">
          <description>
            A stacked dot plot is shown. The horizontal axis represents "difference in infection rates" and has a range
            of -0.6 to 0.8. There are six stacks of dots shown in the plot, with 3 points shown at -0.55, 20-25 points
            shown at -0.32, 30-35 points shown at -0.08, 25-30 points shown at 0.18, 10-12 points shown at 0.41, and 2
            points shown at 0.64.
          </description>
        </image>
      </figure>

      <p>
        Note that the distribution of these simulated differences is centered around 0. We simulated these differences
        assuming that the independence model was true, and under this condition, we expect the difference to be near
        zero with some random fluctuation, where <em>near</em> is pretty generous in this case since the sample sizes
        are so small in this study.
      </p>

      <example xml:id="ex-malaria-rare-event">
        <title>Rarity of the observed difference</title>
        <statement>
          <p>
            How often would you observe a difference of at least 64.3% (0.643) according to
            <xref ref="fig-malaria-rand-dot-plot"/>? Often, sometimes, rarely, or never?
          </p>
        </statement>
        <solution>
          <p>
            It appears that a difference of at least 64.3% due to chance alone would only happen about 2% of the time
            according to <xref ref="fig-malaria-rand-dot-plot"/>. Such a low probability indicates a rare event.
          </p>
        </solution>
      </example>

      <p>
        The difference of 64.3% being a rare event suggests two possible interpretations of the results of the study:
      </p>

      <p>
        <ul>
          <li>
            <p>
              <m>H_0</m>: <term>Independence model.</term> The vaccine has no effect on infection rate, and we just
              happened to observe a difference that would only occur on a rare occasion.
            </p>
          </li>
          <li>
            <p>
              <m>H_A</m>: <term>Alternative model.</term> The vaccine has an effect on infection rate, and the
              difference we observed was actually due to the vaccine being effective at combatting malaria, which
              explains the large difference of 64.3%.
            </p>
          </li>
        </ul>
      </p>

      <p>
        Based on the simulations, we have two options. (1) We conclude that the study results do not provide strong
        evidence against the independence model. That is, we do not have sufficiently strong evidence to conclude the
        vaccine had an effect in this clinical setting. (2) We conclude the evidence is sufficiently strong to reject
        <m>H_0</m> and assert that the vaccine was useful. When we conduct formal studies, usually we reject the notion
        that we just happened to observe a rare event. So in this case, we reject the independence model in favor of
        the alternative. That is, we are concluding the data provide strong evidence that the vaccine provides some
        protection against malaria in this clinical setting.
      </p>

      <p>
        One field of statistics, statistical inference, is built on evaluating whether such differences are due to
        chance. In statistical inference, data scientists evaluate which model is most reasonable given the data. Errors
        do occur, just like rare events, and we might choose the wrong model. While we do not always choose correctly,
        statistical inference gives us tools to control and evaluate how often these errors occur. In Chapter 3, we give
        a formal introduction to the problem of model selection. We spend the next two chapters building a foundation of
        probability and theory necessary to make that discussion rigorous.
      </p>
    </subsection>

    <exercises xml:id="exercises-malaria-case">
      <title>Exercises</title>

      <exercise xml:id="ex-randomization-avandia">
        <title>Side effects of Avandia</title>
        <statement>
          <p>A retrospective study compared cardiovascular problems between rosiglitazone (Avandia) and pioglitazone (Actos) users (counts below).</p>
          <table cols="4">
            <tgroup cols="4">
              <thead>
                <row>
                  <entry></entry>
                  <entry></entry>
                  <entry>Yes</entry>
                  <entry>No</entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry rowspan="2">Treatment</entry>
                  <entry>Rosiglitazone</entry>
                  <entry>2,593</entry>
                  <entry>65,000</entry>
                </row>
                <row>
                  <entry>Pioglitazone</entry>
                  <entry>5,386</entry>
                  <entry>154,592</entry>
                </row>
                <row>
                  <entry></entry>
                  <entry>Total</entry>
                  <entry>7,979</entry>
                  <entry>219,592</entry>
                </row>
              </tbody>
            </tgroup>
          </table>
          <ol marker="a.">
            <li><p>Assess true/false for four claims (rate comparisons, causation, chance).</p></li>
            <li><p>What proportion of all patients had cardiovascular problems?</p></li>
            <li><p>If treatment and outcome were independent, expected rosiglitazone problems?</p></li>
            <li><p>A randomization simulation produced a histogram of rosiglitazone problem counts. Use it to identify claims, direction supporting <m>H_A</m>, and what the simulation suggests.</p></li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-randomization-heart-transplant">
        <title>Heart transplants</title>
        <statement>
          <p>Stanford heart-transplant program: control 34 patients (30 died), treatment 69 (45 died). Plots show survival mosaic and survival-time box plots; a randomization dotplot compares differences.</p>
          <ol marker="a.">
            <li><p>From the mosaic, is survival independent of transplant? Explain.</p></li>
            <li><p>What do the box plots suggest about efficacy?</p></li>
            <li><p>Compute death proportions in treatment vs. control.</p></li>
            <li><p>Fill blanks for a card-shuffle randomization description; what do simulation results indicate about effectiveness?</p></li>
          </ol>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 2.4: Chapter review -->
  <section xml:id="sec-ch02-review">
    <title>Chapter 2 Review Exercises</title>
    
    <exercises>
      <title>Chapter Review</title>
      
      <!-- Exercise 27 -->
      <exercise xml:id="makeup_exam">
        <title>Make-up exam</title>
        <statement>
          <p>
            In a class of 25 students, 24 of them took an exam in class and 1 student took a make-up 
            exam the following day. The professor graded the first batch of 24 exams and found an average 
            score of 74 points with a standard deviation of 8.9 points. The student who took the make-up 
            the following day scored 64 points on the exam.
          </p>
          <p>
            <ol>
              <li><p>Does the new student's score increase or decrease the average score?</p></li>
              <li><p>What is the new average?</p></li>
              <li>
                <p>
                  Does the new student's score increase or decrease the standard deviation of the scores?
                </p>
              </li>
            </ol>
          </p>
        </statement>
      </exercise>
      
      <!-- Exercise 28 -->
      <exercise xml:id="infant_mortality">
        <title>Infant mortality</title>
        <statement>
          <p>
            The infant mortality rate is defined as the number of infant deaths per 1,000 live births. 
            This rate is often used as an indicator of the level of health in a country. The relative 
            frequency histogram below shows the distribution of estimated infant death rates for 224 
            countries for which such data were available in 2014.
          </p>
          <sidebyside widths="45% 50%">
            <stack>
              <p>
                <ol>
                  <li><p>Estimate Q1, the median, and Q3 from the histogram.</p></li>
                  <li>
                    <p>
                      Would you expect the mean of this data set to be smaller or larger than the median? 
                      Explain your reasoning.
                    </p>
                  </li>
                </ol>
              </p>
            </stack>
            <figure xml:id="fig-infant-mortality">
              <caption>Infant mortality rates</caption>
              <image source="ch_summarizing_data/figures/eoce/infant_mortality_rel_freq/infant_mortality_rel_freq_hist" width="85%">
                <description>A histogram is shown for the variable "Infant Mortality (per 1000 live births)" with axis range of 0 to 120. The histogram vertical axis is for "Fraction of Countries" and runs from 0 to 0.4. The bins are as follows: the 0 to 10 bin has a height of 0.38, 10 to 20 has a height of 0.22, 20 to 30 a height of 0.11, 30 to 40 a height of 0.06, 40 to 50 a height of 0.07, 50 to 60 a height of 0.08, 60 to 70 a height of 0.04, 70 to 80 a height of 0.03, 80 to 90 a height of 0.01, 90 to 100 a height of 0.02, and 100 to 110 a height of 0.01.</description>
              </image>
            </figure>
          </sidebyside>
        </statement>
      </exercise>
      
      <!-- Exercise 29 -->
      <exercise xml:id="dist_shape_TV_watchers">
        <title>TV watchers</title>
        <statement>
          <p>
            Students in an AP Statistics class were asked how many hours of television they watch per week 
            (including online streaming). This sample yielded an average of 4.71 hours, with a standard 
            deviation of 4.18 hours. Is the distribution of number of hours students watch television 
            weekly symmetric? If not, what shape would you expect this distribution to have? Explain your 
            reasoning.
          </p>
        </statement>
      </exercise>
      
      <!-- Exercise 30 -->
      <exercise xml:id="new_stat">
        <title>A new statistic</title>
        <statement>
          <p>
            The statistic <m>\frac{\bar{x}}{\text{median}}</m> can be used as a measure of skewness. 
            Suppose we have a distribution where all observations are greater than 0, <m>x_i > 0</m>. 
            What is the expected shape of the distribution under the following conditions? Explain your 
            reasoning.
          </p>
          <p>
            <ol>
              <li><p><m>\frac{\bar{x}}{\text{median}} = 1</m></p></li>
              <li><p><m>\frac{\bar{x}}{\text{median}} \lt 1</m></p></li>
              <li><p><m>\frac{\bar{x}}{\text{median}} \gt 1</m></p></li>
            </ol>
          </p>
        </statement>
      </exercise>
      
      <!-- Exercise 31 -->
      <exercise xml:id="oscar_winners">
        <title>Oscar winners</title>
        <statement>
          <p>
            The first Oscar awards for best actor and best actress were given out in 1929. The histograms 
            below show the age distribution for all of the best actor and best actress winners from 1929 
            to 2018. Summary statistics for these distributions are also provided. Compare the distributions 
            of ages of best actor and actress winners.
          </p>
          <sidebyside widths="70% 28%">
            <figure xml:id="fig-oscar-winners">
              <caption>Oscar winners by age</caption>
              <image source="ch_summarizing_data/figures/eoce/oscar_winners/oscars_winners_hist" width="95%">
                <description>Two histograms are shown, one for "Best Actress" and a second for "Best Actor", where values for the histogram range from 15 to 85. The heights of the bins for the Best Actress histogram are as follows: the bin of 15 to 25 has a height of 9, the 25 to 35 bin has a height of 50, 35 to 45 a height of 19, 45 to 55 a height of 6, 55 to 65 a height of 8, 65 to 75 a height of 1, and 75 to 85 a height of 1. The heights of the bins for the Best Actor histogram are as follows: the bin of 15 to 25 has a height of 0, the 25 to 35 bin has a height of 14, 35 to 45 a height of 45, 45 to 55 a height of 23, 55 to 65 a height of 11, 65 to 75 a height of 0, and 75 to 85 a height of 1.</description>
              </image>
            </figure>
            <tabular halign="center">
              <row bottom="major"><cell></cell><cell>Best Actress</cell></row>
              <row><cell>Mean</cell><cell>36.2</cell></row>
              <row><cell>SD</cell><cell>11.9</cell></row>
              <row bottom="minor"><cell>n</cell><cell>92</cell></row>
              <row><cell></cell><cell></cell></row>
              <row bottom="major"><cell></cell><cell>Best Actor</cell></row>
              <row><cell>Mean</cell><cell>43.8</cell></row>
              <row><cell>SD</cell><cell>8.83</cell></row>
              <row><cell>n</cell><cell>92</cell></row>
            </tabular>
          </sidebyside>
        </statement>
      </exercise>
      
      <!-- Exercise 32 -->
      <exercise xml:id="dist_shape_exam_scores">
        <title>Exam scores</title>
        <statement>
          <p>
            The average on a history exam (scored out of 100 points) was 85, with a standard deviation 
            of 15. Is the distribution of the scores on this exam symmetric? If not, what shape would 
            you expect this distribution to have? Explain your reasoning.
          </p>
        </statement>
      </exercise>
      
      <!-- Exercise 33 -->
      <exercise xml:id="stats_scores_box">
        <title>Stats scores</title>
        <statement>
          <p>
            Below are the final exam scores of twenty introductory statistics students.
          </p>
          <p>
            57, 66, 69, 71, 72, 73, 74, 77, 78, 78, 79, 79, 81, 81, 82, 83, 83, 88, 89, 94
          </p>
          <p>
            Create a box plot of the distribution of these scores. The five number summary provided 
            below may be useful.
          </p>
          <tabular halign="center">
            <row bottom="major">
              <cell>Min</cell>
              <cell>Q1</cell>
              <cell>Q2 (Median)</cell>
              <cell>Q3</cell>
              <cell>Max</cell>
            </row>
            <row>
              <cell>57</cell>
              <cell>72.5</cell>
              <cell>78.5</cell>
              <cell>82.5</cell>
              <cell>94</cell>
            </row>
          </tabular>
        </statement>
      </exercise>
      
      <!-- Exercise 34 -->
      <exercise xml:id="marathon_winners">
        <title>Marathon winners</title>
        <statement>
          <p>
            The histogram and box plots below show the distribution of finishing times in hours for 
            male and female winners of the New York Marathon between 1970 and 1999.
          </p>
          <figure xml:id="fig-marathon-winners-hist">
            <caption>Marathon finishing times histogram and box plot</caption>
            <image source="ch_summarizing_data/figures/eoce/marathon_winners/marathon_winners_hist_box" width="56%">
              <description>Two plots are shown, one that is a histogram and one that is a box plot, where the range of data for each is from 2.0 to 3.2. The bins for the histogram are as follows: the 2.0 to 2.2 bin has a height of 21, bin 2.2 to 2.4 a height of 6, 2.4 to 2.6 a height of 25, 2.6 to 2.8 a height of 3, 2.8 to 3.0 a height of 2, and 3.0 to 3.2 a height of 2. The box plot shows the box spanning 2.2 to 2.5, with the median line centered at 2.4. The whiskers extend from about 2.15 to 2.75. There are four points marked beyond the upper whisker at 2.9, 3.0, 3.10, and 3.15.</description>
            </image>
          </figure>
          <p>
            <ol>
              <li>
                <p>
                  What features of the distribution are apparent in the histogram and not the box plot? 
                  What features are apparent in the box plot but not in the histogram?
                </p>
              </li>
              <li><p>What may be the reason for the bimodal distribution? Explain.</p></li>
              <li>
                <p>
                  Compare the distribution of marathon times for men and women based on the box plot 
                  shown below.
                </p>
                <figure xml:id="fig-marathon-winners-gender">
                  <caption>Marathon times by gender</caption>
                  <image source="ch_summarizing_data/figures/eoce/marathon_winners/marathon_winners_gender_box" width="56%">
                    <description>A side-by-side box plot is shown for marathon run times, one box plot for men and one for women. The axis for the run times spans from 2.0 to 3.2. All values described as follows are estimates. For the men box plot, the box spans 2.16 to 2.22 with the median line at 2.19. The whiskers span to 2.12 up to 2.27. There are 6 points above the upper whisker at 2.32, 2.36, 2.38, 2.44, 2.46, and 2.50. For the women box plot, the box spans from 2.44 to 2.52, with a median value of 2.46. The whiskers span from 2.41 to 2.57. There are 6 points above the upper whisker: 2.72, 2.78, 2.9, 2.92, 3.12, and 3.15.</description>
                  </image>
                </figure>
              </li>
              <li>
                <p>
                  The time series plot shown below is another way to look at these data. Describe what 
                  is visible in this plot but not in the others.
                </p>
                <figure xml:id="fig-marathon-winners-time">
                  <caption>Marathon times over time</caption>
                  <image source="ch_summarizing_data/figures/eoce/marathon_winners/marathon_winners_time_series" width="60%">
                    <description>A time series plot is shown, which in this case gives the appearance of a scatterplot. The horizontal variable is for year, which runs from 1970 to 2000, and the vertical variable is "Marathon times", which runs from 2.0 to 3.2 hours. There are two colors of points, one for men and one for women, and there is one point for men and one for women for each year. The points start at about 2.5 for men in 1970 and 2.9 for women in 1971. The points bounce around for a few years and then decline in 1975 or 1976 to 2.2 for men and 2.7 for women. The values for women decrease for a few more years to about 2.5. For the remainder of the years, the values fluctuate up or down 0.1 hours from year to year but are stable until 1999, which is the last year of data provided.</description>
                  </image>
                </figure>
              </li>
            </ol>
          </p>
        </statement>
      </exercise>
      
    </exercises>
  </section>

</chapter>
