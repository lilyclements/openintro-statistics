<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="ch-inference-for-props" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Inference for Categorical Data</title>
  
  <introduction>
    <p>
      In this chapter, we apply the methods and ideas from Chapter 5 in several contexts for
      categorical data. We'll start by revisiting what we learned for a single proportion, where
      the normal distribution can be used to model the uncertainty in the sample proportion. Next,
      we apply these same ideas to analyze the difference of two proportions using the normal model.
      Later in the chapter, we apply inference techniques to contingency tables; while we will use
      a different distribution in this context, the core ideas of hypothesis testing remain the same.
    </p>
  </introduction>
  
  <!-- Section 6.1: Inference for a single proportion -->
  <section xml:id="singleProportion">
    <title>Inference for a single proportion</title>
    
    <introduction>
      <p>
        We encountered inference methods for a single proportion in Chapter<nbsp/>5, exploring point estimates, confidence intervals, and hypothesis tests. In this section, we'll do a review of these topics and also how to choose an appropriate sample size when collecting data for single proportion contexts.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-sample-prop-normal">
      <title>Identifying when the sample proportion is nearly normal</title>
      
      <p>
        A sample proportion <m>\hat{p}</m> can be modeled using a normal distribution when the sample observations are independent and the sample size is sufficiently large.
      </p>
      
      <assemblage xml:id="assem-sampling-dist-p-hat">
        <title>Sampling distribution of <m>\hat{p}</m></title>
        <p>
          The sampling distribution for <m>\hat{p}</m> based on a sample of size <m>n</m> from a population with a true proportion <m>p</m> is nearly normal when:
        </p>
        <ol>
          <li>The sample's observations are independent, e.g. are from a simple random sample.</li>
          <li>We expected to see at least 10 successes and 10 failures in the sample, i.e. <m>np \geq 10</m> and <m>n(1-p) \geq 10</m>. This is called the <term>success-failure condition</term>.</li>
        </ol>
        <p>
          When these conditions are met, then the sampling distribution of <m>\hat{p}</m> is nearly normal with mean <m>p</m> and standard error <m>SE = \sqrt{\frac{p(1-p)}{n}}</m>.
        </p>
      </assemblage>
      
      <p>
        Typically we don't know the true proportion <m>p</m>, so we substitute some value to check conditions and estimate the standard error. For confidence intervals, the sample proportion <m>\hat{p}</m> is used to check the success-failure condition and compute the standard error. For hypothesis tests, typically the null value<mdash/>that is, the proportion claimed in the null hypothesis<mdash/>is used in place of <m>p</m>.
      </p>
    </subsection>
    
    <subsection xml:id="confIntForPropSection">
      <title>Confidence intervals for a proportion</title>
      
      <p>
        A confidence interval provides a range of plausible values for the parameter <m>p</m>, and when <m>\hat{p}</m> can be modeled using a normal distribution, the confidence interval for <m>p</m> takes the form
      </p>
      <me>
        \hat{p} \pm z^{\star} \times SE
      </me>
      
      <example xml:id="ex-payday-normal-check">
        <statement>
          <p>
            A simple random sample of 826 payday loan borrowers was surveyed to better understand their interests around regulation and costs. 70% of the responses supported new regulations on payday lenders. Is it reasonable to model <m>\hat{p} = 0.70</m> using a normal distribution?
          </p>
        </statement>
        <solution>
          <p>
            The data are a random sample, so the observations are independent and representative of the population of interest.
          </p>
          <p>
            We also must check the success-failure condition, which we do using <m>\hat{p}</m> in place of <m>p</m> when computing a confidence interval:
          </p>
          <md>
            <mrow>\text{Support: } n p \amp \approx 826 \times 0.70 = 578</mrow>
            <mrow>\text{Not: } n (1 - p) \amp \approx 826 \times (1 - 0.70) = 248</mrow>
          </md>
          <p>
            Since both values are at least 10, we can use the normal distribution to model <m>\hat{p}</m>.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="seOfPropOfPDBorrowersSupportReg">
        <statement>
          <p>
            Estimate the standard error of <m>\hat{p} = 0.70</m>. Because <m>p</m> is unknown and the standard error is for a confidence interval, use <m>\hat{p}</m> in place of <m>p</m> in the formula.
          </p>
        </statement>
        <solution>
          <p>
            <m>SE = \sqrt{\frac{p(1-p)}{n}} \approx \sqrt{\frac{0.70 (1 - 0.70)}{826}} = 0.016</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-payday-ci">
        <statement>
          <p>
            Construct a 95% confidence interval for <m>p</m>, the proportion of payday borrowers who support increased regulation for payday lenders.
          </p>
        </statement>
        <solution>
          <p>
            Using the point estimate 0.70, <m>z^{\star} = 1.96</m> for a 95% confidence interval, and the standard error <m>SE = 0.016</m> from Guided Practice<nbsp/><xref ref="seOfPropOfPDBorrowersSupportReg"/>, the confidence interval is
          </p>
          <md>
            <mrow>\text{point estimate} \pm z^{\star} \times SE \amp \to 0.70 \pm 1.96 \times 0.016</mrow>
            <mrow>\amp \to (0.669, 0.731)</mrow>
          </md>
          <p>
            We are 95% confident that the true proportion of payday borrowers who supported regulation at the time of the poll was between 0.669 and 0.731.
          </p>
        </solution>
      </example>
      
      <assemblage xml:id="assem-ci-single-proportion">
        <title>Confidence interval for a single proportion</title>
        <p>
          Once you've determined a one-proportion confidence interval would be helpful for an application, there are four steps to constructing the interval:
        </p>
        <ol>
          <li><strong>Prepare:</strong> Identify <m>\hat{p}</m> and <m>n</m>, and determine what confidence level you wish to use.</li>
          <li><strong>Check:</strong> Verify the conditions to ensure <m>\hat{p}</m> is nearly normal. For one-proportion confidence intervals, use <m>\hat{p}</m> in place of <m>p</m> to check the success-failure condition.</li>
          <li><strong>Calculate:</strong> If the conditions hold, compute <m>SE</m> using <m>\hat{p}</m>, find <m>z^{\star}</m>, and construct the interval.</li>
          <li><strong>Conclude:</strong> Interpret the confidence interval in the context of the problem.</li>
        </ol>
      </assemblage>
      
      <p>
        For additional one-proportion confidence interval examples, see Section<nbsp/>5.2.
      </p>
    </subsection>
    
    <subsection xml:id="htForPropSection">
      <title>Hypothesis testing for a proportion</title>
      
      <p>
        One possible regulation for payday lenders is that they would be required to do a credit check and evaluate debt payments against the borrower's finances. We would like to know: would borrowers support this form of regulation?
      </p>
      
      <exercise xml:id="paydayCC_hypotheses_gp">
        <statement>
          <p>
            Set up hypotheses to evaluate whether borrowers have a majority support or majority opposition for this type of regulation.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: <m>p = 0.50</m>. <m>H_A</m>: <m>p \neq 0.50</m>.
          </p>
        </solution>
      </exercise>
      
      <p>
        To apply the normal distribution framework in the context of a hypothesis test for a proportion, the independence and success-failure conditions must be satisfied. In a hypothesis test, the success-failure condition is checked using the null proportion: we verify <m>np_0</m> and <m>n(1-p_0)</m> are at least 10, where <m>p_0</m> is the null value.
      </p>
      
      <exercise xml:id="paydayCC_conditions_gp">
        <statement>
          <p>
            Do payday loan borrowers support a regulation that would require lenders to pull their credit report and evaluate their debt payments? From a random sample of 826 borrowers, 51% said they would support such a regulation. Is it reasonable to model <m>\hat{p} = 0.51</m> using a normal distribution for a hypothesis test here?
          </p>
        </statement>
        <solution>
          <p>
            Independence holds since the poll is based on a random sample. The success-failure condition also holds, which is checked using the null value (<m>p_0 = 0.5</m>) from <m>H_0</m>: <m>np_0 = 826 \times 0.5 = 413</m>, <m>n(1 - p_0) = 826 \times 0.5 = 413</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-payday-ht">
        <statement>
          <p>
            Using the hypotheses and data from Guided Practice<nbsp/><xref ref="paydayCC_hypotheses_gp"/> and<nbsp/><xref ref="paydayCC_conditions_gp"/>, evaluate whether the poll provides convincing evidence that a majority of payday loan borrowers support a new regulation that would require lenders to pull credit reports and evaluate debt payments.
          </p>
        </statement>
        <solution>
          <p>
            With hypotheses already set up and conditions checked, we can move onto calculations. The standard error in the context of a one-proportion hypothesis test is computed using the null value, <m>p_0</m>:
          </p>
          <me>
            SE = \sqrt{\frac{p_0 (1 - p_0)}{n}} = \sqrt{\frac{0.5 (1 - 0.5)}{826}} = 0.017
          </me>
          <p>
            A picture of the normal model is shown below with the p-value represented by the shaded region.
          </p>
          <figure xml:id="fig-paydayCC-norm-pvalue">
            <caption>A normal distribution is shown with a center of 0.5 and a standard deviation of 0.017. Two tails are shaded: The region above 0.51 and a region in the corresponding lower tail. Visually, it looks like a little over half of the area under the normal curve is shaded.</caption>
            <image source="ch_inference_for_props/paydayCC_norm_pvalue.png" width="50%"/>
          </figure>
          <p>
            Based on the normal model, the test statistic can be computed as the Z-score of the point estimate:
          </p>
          <me>
            Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.51 - 0.50}{0.017} = 0.59
          </me>
          <p>
            The single tail area is 0.2776, and the p-value, represented by both tail areas together, is 0.5552. Because the p-value is larger than 0.05, we do not reject <m>H_0</m>. The poll does not provide convincing evidence that a majority of payday loan borrowers support or oppose regulations around credit checks and evaluation of debt payments.
          </p>
        </solution>
      </example>
      
      <assemblage xml:id="assem-ht-single-proportion">
        <title>Hypothesis testing for a single proportion</title>
        <p>
          Once you've determined a one-proportion hypothesis test is the correct procedure, there are four steps to completing the test:
        </p>
        <ol>
          <li><strong>Prepare:</strong> Identify the parameter of interest, list hypotheses, identify the significance level, and identify <m>\hat{p}</m> and <m>n</m>.</li>
          <li><strong>Check:</strong> Verify conditions to ensure <m>\hat{p}</m> is nearly normal under <m>H_0</m>. For one-proportion hypothesis tests, use the null value to check the success-failure condition.</li>
          <li><strong>Calculate:</strong> If the conditions hold, compute the standard error, again using <m>p_0</m>, compute the Z-score, and identify the p-value.</li>
          <li><strong>Conclude:</strong> Evaluate the hypothesis test by comparing the p-value to <m>\alpha</m>, and provide a conclusion in the context of the problem.</li>
        </ol>
      </assemblage>
      
      <p>
        For additional one-proportion hypothesis test examples, see Section<nbsp/>5.3.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-conditions-not-met">
      <title>When one or more conditions aren't met</title>
      
      <p>
        We've spent a lot of time discussing conditions for when <m>\hat{p}</m> can be reasonably modeled by a normal distribution. What happens when the success-failure condition fails? What about when the independence condition fails? In either case, the general ideas of confidence intervals and hypothesis tests remain the same, but the strategy or technique used to generate the interval or p-value change.
      </p>
      <p>
        When the success-failure condition isn't met for a hypothesis test, we can simulate the null distribution of <m>\hat{p}</m> using the null value, <m>p_0</m>. The simulation concept is similar to the ideas used in the malaria case study presented in Section<nbsp/>5.1, and an online section outlines this strategy: <url href="http://www.openintro.org/r?go=stat_sim_prop_ht">www.openintro.org/r?go=stat_sim_prop_ht</url>
      </p>
      <p>
        For a confidence interval when the success-failure condition isn't met, we can use what's called the <term>Clopper-Pearson interval</term>. The details are beyond the scope of this book. However, there are many internet resources covering this topic.
      </p>
      <p>
        The independence condition is a more nuanced requirement. When it isn't met, it is important to understand how and why it isn't met. For example, if we took a cluster sample (see Section<nbsp/>1.3), suitable statistical methods are available but would be beyond the scope of even most second or third courses in statistics. On the other hand, we'd be stretched to find any method that we could confidently apply to correct the inherent biases of data from a convenience sample.
      </p>
      <p>
        While this book is scoped to well-constrained statistical problems, do remember that this is just the first book in what is a large library of statistical methods that are suitable for a very wide range of data and contexts.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-choosing-sample-size">
      <title>Choosing a sample size when estimating a proportion</title>
      
      <p>
        When collecting data, we choose a sample size suitable for the purpose of the study. Often times this means choosing a sample size large enough that the <term>margin of error</term><mdash/>which is the part we add and subtract from the point estimate in a confidence interval<mdash/>is sufficiently small that the sample is useful. For example, our task might be to find a sample size <m>n</m> so that the sample proportion is within <m>\pm 0.04</m> of the actual proportion in a 95% confidence interval.
      </p>
      
      <example xml:id="ex-football-stadium-sample-size">
        <statement>
          <p>
            A university newspaper is conducting a survey to determine what fraction of students support a $200 per year increase in fees to pay for a new football stadium. How big of a sample is required to ensure the margin of error is smaller than 0.04 using a 95% confidence level?
          </p>
        </statement>
        <solution>
          <p>
            The margin of error for a sample proportion is
          </p>
          <me>
            z^{\star} \sqrt{\frac{p (1 - p)}{n}}
          </me>
          <p>
            Our goal is to find the smallest sample size <m>n</m> so that this margin of error is smaller than 0.04. For a 95% confidence level, the value <m>z^{\star}</m> corresponds to 1.96:
          </p>
          <me>
            1.96\times \sqrt{\frac{p(1-p)}{n}} \ \lt \ 0.04
          </me>
          <p>
            There are two unknowns in the equation: <m>p</m> and <m>n</m>. If we have an estimate of <m>p</m>, perhaps from a prior survey, we could enter in that value and solve for <m>n</m>. If we have no such estimate, we must use some other value for <m>p</m>. It turns out that the margin of error is largest when <m>p</m> is 0.5, so we typically use this <em>worst case value</em> if no estimate of the proportion is available:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{0.5(1-0.5)}{n}} \amp \ \lt \ 0.04</mrow>
            <mrow>1.96^2\times \frac{0.5(1-0.5)}{n} \amp \ \lt \ 0.04^2</mrow>
            <mrow>1.96^2\times \frac{0.5(1-0.5)}{0.04^2} \amp \ \lt \ n</mrow>
            <mrow>600.25 \amp \ \lt \ n</mrow>
          </md>
          <p>
            We would need over 600.25 participants, which means we need 601 participants or more, to ensure the sample proportion is within 0.04 of the true proportion with 95% confidence.
          </p>
        </solution>
      </example>
      
      <p>
        When an estimate of the proportion is available, we use it in place of the worst case proportion value, 0.5.
      </p>
      
      <exercise xml:id="tire_failure_rate_3_samp_size_calc">
        <statement>
          <p>
            A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate what proportion of these tires will be rejected through quality control. The quality control team has monitored the last three tire models produced by the factory, failing 1.7% of tires in the first model, 6.2% of the second model, and 1.3% of the third model. The manager would like to examine enough tires to estimate the failure rate of the new tire model to within about 1% with a 90% confidence level. There are three different failure rates to choose from. Perform the sample size computation for each separately, and identify three sample sizes to consider.
          </p>
        </statement>
        <solution>
          <p>
            For a 90% confidence interval, <m>z^{\star} = 1.6449</m>, and since an estimate of the proportion 0.017 is available, we'll use it in the margin of error formula:
          </p>
          <md>
            <mrow>1.6449\times \sqrt{\frac{0.017(1-0.017)}{n}} \amp \ \lt \ 0.01</mrow>
            <mrow>\frac{0.017(1-0.017)}{n} \amp \ \lt \ \left(\frac{0.01}{1.6449}\right)^2</mrow>
            <mrow>452.15 \amp \ \lt \ n</mrow>
          </md>
          <p>
            For sample size calculations, we always round up, so the first tire model suggests 453 tires would be sufficient.
          </p>
          <p>
            A similar computation can be accomplished using 0.062 and 0.013 for <m>p</m>, and you should verify that using these proportions results in minimum sample sizes of 1574 and 348 tires, respectively.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-tire-failure-choice">
        <statement>
          <p>
            The sample sizes vary widely in Guided Practice<nbsp/><xref ref="tire_failure_rate_3_samp_size_calc"/>. Which of the three would you suggest using? What would influence your choice?
          </p>
        </statement>
        <solution>
          <p>
            We could examine which of the old models is most like the new model, then choose the corresponding sample size. Or if two of the previous estimates are based on small samples while the other is based on a larger sample, we might consider the value corresponding to the larger sample. There are also other reasonable approaches.
          </p>
          <p>
            Also observe that the success-failure condition would need to be checked in the final sample. For instance, if we sampled <m>n = 1584</m> tires and found a failure rate of 0.5%, the normal approximation would not be reasonable, and we would require more advanced statistical methods for creating the confidence interval.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-payday-monthly-poll">
        <statement>
          <p>
            Suppose we want to continually track the support of payday borrowers for regulation on lenders, where we would conduct a new poll every month. Running such frequent polls is expensive, so we decide a wider margin of error of 5% for each individual survey would be acceptable. Based on the original sample of borrowers where 70% supported some form of regulation, how big should our monthly sample be for a margin of error of 0.05 with 95% confidence?
          </p>
        </statement>
        <solution>
          <p>
            We complete the same computations as before, except now we use 0.70 instead of 0.5 for <m>p</m>:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{p(1-p)}{n}} \amp \approx 1.96\times \sqrt{\frac{0.70(1-0.70)}{n}} \leq 0.05</mrow>
            <mrow>n \amp \geq 322.7</mrow>
          </md>
          <p>
            A sample size of 323 or more would be reasonable. (Reminder: always round up for sample size calculations!) Given that we plan to track this poll over time, we also may want to periodically repeat these calculations to ensure that we're being thoughtful in our sample size recommendations in case the baseline rate fluctuates.
          </p>
        </solution>
      </exercise>
    </subsection>
    
    <exercises>
      <title>Section 6.1 Exercises</title>
      
      <exercise xml:id="veg_coll_students_CLT">
        <title>Vegetarian college students</title>
        <statement>
          <p>
            Suppose that 8% of college students are vegetarians. Determine if the following statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>The distribution of the sample proportions of vegetarians in random samples of size 60 is approximately normal since <m>n \geq 30</m>.</li>
            <li>The distribution of the sample proportions of vegetarian college students in random samples of size 50 is right skewed.</li>
            <li>A random sample of 125 college students where 12% are vegetarians would be considered unusual.</li>
            <li>A random sample of 250 college students where 12% are vegetarians would be considered unusual.</li>
            <li>The standard error would be reduced by one-half if we increased the sample size from 125 to 250.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="young_americans_CLT_1">
        <title>Young Americans, Part I</title>
        <statement>
          <p>
            About 77% of young adults think they can achieve the American dream. Determine if the following statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>The distribution of sample proportions of young Americans who think they can achieve the American dream in samples of size 20 is left skewed.</li>
            <li>The distribution of sample proportions of young Americans who think they can achieve the American dream in random samples of size 40 is approximately normal since <m>n \geq 30</m>.</li>
            <li>A random sample of 60 young Americans where 85% think they can achieve the American dream would be considered unusual.</li>
            <li>A random sample of 120 young Americans where 85% think they can achieve the American dream would be considered unusual.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="orange_tabbies_CLT">
        <title>Orange tabbies</title>
        <statement>
          <p>
            Suppose that 90% of orange tabby cats are male. Determine if the following statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>The distribution of sample proportions of random samples of size 30 is left skewed.</li>
            <li>Using a sample size that is 4 times as large will reduce the standard error of the sample proportion by one-half.</li>
            <li>The distribution of sample proportions of random samples of size 140 is approximately normal.</li>
            <li>The distribution of sample proportions of random samples of size 280 is approximately normal.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="young_americans_CLT_2">
        <title>Young Americans, Part II</title>
        <statement>
          <p>
            About 25% of young Americans have delayed starting a family due to the continued economic slump. Determine if the following statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>The distribution of sample proportions of young Americans who have delayed starting a family due to the continued economic slump in random samples of size 12 is right skewed.</li>
            <li>In order for the distribution of sample proportions of young Americans who have delayed starting a family due to the continued economic slump to be approximately normal, we need random samples where the sample size is at least 40.</li>
            <li>A random sample of 50 young Americans where 20% have delayed starting a family due to the continued economic slump would be considered unusual.</li>
            <li>A random sample of 150 young Americans where 20% have delayed starting a family due to the continued economic slump would be considered unusual.</li>
            <li>Tripling the sample size will reduce the standard error of the sample proportion by one-third.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="gender_equality">
        <title>Gender equality</title>
        <statement>
          <p>
            The General Social Survey asked a random sample of 1,390 Americans the following question: "On the whole, do you think it should or should not be the government's responsibility to promote equality between men and women?" 82% of the respondents said it "should be". At a 95% confidence level, this sample has 2% margin of error. Based on this information, determine if the following statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>We are 95% confident that between 80% and 84% of Americans in this sample think it's the government's responsibility to promote equality between men and women.</li>
            <li>We are 95% confident that between 80% and 84% of all Americans think it's the government's responsibility to promote equality between men and women.</li>
            <li>If we considered many random samples of 1,390 Americans, and we calculated 95% confidence intervals for each, 95% of these intervals would include the true population proportion of Americans who think it's the government's responsibility to promote equality between men and women.</li>
            <li>In order to decrease the margin of error to 1%, we would need to quadruple (multiply by 4) the sample size.</li>
            <li>Based on this confidence interval, there is sufficient evidence to conclude that a majority of Americans think it's the government's responsibility to promote equality between men and women.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="elderly_drivers_CI_concept">
        <title>Elderly drivers</title>
        <statement>
          <p>
            The Marist Poll published a report stating that 66% of adults nationally think licensed drivers should be required to retake their road test once they reach 65 years of age. It was also reported that interviews were conducted on 1,018 American adults, and that the margin of error was 3% using a 95% confidence level.
          </p>
          <ol>
            <li>Verify the margin of error reported by The Marist Poll.</li>
            <li>Based on a 95% confidence interval, does the poll provide convincing evidence that <em>more than</em> 70% of the population think that licensed drivers should be required to retake their road test once they turn 65?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="fireworks_CI_concept">
        <title>Fireworks on July <m>4^\text{th}</m></title>
        <statement>
          <p>
            A local news outlet reported that 56% of 600 randomly sampled Kansas residents planned to set off fireworks on July <m>4^\text{th}</m>. Determine the margin of error for the 56% point estimate using a 95% confidence level.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="greece_life_rating_CI">
        <title>Life rating in Greece</title>
        <statement>
          <p>
            Greece has faced a severe economic crisis since the end of 2009. A Gallup poll surveyed 1,000 randomly sampled Greeks in 2011 and found that 25% of them said they would rate their lives poorly enough to be considered "suffering".
          </p>
          <ol>
            <li>Describe the population parameter of interest. What is the value of the point estimate of this parameter?</li>
            <li>Check if the conditions required for constructing a confidence interval based on these data are met.</li>
            <li>Construct a 95% confidence interval for the proportion of Greeks who are "suffering".</li>
            <li>Without doing any calculations, describe what would happen to the confidence interval if we decided to use a higher confidence level.</li>
            <li>Without doing any calculations, describe what would happen to the confidence interval if we used a larger sample.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="study_abroad_CI_decision">
        <title>Study abroad</title>
        <statement>
          <p>
            A survey on 1,509 high school seniors who took the SAT and who completed an optional web survey shows that 55% of high school seniors are fairly certain that they will participate in a study abroad program in college.
          </p>
          <ol>
            <li>Is this sample a representative sample from the population of all high school seniors in the US? Explain your reasoning.</li>
            <li>Let's suppose the conditions for inference are met. Even if your answer to part (a) indicated that this approach would not be reliable, this analysis may still be interesting to carry out (though not report). Construct a 90% confidence interval for the proportion of high school seniors (of those who took the SAT) who are fairly certain they will participate in a study abroad program in college, and interpret this interval in context.</li>
            <li>What does "90% confidence" mean?</li>
            <li>Based on this interval, would it be appropriate to claim that the majority of high school seniors are fairly certain that they will participate in a study abroad program in college?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="legalize_marijuana_CI_decision">
        <title>Legalization of marijuana, Part I</title>
        <statement>
          <p>
            The General Social Survey asked 1,578 US residents: "Do you think the use of marijuana should be made legal, or not?" 61% of the respondents said it should be made legal.
          </p>
          <ol>
            <li>Is 61% a sample statistic or a population parameter? Explain.</li>
            <li>Construct a 95% confidence interval for the proportion of US residents who think marijuana should be made legal, and interpret it in the context of the data.</li>
            <li>A critic points out that this 95% confidence interval is only accurate if the statistic follows a normal distribution, or if the normal model is a good approximation. Is this true for these data? Explain.</li>
            <li>A news piece on this survey's findings states, "Majority of Americans think marijuana should be legalized." Based on your confidence interval, is this news piece's statement justified?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="national_health_plan_HT">
        <title>National Health Plan, Part I</title>
        <statement>
          <p>
            A <em>Kaiser Family Foundation</em> poll for US adults in 2019 found that 79% of Democrats, 55% of Independents, and 24% of Republicans supported a generic "National Health Plan". There were 347 Democrats, 298 Republicans, and 617 Independents surveyed.
          </p>
          <ol>
            <li>A political pundit on TV claims that a majority of Independents support a National Health Plan. Do these data provide strong evidence to support this type of statement?</li>
            <li>Would you expect a confidence interval for the proportion of Independents who oppose the public option plan to include 0.5? Explain.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="college_worth_it_HT_CI">
        <title>Is college worth it? Part I</title>
        <statement>
          <p>
            Among a simple random sample of 331 American adults who do not have a four-year college degree and are not currently enrolled in school, 48% said they decided not to go to college because they could not afford school.
          </p>
          <ol>
            <li>A newspaper article states that only a minority of the Americans who decide not to go to college do so because they cannot afford it and uses the point estimate from this survey as evidence. Conduct a hypothesis test to determine if these data provide strong evidence supporting this statement.</li>
            <li>Would you expect a confidence interval for the proportion of American adults who decide not to go to college because they cannot afford it to include 0.5? Explain.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="taste_test_HT_2_sided">
        <title>Taste test</title>
        <statement>
          <p>
            Some people claim that they can tell the difference between a diet soda and a regular soda in the first sip. A researcher wanting to test this claim randomly sampled 80 such people. He then filled 80 plain white cups with soda, half diet and half regular through random assignment, and asked each person to take one sip from their cup and identify the soda as diet or regular. 53 participants correctly identified the soda.
          </p>
          <ol>
            <li>Do these data provide strong evidence that these people are any better or worse than random guessing at telling the difference between diet and regular soda?</li>
            <li>Interpret the p-value in this context.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="college_worth_it_CI_sample_size">
        <title>Is college worth it? Part II</title>
        <statement>
          <p>
            Exercise <xref ref="college_worth_it_HT_CI"/> presents the results of a poll where 48% of 331 Americans who decide to not go to college do so because they cannot afford it.
          </p>
          <ol>
            <li>Calculate a 90% confidence interval for the proportion of Americans who decide to not go to college because they cannot afford it, and interpret the interval in context.</li>
            <li>Suppose we wanted the margin of error for the 90% confidence level to be about 1.5%. How large of a survey would you recommend?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="national_health_plan_CI_sample_size_replaced">
        <title>National Health Plan, Part II</title>
        <statement>
          <p>
            Exercise <xref ref="national_health_plan_HT"/> presents the results of a poll evaluating support for a generic "National Health Plan" in the US in 2019, reporting that 55% of Independents are supportive. If we wanted to estimate this number to within 1% with 90% confidence, what would be an appropriate sample size?
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="legalize_marijuana_CI_sample_size">
        <title>Legalize Marijuana, Part II</title>
        <statement>
          <p>
            As discussed in Exercise <xref ref="legalize_marijuana_CI_decision"/>, the General Social Survey reported a sample where about 61% of US residents thought marijuana should be made legal. If we wanted to limit the margin of error of a 95% confidence interval to 2%, about how many Americans would we need to survey?
          </p>
        </statement>
      </exercise>
    </exercises>
    
  </section>
  
  <!-- Section 7.2: Difference of two proportions -->
  <section xml:id="differenceOfTwoProportions">
    <title>Difference of two proportions</title>
    
    <introduction>
      <p>
        We would like to extend the methods from Section<nbsp/><xref ref="singleProportion"/> to apply confidence intervals and hypothesis tests to differences in population proportions: <m>p_1 - p_2</m>. In our investigations, we'll identify a reasonable point estimate of <m>p_1 - p_2</m> based on the sample, and you may have already guessed its form: <m>\hat{p}_1 - \hat{p}_2</m>. Next, we'll apply the same processes we used in the single-proportion context: we verify that the point estimate can be modeled using a normal distribution, we compute the estimate's standard error, and we apply our inferential framework.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-sampling-dist-diff-two-props">
      <title>Sampling distribution of the difference of two proportions</title>
      
      <p>
        Like with <m>\hat{p}</m>, the difference of two sample proportions <m>\hat{p}_1 - \hat{p}_2</m> can be modeled using a normal distribution when certain conditions are met. First, we require a broader independence condition, and secondly, the success-failure condition must be met by both groups.
      </p>
      
      <assemblage xml:id="assem-sampling-dist-p1-p2">
        <title>Conditions for the sampling distribution of <m>\hat{p}_1 - \hat{p}_2</m> to be normal</title>
        <p>
          The difference <m>\hat{p}_1 - \hat{p}_2</m> can be modeled using a normal distribution when
        </p>
        <ul>
          <li>
            <em>Independence, extended.</em> The data are independent within and between the two groups. Generally this is satisfied if the data come from two independent random samples or if the data come from a randomized experiment.
          </li>
          <li>
            <em>Success-failure condition.</em> The success-failure condition holds for both groups, where we check successes and failures in each group separately.
          </li>
        </ul>
        <p>
          When these conditions are satisfied, the standard error of <m>\hat{p}_1 - \hat{p}_2</m> is
        </p>
        <me>
          SE = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
        </me>
        <p>
          where <m>p_1</m> and <m>p_2</m> represent the population proportions, and <m>n_1</m> and <m>n_2</m> represent the sample sizes.
        </p>
      </assemblage>
    </subsection>
    
    <subsection xml:id="confIntForPropDiffSection">
      <title>Confidence intervals for <m>p_1 - p_2</m></title>
      
      <p>
        We can apply the generic confidence interval formula for a difference of two proportions, where we use <m>\hat{p}_1 - \hat{p}_2</m> as the point estimate and substitute the <m>SE</m> formula:
      </p>
      <md>
        <mrow>\text{point estimate} \pm z^{\star} \times SE \amp \to \hat{p}_1 - \hat{p}_2 \pm z^{\star} \times \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}</mrow>
      </md>
      <p>
        We can also follow the same Prepare, Check, Calculate, Conclude steps for computing a confidence interval or completing a hypothesis test. The details change a little, but the general approach remain the same. Think about these steps when you apply statistical methods.
      </p>
      
      <example xml:id="ex-cpr-check-conditions">
        <statement>
          <p>
            We consider an experiment for patients who underwent cardiopulmonary resuscitation (CPR) for a heart attack and were subsequently admitted to a hospital. These patients were randomly divided into a treatment group where they received a blood thinner or the control group where they did not receive a blood thinner. The outcome variable of interest was whether the patients survived for at least 24 hours. The results are shown in <xref ref="resultsForCPRStudyInSmallSampleSection"/>. Check whether we can model the difference in sample proportions using the normal distribution.
          </p>
        </statement>
        <solution>
          <p>
            We first check for independence: since this is a randomized experiment, this condition is satisfied.
          </p>
          <p>
            Next, we check the success-failure condition for each group. We have at least 10 successes and 10 failures in each experiment arm (11, 14, 39, 26), so this condition is also satisfied.
          </p>
          <p>
            With both conditions satisfied, the difference in sample proportions can be reasonably modeled using a normal distribution for these data.
          </p>
        </solution>
      </example>
      
      <table xml:id="resultsForCPRStudyInSmallSampleSection">
        <title>Results for the CPR study. Patients in the treatment group were given a blood thinner, and patients in the control group were not.</title>
        <tabular>
          <row bottom="minor">
            <cell></cell>
            <cell>Survived</cell>
            <cell>Died</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Control</cell>
            <cell>11</cell>
            <cell>39</cell>
            <cell>50</cell>
          </row>
          <row>
            <cell>Treatment</cell>
            <cell>14</cell>
            <cell>26</cell>
            <cell>40</cell>
          </row>
          <row bottom="minor">
            <cell>Total</cell>
            <cell>25</cell>
            <cell>65</cell>
            <cell>90</cell>
          </row>
        </tabular>
      </table>
      
      <example xml:id="ex-cpr-ci">
        <statement>
          <p>
            Create and interpret a 90% confidence interval of the difference for the survival rates in the CPR study.
          </p>
        </statement>
        <solution>
          <p>
            We'll use <m>p_t</m> for the survival rate in the treatment group and <m>p_c</m> for the control group:
          </p>
          <md>
            <mrow>\hat{p}_{t} - \hat{p}_{c} = \frac{14}{40} - \frac{11}{50} = 0.35 - 0.22 = 0.13</mrow>
          </md>
          <p>
            We use the standard error formula provided on page<nbsp/><xref ref="assem-sampling-dist-p1-p2"/>. As with the one-sample proportion case, we use the sample estimates of each proportion in the formula in the confidence interval context:
          </p>
          <md>
            <mrow>SE \approx \sqrt{\frac{0.35 (1 - 0.35)}{40} + \frac{0.22 (1 - 0.22)}{50}} = 0.095</mrow>
          </md>
          <p>
            For a 90% confidence interval, we use <m>z^{\star} = 1.6449</m>:
          </p>
          <md>
            <mrow>\text{point estimate} \pm z^{\star} \times SE \amp \to 0.13 \pm 1.6449 \times  0.095</mrow>
            <mrow>\amp \to (-0.026, 0.286)</mrow>
          </md>
          <p>
            We are 90% confident that blood thinners have a difference of -2.6% to +28.6% percentage point impact on survival rate for patients who are like those in the study. Because 0% is contained in the interval, we do not have enough information to say whether blood thinners help or harm heart attack patients who have been admitted after they have undergone CPR.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-fish-oil-ci">
        <statement>
          <p>
            A 5-year experiment was conducted to evaluate the effectiveness of fish oils on reducing cardiovascular events, where each subject was randomized into one of two treatment groups. We'll consider heart attack outcomes in these patients:
          </p>
          <table>
            <tabular>
              <row bottom="minor">
                <cell></cell>
                <cell>heart attack</cell>
                <cell>no event</cell>
                <cell>Total</cell>
              </row>
              <row>
                <cell>fish oil</cell>
                <cell>145</cell>
                <cell>12788</cell>
                <cell>12933</cell>
              </row>
              <row>
                <cell>placebo</cell>
                <cell>200</cell>
                <cell>12738</cell>
                <cell>12938</cell>
              </row>
            </tabular>
          </table>
          <p>
            Create a 95% confidence interval for the effect of fish oils on heart attacks for patients who are well-represented by those in the study. Also interpret the interval in the context of the study.
          </p>
        </statement>
        <solution>
          <p>
            Because the patients were randomized, the subjects are independent, both within and between the two groups. The success-failure condition is also met for both groups as all counts are at least 10. This satisfies the conditions necessary to model the difference in proportions using a normal distribution.
          </p>
          <p>
            Compute the sample proportions (<m>\hat{p}_{\text{fish oil}} = 0.0112</m>, <m>\hat{p}_{\text{placebo}} = 0.0155</m>), point estimate of the difference (<m>0.0112 - 0.0155 = -0.0043</m>), and standard error (<m>SE = \sqrt{\frac{0.0112 \times 0.9888}{12933} + \frac{0.0155 \times 0.9845}{12938}} = 0.00145</m>). Next, plug the values into the general formula for a confidence interval, where we'll use a 95% confidence level with <m>z^{\star} = 1.96</m>:
          </p>
          <md>
            <mrow>-0.0043 \pm 1.96 \times 0.00145 \to (-0.0071, -0.0015)</mrow>
          </md>
          <p>
            We are 95% confident that fish oils decreases heart attacks by 0.15 to 0.71 percentage points (off of a baseline of about 1.55%) over a 5-year period for subjects who are similar to those in the study. Because the interval is entirely below 0, the data provide strong evidence that fish oil supplements reduce heart attacks in patients like those in the study.
          </p>
        </solution>
      </exercise>
    </subsection>
    
    <subsection xml:id="htForPropDiffSection">
      <title>Hypothesis tests for the difference of two proportions</title>
      
      <p>
        A mammogram is an X-ray procedure used to check for breast cancer. Whether mammograms should be used is part of a controversial discussion, and it's the topic of our next example where we learn about 2-proportion hypothesis tests when <m>H_0</m> is <m>p_1 - p_2 = 0</m> (or equivalently, <m>p_1 = p_2</m>).
      </p>
      
      <p>
        A 30-year study was conducted with nearly 90,000 female participants. During a 5-year screening period, each woman was randomized to one of two groups: in the first group, women received regular mammograms to screen for breast cancer, and in the second group, women received regular non-mammogram breast cancer exams. No intervention was made during the following 25 years of the study, and we'll consider death resulting from breast cancer over the full 30-year period. Results from the study are summarized in <xref ref="mammogramStudySummaryTable"/>.
      </p>
      
      <p>
        If mammograms are much more effective than non-mammogram breast cancer exams, then we would expect to see additional deaths from breast cancer in the control group. On the other hand, if mammograms are not as effective as regular breast cancer exams, we would expect to see an increase in breast cancer deaths in the mammogram group.
      </p>
      
      <table xml:id="mammogramStudySummaryTable">
        <title>Summary results for breast cancer study.</title>
        <tabular>
          <row>
            <cell></cell>
            <cell></cell>
            <cell colspan="2" halign="center">Death from breast cancer?</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell>Yes</cell>
            <cell>No</cell>
          </row>
          <row>
            <cell>Mammogram</cell>
            <cell></cell>
            <cell>500</cell>
            <cell>44,425</cell>
          </row>
          <row>
            <cell>Control</cell>
            <cell></cell>
            <cell>505</cell>
            <cell>44,405</cell>
          </row>
        </tabular>
      </table>
      
      <exercise xml:id="ex-mammogram-experiment">
        <statement>
          <p>
            Is this study an experiment or an observational study?
          </p>
        </statement>
        <solution>
          <p>
            This is an experiment. Patients were randomized to receive mammograms or a standard breast cancer exam. We will be able to make causal conclusions based on this study.
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="htFormammogramStudySummaryTable">
        <statement>
          <p>
            Set up hypotheses to test whether there was a difference in breast cancer deaths in the mammogram and control groups.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: the breast cancer death rate for patients screened using mammograms is the same as the breast cancer death rate for patients in the control, <m>p_{mgm} - p_{ctrl} = 0</m>.
          </p>
          <p>
            <m>H_A</m>: the breast cancer death rate for patients screened using mammograms is different than the breast cancer death rate for patients in the control, <m>p_{mgm} - p_{ctrl} \neq 0</m>.
          </p>
        </solution>
      </exercise>
      
      <p>
        In Example<nbsp/><xref ref="condFormammogramStudySummaryTableNormalInference"/>, we will check the conditions for using a normal distribution to analyze the results of the study. The details are very similar to that of confidence intervals. However, when the null hypothesis is that <m>p_1 - p_2 = 0</m>, we use a special proportion called the <term>pooled proportion</term> to check the success-failure condition:
      </p>
      <md>
        <mrow>\hat{p}_{\textit{pooled}} \amp = \frac{\text{\# of patients who died from breast cancer in the entire study}}{\text{\# of patients in the entire study}}</mrow>
        <mrow>\amp = \frac{500 + 505}{500 + \text{44,425} + 505 + \text{44,405}}</mrow>
        <mrow>\amp = 0.0112</mrow>
      </md>
      <p>
        This proportion is an estimate of the breast cancer death rate across the entire study, and it's our best estimate of the proportions <m>p_{mgm}</m> and <m>p_{ctrl}</m> <em>if the null hypothesis is true that <m>p_{mgm} = p_{ctrl}</m></em>. We will also use this pooled proportion when computing the standard error.
      </p>
      
      <example xml:id="condFormammogramStudySummaryTableNormalInference">
        <statement>
          <p>
            Is it reasonable to model the difference in proportions using a normal distribution in this study?
          </p>
        </statement>
        <solution>
          <p>
            Because the patients are randomized, they can be treated as independent, both within and between groups. We also must check the success-failure condition for each group. Under the null hypothesis, the proportions <m>p_{mgm}</m> and <m>p_{ctrl}</m> are equal, so we check the success-failure condition with our best estimate of these values under <m>H_0</m>, the pooled proportion from the two samples, <m>\hat{p}_{\textit{pooled}} = 0.0112</m>:
          </p>
          <md>
            <mrow>\hat{p}_{\textit{pooled}} \times n_{mgm} \amp = 0.0112 \times \text{44,925} = 503</mrow>
            <mrow>(1 - \hat{p}_{\textit{pooled}}) \times n_{mgm} \amp = 0.9888 \times \text{44,925} = \text{44,422}</mrow>
            <mrow>\hat{p}_{\textit{pooled}} \times n_{ctrl} \amp = 0.0112 \times \text{44,910} = 503</mrow>
            <mrow>(1 - \hat{p}_{\textit{pooled}}) \times n_{ctrl} \amp = 0.9888 \times \text{44,910} = \text{44,407}</mrow>
          </md>
          <p>
            The success-failure condition is satisfied since all values are at least 10. With both conditions satisfied, we can safely model the difference in proportions using a normal distribution.
          </p>
        </solution>
      </example>
      
      <assemblage xml:id="assem-pooled-proportion">
        <title>Use the pooled proportion when <m>H_0</m> is <m>p_1 - p_2 = 0</m></title>
        <p>
          When the null hypothesis is that the proportions are equal, use the pooled proportion (<m>\hat{p}_{\textit{pooled}}</m>) to verify the success-failure condition and estimate the standard error:
        </p>
        <me>
          \hat{p}_{\textit{pooled}} = \frac{\text{number of ``successes''}}{\text{number of cases}} = \frac{\hat{p}_1 n_1 + \hat{p}_2 n_2}{n_1 + n_2}
        </me>
        <p>
          Here <m>\hat{p}_1 n_1</m> represents the number of successes in sample 1 since
        </p>
        <me>
          \hat{p}_1 = \frac{\text{number of successes in sample 1}}{n_1}
        </me>
        <p>
          Similarly, <m>\hat{p}_2 n_2</m> represents the number of successes in sample 2.
        </p>
      </assemblage>
      
      <p>
        In Example<nbsp/><xref ref="condFormammogramStudySummaryTableNormalInference"/>, the pooled proportion was used to check the success-failure condition.<fn>For an example of a two-proportion hypothesis test that does not require the success-failure condition to be met, see Section<nbsp/><xref ref="sec-malaria-vaccine"/>.</fn> In the next example, we see the second place where the pooled proportion comes into play: the standard error calculation.
      </p>
      
      <example xml:id="ex-mammogram-se">
        <statement>
          <p>
            Compute the point estimate of the difference in breast cancer death rates in the two groups, and use the pooled proportion <m>\hat{p}_{\textit{pooled}} = 0.0112</m> to calculate the standard error.
          </p>
        </statement>
        <solution>
          <p>
            The point estimate of the difference in breast cancer death rates is
          </p>
          <md>
            <mrow>\hat{p}_{mgm} - \hat{p}_{ctrl} \amp = \frac{500}{500 + 44,425} - \frac{505}{505 + 44,405}</mrow>
            <mrow>\amp = 0.01113 - 0.01125</mrow>
            <mrow>\amp = -0.00012</mrow>
          </md>
          <p>
            The breast cancer death rate in the mammogram group was 0.012% less than in the control group. Next, the standard error is calculated <em>using the pooled proportion</em>, <m>\hat{p}_{\textit{pooled}}</m>:
          </p>
          <md>
            <mrow>SE = \sqrt{\frac{\hat{p}_{\textit{pooled}}(1-\hat{p}_{\textit{pooled}})}{n_{mgm}} + \frac{\hat{p}_{\textit{pooled}}(1-\hat{p}_{\textit{pooled}})}{n_{ctrl}}} = 0.00070</mrow>
          </md>
        </solution>
      </example>
      
      <example xml:id="ex-mammogram-ht">
        <statement>
          <p>
            Using the point estimate <m>\hat{p}_{mgm} - \hat{p}_{ctrl} = -0.00012</m> and standard error <m>SE = 0.00070</m>, calculate a p-value for the hypothesis test and write a conclusion.
          </p>
        </statement>
        <solution>
          <p>
            Just like in past tests, we first compute a test statistic and draw a picture:
          </p>
          <md>
            <mrow>Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{-0.00012 - 0}{0.00070} = -0.17</mrow>
          </md>
          <figure xml:id="mammogramPValue">
            <caption>A normal distribution is shown centered at 0 with a standard deviation of 0.0007. The lower tail is shaded below -0.00012 and the upper tail is shaded above 0.00012. Visually, it looks like very roughly 90% of the area under the normal distribution is shaded.</caption>
            <image source="ch_inference_for_props/mammograms/mammogramPValue.png" width="45%"/>
          </figure>
          <p>
            The lower tail area is 0.4325, which we double to get the p-value: 0.8650. Because this p-value is larger than 0.05, we do not reject the null hypothesis. That is, the difference in breast cancer death rates is reasonably explained by chance, and we do not observe benefits or harm from mammograms relative to a regular breast exam.
          </p>
        </solution>
      </example>
      
      <p>
        Can we conclude that mammograms have no benefits or harm? Here are a few considerations to keep in mind when reviewing the mammogram study as well as any other medical study:
      </p>
      <ul>
        <li>
          We do not reject the null hypothesis, which means we don't have sufficient evidence to conclude that mammograms reduce or increase breast cancer deaths.
        </li>
        <li>
          If mammograms are helpful or harmful, the data suggest the effect isn't very large.
        </li>
        <li>
          Are mammograms more or less expensive than a non-mammogram breast exam? If one option is much more expensive than the other and doesn't offer clear benefits, then we should lean towards the less expensive option.
        </li>
        <li>
          The study's authors also found that mammograms led to overdiagnosis of breast cancer, which means some breast cancers were found (or thought to be found) but that these cancers would not cause symptoms during patients' lifetimes. That is, something else would kill the patient before breast cancer symptoms appeared. This means some patients may have been treated for breast cancer unnecessarily, and this treatment is another cost to consider. It is also important to recognize that overdiagnosis can cause unnecessary physical or emotional harm to patients.
        </li>
      </ul>
      <p>
        These considerations highlight the complexity around medical care and treatment recommendations. Experts and medical boards who study medical treatments use considerations like those above to provide their best recommendation based on the current evidence.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-more-2prop-ht">
      <title>More on 2-proportion hypothesis tests (special topic)</title>
      
      <p>
        When we conduct a 2-proportion hypothesis test, usually <m>H_0</m> is <m>p_1 - p_2 = 0</m>. However, there are rare situations where we want to check for some difference in <m>p_1</m> and <m>p_2</m> that is some value other than 0. For example, maybe we care about checking a null hypothesis where <m>p_1 - p_2 = 0.1</m>. In contexts like these, we generally use <m>\hat{p}_1</m> and <m>\hat{p}_2</m> to check the success-failure condition and construct the standard error.
      </p>
      
      <exercise xml:id="carWheelBladeManufacturer">
        <statement>
          <p>
            A quadcopter company is considering a new manufacturer for rotor blades. The new manufacturer would be more expensive, but they claim their higher-quality blades are more reliable, with 3% more blades passing inspection than their competitor. Set up appropriate hypotheses for the test.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: The higher-quality blades will pass inspection 3% more frequently than the standard-quality blades. <m>p_{highQ} - p_{standard} = 0.03</m>.
          </p>
          <p>
            <m>H_A</m>: The higher-quality blades will pass inspection some amount different than 3% more often than the standard-quality blades. <m>p_{highQ} - p_{standard} \neq 0.03</m>.
          </p>
        </solution>
      </exercise>
      
      <figure xml:id="quadcopter_david_j">
        <caption>A Phantom quadcopter. Photo by David J (http://flic.kr/p/oiWLNu). CC-BY 2.0 license. This photo has been cropped and a border has been added.</caption>
        <image source="ch_inference_for_props/quadcopter/quadcopter_david_j.jpg" width="60%"/>
      </figure>
      
      <example xml:id="qualityCtrlEngHypothesisEval">
        <statement>
          <p>
            The quality control engineer from Guided Practice<nbsp/><xref ref="carWheelBladeManufacturer"/> collects a sample of blades, examining 1000 blades from each company, and she finds that 899 blades pass inspection from the current supplier and 958 pass inspection from the prospective supplier. Using these data, evaluate the hypotheses from Guided Practice<nbsp/><xref ref="carWheelBladeManufacturer"/> with a significance level of 5%.
          </p>
        </statement>
        <solution>
          <p>
            First, we check the conditions. The sample is not necessarily random, so to proceed we must assume the blades are all independent; for this sample we will suppose this assumption is reasonable, but the engineer would be more knowledgeable as to whether this assumption is appropriate. The success-failure condition also holds for each sample. Thus, the difference in sample proportions, <m>0.958 - 0.899 = 0.059</m>, can be said to come from a nearly normal distribution.
          </p>
          <p>
            The standard error is computed using the two sample proportions since we do not use a pooled proportion for this context:
          </p>
          <md>
            <mrow>SE = \sqrt{\frac{0.958(1-0.958)}{1000} + \frac{0.899(1-0.899)}{1000}} = 0.0114</mrow>
          </md>
          <p>
            In this hypothesis test, because the null is that <m>p_1 - p_2 = 0.03</m>, the sample proportions were used for the standard error calculation rather than a pooled proportion.
          </p>
          <p>
            Next, we compute the test statistic and use it to find the p-value, which is depicted in <xref ref="bladesTwoSampleHTPValueQC"/>.
          </p>
          <md>
            <mrow>Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.059 - 0.03}{0.0114} = 2.54</mrow>
          </md>
          <p>
            Using a standard normal distribution for this test statistic, we identify the right tail area as 0.006, and we double it to get the p-value: 0.012. We reject the null hypothesis because 0.012 is less than 0.05. Since we observed a larger-than-3% increase in blades that pass inspection, we have statistically significant evidence that the higher-quality blades pass inspection <em>more than</em> 3% as often as the currently used blades, exceeding the company's claims.
          </p>
        </solution>
      </example>
      
      <figure xml:id="bladesTwoSampleHTPValueQC">
        <caption>Distribution of the test statistic if the null hypothesis was true. The p-value is represented by the shaded areas.</caption>
        <image source="ch_inference_for_props/bladesTwoSampleHTPValueQC.png" width="45%"/>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-se-formula-special">
      <title>Examining the standard error formula (special topic)</title>
      
      <p>
        This subsection covers more theoretical topics that offer deeper insights into the origins of the standard error formula for the difference of two proportions. Ultimately, all of the standard error formulas we encounter in this chapter and in Chapter<nbsp/><xref ref="ch-inference-for-means"/> can be derived from the probability principles of Section<nbsp/><xref ref="sec-random-variables"/>.
      </p>
      
      <p>
        The formula for the standard error of the difference in two proportions can be deconstructed into the formulas for the standard errors of the individual sample proportions. Recall that the standard error of the individual sample proportions <m>\hat{p}_1</m> and <m>\hat{p}_2</m> are
      </p>
      <md>
        <mrow>SE_{\hat{p}_1} = \sqrt{\frac{{p}_1 (1 - {p}_1)}{n_1}} \qquad SE_{\hat{p}_2} = \sqrt{\frac{{p}_2 (1 - {p}_2)}{n_2}}</mrow>
      </md>
      <p>
        The standard error of the difference of two sample proportions can be deconstructed from the standard errors of the separate sample proportions:
      </p>
      <md>
        <mrow>SE_{\hat{p}_{1} - \hat{p}_{2}} = \sqrt{SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2} = \sqrt{\frac{{p}_1 (1 - {p}_1)}{n_1} + \frac{{p}_2 (1 - {p}_2)}{n_2}}</mrow>
      </md>
      <p>
        This special relationship follows from probability theory.
      </p>
      
      <exercise xml:id="derivingSEForDiffOfTwoMeansExercise">
        <statement>
          <p>
            Prerequisite: Section<nbsp/><xref ref="sec-random-variables"/>. We can rewrite the equation above in a different way:
          </p>
          <me>
            SE_{\hat{p}_{1} - \hat{p}_{2}}^2 = SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2
          </me>
          <p>
            Explain where this formula comes from using the formula for the variability of the sum of two random variables.
          </p>
        </statement>
        <solution>
          <p>
            The standard error squared represents the variance of the estimate. If <m>X</m> and <m>Y</m> are two random variables with variances <m>\sigma_x^2</m> and <m>\sigma_y^2</m>, then the variance of <m>X - Y</m> is <m>\sigma_x^2 + \sigma_y^2</m>. Likewise, the variance corresponding to <m>\hat{p}_1 - \hat{p}_2</m> is <m>\sigma_{\hat{p}_1}^2 + \sigma_{\hat{p}_2}^2</m>. Because <m>\sigma_{\hat{p}_1}^2</m> and <m>\sigma_{\hat{p}_2}^2</m> are just another way of writing <m>SE_{\hat{p}_1}^2</m> and  <m>SE_{\hat{p}_2}^2</m>, the variance associated with <m>\hat{p}_1 - \hat{p}_2</m> may be written as <m>SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2</m>.
          </p>
        </solution>
      </exercise>
    </subsection>
    
    <exercises>
      <title>Section 6.2 Exercises</title>
      
      <exercise xml:id="social_experiment_conditions">
        <title>Social experiment, Part I</title>
        <statement>
          <p>
            A "social experiment" conducted by a TV program questioned what people do when they see a very obviously bruised woman getting picked on by her boyfriend. On two different occasions at the same restaurant, the same couple was depicted. In one scenario the woman was dressed "provocatively" and in the other scenario the woman was dressed "conservatively". The table below shows how many restaurant diners were present under each scenario, and whether or not they intervened.
          </p>
          <tabular>
            <row>
              <cell></cell>
              <cell></cell>
              <cell colspan="2" halign="center"><em>Scenario</em></cell>
            </row>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>Provocative</cell>
              <cell>Conservative</cell>
              <cell>Total</cell>
            </row>
            <row>
              <cell><em>Intervene</em></cell>
              <cell>Yes</cell>
              <cell>5</cell>
              <cell>15</cell>
              <cell>20</cell>
            </row>
            <row>
              <cell></cell>
              <cell>No</cell>
              <cell>15</cell>
              <cell>10</cell>
              <cell>25</cell>
            </row>
            <row>
              <cell></cell>
              <cell>Total</cell>
              <cell>20</cell>
              <cell>25</cell>
              <cell>45</cell>
            </row>
          </tabular>
          <p>
            Explain why the sampling distribution of the difference between the proportions of interventions under provocative and conservative scenarios does not follow an approximately normal distribution.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="heart_transplant_conditions">
        <title>Heart transplant success</title>
        <statement>
          <p>
            The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was officially designated a heart transplant candidate, meaning that he was gravely ill and might benefit from a new heart. Patients were randomly assigned into treatment and control groups. Patients in the treatment group received a transplant, and those in the control group did not. The table below displays how many patients survived and died in each group.
          </p>
          <tabular>
            <row bottom="minor">
              <cell></cell>
              <cell>control</cell>
              <cell>treatment</cell>
            </row>
            <row>
              <cell>alive</cell>
              <cell>4</cell>
              <cell>24</cell>
            </row>
            <row bottom="minor">
              <cell>dead</cell>
              <cell>30</cell>
              <cell>45</cell>
            </row>
          </tabular>
          <p>
            Suppose we are interested in estimating the difference in survival rate between the control and treatment groups using a confidence interval. Explain why we cannot construct such an interval using the normal approximation. What might go wrong if we constructed the confidence interval despite this problem?
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="gender_color_preference_CI_concept">
        <title>Gender and color preference</title>
        <statement>
          <p>
            A study asked 1,924 male and 3,666 female undergraduate college students their favorite color. A 95% confidence interval for the difference between the proportions of males and females whose favorite color is black <m>(p_{male} - p_{female})</m> was calculated to be (0.02, 0.06). Based on this information, determine if the following statements about undergraduate college students are true or false, and explain your reasoning for each statement you identify as false.
          </p>
          <ol>
            <li>We are 95% confident that the true proportion of males whose favorite color is black is 2% lower to 6% higher than the true proportion of females whose favorite color is black.</li>
            <li>We are 95% confident that the true proportion of males whose favorite color is black is 2% to 6% higher than the true proportion of females whose favorite color is black.</li>
            <li>95% of random samples will produce 95% confidence intervals that include the true difference between the population proportions of males and females whose favorite color is black.</li>
            <li>We can conclude that there is a significant difference between the proportions of males and females whose favorite color is black and that the difference between the two sample proportions is too large to plausibly be due to chance.</li>
            <li>The 95% confidence interval for <m>(p_{female} - p_{male})</m> cannot be calculated with only the information given in this exercise.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="government_shutdown_CI_concept">
        <title>Government shutdown</title>
        <statement>
          <p>
            The United States federal government shutdown of 20182019 occurred from December 22, 2018 until January 25, 2019, a span of 35 days. A Survey USA poll of 614 randomly sampled Americans during this time period reported that 48% of those who make less than $40,000 per year and 55% of those who make $40,000 or more per year said the government shutdown has not at all affected them personally. A 95% confidence interval for <m>(p_{\text{$\lt$40K}} - p_{\text{$\ge$40K}})</m>, where <m>p</m> is the proportion of those who said the government shutdown has not at all affected them personally, is (-0.16, 0.02). Based on this information, determine if the following statements are true or false, and explain your reasoning if you identify the statement as false.
          </p>
          <ol>
            <li>At the 5% significance level, the data provide convincing evidence of a real difference in the proportion who are not affected personally between Americans who make less than $40,000 annually and Americans who make $40,000 annually.</li>
            <li>We are 95% confident that 16% more to 2% fewer Americans who make less than $40,000 per year are not at all personally affected by the government shutdown compared to those who make $40,000 or more per year.</li>
            <li>A 90% confidence interval for <m>(p_{\text{$\lt$40K}} - p_{\text{$\ge$40K}})</m> would be wider than the <m>(-0.16, 0.02)</m> interval.</li>
            <li>A 95% confidence interval for <m>(p_{\text{$\ge$40K}} - p_{\text{$\lt$40K}})</m> is (-0.02, 0.16).</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="national_health_plan_CI_replaced">
        <title>National Health Plan, Part III</title>
        <statement>
          <p>
            Exercise <xref ref="national_health_plan_HT"/> presents the results of a poll evaluating support for a generically branded "National Health Plan" in the United States. 79% of 347 Democrats and 55% of 617 Independents support a National Health Plan.
          </p>
          <ol>
            <li>Calculate a 95% confidence interval for the difference between the proportion of Democrats and Independents who support a National Health Plan <m>(p_{D} - p_{I})</m>, and interpret it in this context. We have already checked conditions for you.</li>
            <li>True or false: If we had picked a random Democrat and a random Independent at the time of this poll, it is more likely that the Democrat would support the National Health Plan than the Independent.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="sleep_OR_CA_CI">
        <title>Sleep deprivation, CA vs. OR, Part I</title>
        <statement>
          <p>
            According to a report on sleep deprivation by the Centers for Disease Control and Prevention, the proportion of California residents who reported insufficient rest or sleep during each of the preceding 30 days is 8.0%, while this proportion is 8.8% for Oregon residents. These data are based on simple random samples of 11,545 California and 4,691 Oregon residents. Calculate a 95% confidence interval for the difference between the proportions of Californians and Oregonians who are sleep deprived and interpret it in context of the data.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="offshore_drill_edu_dontknow_HT">
        <title>Offshore drilling, Part I</title>
        <statement>
          <p>
            A survey asked 827 randomly sampled registered voters in California "Do you support? Or do you oppose? Drilling for oil and natural gas off the Coast of California? Or do you not know enough to say?" Below is the distribution of responses, separated based on whether or not the respondent graduated from college.
          </p>
          <tabular>
            <row>
              <cell></cell>
              <cell colspan="2" halign="center"><em>College Grad</em></cell>
            </row>
            <row>
              <cell></cell>
              <cell>Yes</cell>
              <cell>No</cell>
            </row>
            <row>
              <cell>Support</cell>
              <cell>154</cell>
              <cell>132</cell>
            </row>
            <row>
              <cell>Oppose</cell>
              <cell>180</cell>
              <cell>126</cell>
            </row>
            <row>
              <cell>Do not know</cell>
              <cell>104</cell>
              <cell>131</cell>
            </row>
            <row>
              <cell>Total</cell>
              <cell>438</cell>
              <cell>389</cell>
            </row>
          </tabular>
          <ol>
            <li>What percent of college graduates and what percent of the non-college graduates in this sample do not know enough to have an opinion on drilling for oil and natural gas off the Coast of California?</li>
            <li>Conduct a hypothesis test to determine if the data provide strong evidence that the proportion of college graduates who do not have an opinion on this issue is different than that of non-college graduates.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="sleep_OR_CA_HT">
        <title>Sleep deprivation, CA vs. OR, Part II</title>
        <statement>
          <p>
            Exercise <xref ref="sleep_OR_CA_CI"/> provides data on sleep deprivation rates of Californians and Oregonians. The proportion of California residents who reported insufficient rest or sleep during each of the preceding 30 days is 8.0%, while this proportion is 8.8% for Oregon residents. These data are based on simple random samples of 11,545 California and 4,691 Oregon residents.
          </p>
          <ol>
            <li>Conduct a hypothesis test to determine if these data provide strong evidence the rate of sleep deprivation is different for the two states. (Reminder: Check conditions)</li>
            <li>It is possible the conclusion of the test in part (a) is incorrect. If this is the case, what type of error was made?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="offshore_drill_edu_support_HT">
        <title>Offshore drilling, Part II</title>
        <statement>
          <p>
            Results of a poll evaluating support for drilling for oil and natural gas off the coast of California were introduced in Exercise <xref ref="offshore_drill_edu_dontknow_HT"/>.
          </p>
          <tabular>
            <row>
              <cell></cell>
              <cell colspan="2" halign="center"><em>College Grad</em></cell>
            </row>
            <row>
              <cell></cell>
              <cell>Yes</cell>
              <cell>No</cell>
            </row>
            <row>
              <cell>Support</cell>
              <cell>154</cell>
              <cell>132</cell>
            </row>
            <row>
              <cell>Oppose</cell>
              <cell>180</cell>
              <cell>126</cell>
            </row>
            <row>
              <cell>Do not know</cell>
              <cell>104</cell>
              <cell>131</cell>
            </row>
            <row>
              <cell>Total</cell>
              <cell>438</cell>
              <cell>389</cell>
            </row>
          </tabular>
          <ol>
            <li>What percent of college graduates and what percent of the non-college graduates in this sample support drilling for oil and natural gas off the Coast of California?</li>
            <li>Conduct a hypothesis test to determine if the data provide strong evidence that the proportion of college graduates who support off-shore drilling in California is different than that of non-college graduates.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="full_body_scan_HT_Error">
        <title>Full body scan, Part I</title>
        <statement>
          <p>
            A news article reports that "Americans have differing views on two potentially inconvenient and invasive practices that airports could implement to uncover potential terrorist attacks." This news piece was based on a survey conducted among a random sample of 1,137 adults nationwide, where one of the questions on the survey was "Some airports are now using 'full-body' digital x-ray machines to electronically screen passengers in airport security lines. Do you think these new x-ray machines should or should not be used at airports?" Below is a summary of responses based on party affiliation.
          </p>
          <tabular>
            <row>
              <cell></cell>
              <cell></cell>
              <cell colspan="3" halign="center"><em>Party Affiliation</em></cell>
            </row>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>Republican</cell>
              <cell>Democrat</cell>
              <cell>Independent</cell>
            </row>
            <row>
              <cell><em>Answer</em></cell>
              <cell>Should</cell>
              <cell>264</cell>
              <cell>299</cell>
              <cell>351</cell>
            </row>
            <row>
              <cell></cell>
              <cell>Should not</cell>
              <cell>38</cell>
              <cell>55</cell>
              <cell>77</cell>
            </row>
            <row>
              <cell></cell>
              <cell>Don't know/No answer</cell>
              <cell>16</cell>
              <cell>15</cell>
              <cell>22</cell>
            </row>
            <row>
              <cell></cell>
              <cell>Total</cell>
              <cell>318</cell>
              <cell>369</cell>
              <cell>450</cell>
            </row>
          </tabular>
          <ol>
            <li>Conduct an appropriate hypothesis test evaluating whether there is a difference in the proportion of Republicans and Democrats who think the full-body scans should be applied in airports. Assume that all relevant conditions are met.</li>
            <li>The conclusion of the test in part (a) may be incorrect, meaning a testing error was made. If an error was made, was it a Type 1 or a Type 2 Error? Explain.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="sleep_deprived_driver_HT">
        <title>Sleep deprived transportation workers</title>
        <statement>
          <p>
            The National Sleep Foundation conducted a survey on the sleep habits of randomly sampled transportation workers and a control sample of non-transportation workers. The results of the survey are shown below.
          </p>
          <tabular>
            <row>
              <cell></cell>
              <cell></cell>
              <cell colspan="4" halign="center"><em>Transportation Professionals</em></cell>
            </row>
            <row>
              <cell></cell>
              <cell><em>Control</em></cell>
              <cell>Pilots</cell>
              <cell>Truck Drivers</cell>
              <cell>Train Operators</cell>
              <cell>Bus/Taxi/Limo Drivers</cell>
            </row>
            <row>
              <cell>Less than 6 hours of sleep</cell>
              <cell>35</cell>
              <cell>19</cell>
              <cell>35</cell>
              <cell>29</cell>
              <cell>21</cell>
            </row>
            <row>
              <cell>6 to 8 hours of sleep</cell>
              <cell>193</cell>
              <cell>132</cell>
              <cell>117</cell>
              <cell>119</cell>
              <cell>131</cell>
            </row>
            <row>
              <cell>More than 8 hours</cell>
              <cell>64</cell>
              <cell>51</cell>
              <cell>51</cell>
              <cell>32</cell>
              <cell>58</cell>
            </row>
            <row>
              <cell>Total</cell>
              <cell>292</cell>
              <cell>202</cell>
              <cell>203</cell>
              <cell>180</cell>
              <cell>210</cell>
            </row>
          </tabular>
          <p>
            Conduct a hypothesis test to evaluate if these data provide evidence of a difference between the proportions of truck drivers and non-transportation workers (the control group) who get less than 6 hours of sleep per day, i.e. are considered sleep deprived.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="prenatal_vitamin_autism_HT">
        <title>Prenatal vitamins and Autism</title>
        <statement>
          <p>
            Researchers studying the link between prenatal vitamin use and autism surveyed the mothers of a random sample of children aged 24 - 60 months with autism and conducted another separate random sample for children with typical development. The table below shows the number of mothers in each group who did and did not use prenatal vitamins during the three months before pregnancy (periconceptional period).
          </p>
          <tabular>
            <row>
              <cell></cell>
              <cell></cell>
              <cell colspan="2" halign="center"><em>Autism</em></cell>
              <cell></cell>
            </row>
            <row>
              <cell></cell>
              <cell></cell>
              <cell>Autism</cell>
              <cell>Typical development</cell>
              <cell>Total</cell>
            </row>
            <row>
              <cell><em>Periconceptional</em></cell>
              <cell>No vitamin</cell>
              <cell>111</cell>
              <cell>70</cell>
              <cell>181</cell>
            </row>
            <row>
              <cell><em>prenatal vitamin</em></cell>
              <cell>Vitamin</cell>
              <cell>143</cell>
              <cell>159</cell>
              <cell>302</cell>
            </row>
            <row>
              <cell></cell>
              <cell>Total</cell>
              <cell>254</cell>
              <cell>229</cell>
              <cell>483</cell>
            </row>
          </tabular>
          <ol>
            <li>State appropriate hypotheses to test for independence of use of prenatal vitamins during the three months before pregnancy and autism.</li>
            <li>Complete the hypothesis test and state an appropriate conclusion. (Reminder: Verify any necessary conditions for the test.)</li>
            <li>A New York Times article reporting on this study was titled "Prenatal Vitamins May Ward Off Autism". Do you find the title of this article to be appropriate? Explain your answer. Additionally, propose an alternative title.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="hiv_africa_HT">
        <title>HIV in sub-Saharan Africa</title>
        <statement>
          <p>
            In July 2008 the US National Institutes of Health announced that it was stopping a clinical study early because of unexpected results. The study population consisted of HIV-infected women in sub-Saharan Africa who had been given single dose Nevaripine (a treatment for HIV) while giving birth, to prevent transmission of HIV to the infant. The study was a randomized comparison of continued treatment of a woman (after successful childbirth) with Nevaripine vs Lopinavir, a second drug used to treat HIV. 240 women participated in the study; 120 were randomized to each of the two treatments. Twenty-four weeks after starting the study treatment, each woman was tested to determine if the HIV infection was becoming worse (an outcome called <em>virologic failure</em>). Twenty-six of the 120 women treated with Nevaripine experienced virologic failure, while 10 of the 120 women treated with the other drug experienced virologic failure.
          </p>
          <ol>
            <li>Create a two-way table presenting the results of this study.</li>
            <li>State appropriate hypotheses to test for difference in virologic failure rates between treatment groups.</li>
            <li>Complete the hypothesis test and state an appropriate conclusion. (Reminder: Verify any necessary conditions for the test.)</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="apple_doctor_HT_concept">
        <title>An apple a day keeps the doctor away</title>
        <statement>
          <p>
            A physical education teacher at a high school wanting to increase awareness on issues of nutrition and health asked her students at the beginning of the semester whether they believed the expression "an apple a day keeps the doctor away", and 40% of the students responded yes. Throughout the semester she started each class with a brief discussion of a study highlighting positive effects of eating more fruits and vegetables. She conducted the same apple-a-day survey at the end of the semester, and this time 60% of the students responded yes. Can she use a two-proportion method from this section for this analysis? Explain your reasoning.
          </p>
        </statement>
      </exercise>
    </exercises>
    
  </section>
  
  <!-- Section 7.3: Testing for goodness of fit using chi-square -->
  <section xml:id="oneWayChiSquare">
    <title>Testing for goodness of fit using chi-square</title>
    
    <introduction>
      <p>
        In this section, we develop a method for assessing a null model when the data are binned. This technique is commonly used in two circumstances:
      </p>
      <ul>
        <li>Given a sample of cases that can be classified into several groups, determine if the sample is representative of the general population.</li>
        <li>Evaluate whether data resemble a particular distribution, such as a normal distribution or a geometric distribution.</li>
      </ul>
      <p>
        Each of these scenarios can be addressed using the same statistical test: a chi-square test.
      </p>
      <p>
        In the first case, we consider data from a random sample of 275 jurors in a small county. Jurors identified their racial group, as shown in <xref ref="juryRepresentationAndCityRepresentationForRace"/>, and we would like to determine if these jurors are racially representative of the population. If the jury is representative of the population, then the proportions in the sample should roughly reflect the population of eligible jurors, i.e. registered voters.
      </p>
      
      <table xml:id="juryRepresentationAndCityRepresentationForRace">
        <title>Representation by race in a city's juries and population.</title>
        <tabular>
          <row bottom="minor">
            <cell>Race</cell>
            <cell></cell>
            <cell>White</cell>
            <cell>Black</cell>
            <cell>Hispanic</cell>
            <cell>Other</cell>
            <cell></cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Representation in juries</cell>
            <cell></cell>
            <cell>205</cell>
            <cell>26</cell>
            <cell>25</cell>
            <cell>19</cell>
            <cell></cell>
            <cell>275</cell>
          </row>
          <row bottom="minor">
            <cell>Registered voters</cell>
            <cell></cell>
            <cell>0.72</cell>
            <cell>0.07</cell>
            <cell>0.12</cell>
            <cell>0.09</cell>
            <cell></cell>
            <cell>1.00</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        While the proportions in the juries do not precisely represent the population proportions, it is unclear whether these data provide convincing evidence that the sample is not representative. If the jurors really were randomly sampled from the registered voters, we might expect small differences due to chance. However, unusually large differences may provide convincing evidence that the juries were not representative.
      </p>
      
      <p>
        A second application, assessing the fit of a distribution, is presented at the end of this section. Daily stock returns from the S&amp;P500 for 25 years are used to assess whether stock activity each day is independent of the stock's behavior on previous days.
      </p>
      
      <p>
        In these problems, we would like to examine all bins simultaneously, not simply compare one or two bins at a time, which will require us to develop a new test statistic.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-test-statistic-one-way">
      <title>Creating a test statistic for one-way tables</title>
      
      <example xml:id="ex-expected-juror-white-black">
        <statement>
          <p>
            Of the people in the city, 275 served on a jury. If the individuals are randomly selected to serve on a jury, about how many of the 275 people would we expect to be White? How many would we expect to be Black?
          </p>
        </statement>
        <solution>
          <p>
            About 72% of the population is White, so we would expect about 72% of the jurors to be White: <m>0.72\times 275 = 198</m>.
          </p>
          <p>
            Similarly, we would expect about 7% of the jurors to be Black, which would correspond to about <m>0.07\times 275 = 19.25</m> Black jurors.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-expected-juror-hispanic-other">
        <statement>
          <p>
            Twelve percent of the population is Hispanic and 9% represent other races. How many of the 275 jurors would we expect to be Hispanic or from another race? Answers can be found in <xref ref="expectedJuryRepresentationIfNoBias"/>.
          </p>
        </statement>
        <solution>
          <p>
            Hispanic: <m>0.12 \times 275 = 33</m>. Other: <m>0.09 \times 275 = 24.75</m>.
          </p>
        </solution>
      </exercise>
      
      <table xml:id="expectedJuryRepresentationIfNoBias">
        <title>Actual and expected make-up of the jurors.</title>
        <tabular>
          <row bottom="minor">
            <cell>Race</cell>
            <cell></cell>
            <cell>White</cell>
            <cell>Black</cell>
            <cell>Hispanic</cell>
            <cell>Other</cell>
            <cell></cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Observed data</cell>
            <cell></cell>
            <cell>205</cell>
            <cell>26</cell>
            <cell>25</cell>
            <cell>19</cell>
            <cell></cell>
            <cell>275</cell>
          </row>
          <row bottom="minor">
            <cell>Expected counts</cell>
            <cell></cell>
            <cell>198</cell>
            <cell>19.25</cell>
            <cell>33</cell>
            <cell>24.75</cell>
            <cell></cell>
            <cell>275</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        The sample proportion represented from each race among the 275 jurors was not a precise match for any ethnic group. While some sampling variation is expected, we would expect the sample proportions to be fairly similar to the population proportions if there is no bias on juries. We need to test whether the differences are strong enough to provide convincing evidence that the jurors are not a random sample. These ideas can be organized into hypotheses:
      </p>
      <ul>
        <li><m>H_0</m>: The jurors are a random sample, i.e. there is no racial bias in who serves on a jury, and the observed counts reflect natural sampling fluctuation.</li>
        <li><m>H_A</m>: The jurors are not randomly sampled, i.e. there is racial bias in juror selection.</li>
      </ul>
      <p>
        To evaluate these hypotheses, we quantify how different the observed counts are from the expected counts. Strong evidence for the alternative hypothesis would come in the form of unusually large deviations in the groups from what would be expected based on sampling variation alone.
      </p>
    </subsection>
    
    <subsection xml:id="chiSquareTestStatistic">
      <title>The chi-square test statistic</title>
      
      <p>
        In previous hypothesis tests, we constructed a test statistic of the following form:
      </p>
      <me>
        \frac{\text{point estimate} - \text{null value}}{\text{SE of point estimate}}
      </me>
      <p>
        This construction was based on (1) identifying the difference between a point estimate and an expected value if the null hypothesis was true, and (2) standardizing that difference using the standard error of the point estimate. These two ideas will help in the construction of an appropriate test statistic for count data.
      </p>
      
      <p>
        Our strategy will be to first compute the difference between the observed counts and the counts we would expect if the null hypothesis was true, then we will standardize the difference:
      </p>
      <me>
        Z_{1} = \frac{\text{observed White count} - \text{null White count}}{\text{SE of observed White count}}
      </me>
      <p>
        The standard error for the point estimate of the count in binned data is the square root of the count under the null.<fn>Using some of the rules learned in earlier chapters, we might think that the standard error would be <m>np(1-p)</m>, where <m>n</m> is the sample size and <m>p</m> is the proportion in the population. This would be correct if we were looking only at one count. However, we are computing many standardized differences and adding them together. It can be shown<mdash/>though not here<mdash/>that the square root of the count is a better way to standardize the count differences.</fn> Therefore:
      </p>
      <me>
        Z_1 = \frac{205 - 198}{\sqrt{198}} = 0.50
      </me>
      <p>
        The fraction is very similar to previous test statistics: first compute a difference, then standardize it. These computations should also be completed for the Black, Hispanic, and other groups:
      </p>
      <md>
        <mrow>\text{Black} \qquad Z_2 \amp = \frac{26-19.25}{\sqrt{19.25}}=1.54</mrow>
        <mrow>\text{Hispanic} \qquad Z_3 \amp = \frac{25-33}{\sqrt{33}}=-1.39</mrow>
        <mrow>\text{Other} \qquad Z_4 \amp = \frac{19-24.75}{\sqrt{24.75}}=-1.16</mrow>
      </md>
      <p>
        We would like to use a single test statistic to determine if these four standardized differences are irregularly far from zero. That is, <m>Z_1</m>, <m>Z_2</m>, <m>Z_3</m>, and <m>Z_4</m> must be combined somehow to help determine if they<mdash/>as a group<mdash/>tend to be unusually far from zero. A first thought might be to take the absolute value of these four standardized differences and add them up:
      </p>
      <me>
        |Z_1| + |Z_2| + |Z_3| + |Z_4| = 4.58
      </me>
      <p>
        Indeed, this does give one number summarizing how far the actual counts are from what was expected. However, it is more common to add the squared values:
      </p>
      <me>
        Z_1^2 + Z_2^2 + Z_3^2 + Z_4^2 = 5.89
      </me>
      <p>
        Squaring each standardized difference before adding them together does two things:
      </p>
      <ul>
        <li>Any standardized difference that is squared will now be positive.</li>
        <li>Differences that already look unusual<mdash/>e.g. a standardized difference of 2.5<mdash/>will become much larger after being squared.</li>
      </ul>
      <p>
        The test statistic <m>X^2</m>, which is the sum of the <m>Z^2</m> values, is generally used for these reasons. We can also write an equation for <m>X^2</m> using the observed counts and null counts:
      </p>
      <me>
        X^2 = \frac{(\text{observed count}_1 - \text{null count}_1)^2}{\text{null count}_1} + \dots + \frac{(\text{observed count}_4 - \text{null count}_4)^2}{\text{null count}_4}
      </me>
      <p>
        The final number <m>X^2</m> summarizes how strongly the observed counts tend to deviate from the null counts. In Section<nbsp/><xref ref="pValueForAChiSquareTest"/>, we will see that if the null hypothesis is true, then <m>X^2</m> follows a new distribution called a <em>chi-square distribution</em>. Using this distribution, we will be able to obtain a p-value to evaluate the hypotheses.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-dist-areas">
      <title>The chi-square distribution and finding areas</title>
      
      <p>
        The <term>chi-square distribution</term> is sometimes used to characterize data sets and statistics that are always positive and typically right skewed. Recall a normal distribution had two parameters<mdash/>mean and standard deviation<mdash/>that could be used to describe its exact characteristics. The chi-square distribution has just one parameter called <term>degrees of freedom (df)</term>, which influences the shape, center, and spread of the distribution.
      </p>
      
      <exercise xml:id="exerChiSquareDistributionDescriptionWithMoreDOF">
        <statement>
          <p>
            <xref ref="chiSquareDistributionWithInceasingDF"/> shows three chi-square distributions.
          </p>
          <p>
            (a) How does the center of the distribution change when the degrees of freedom is larger?
          </p>
          <p>
            (b) What about the variability (spread)?
          </p>
          <p>
            (c) How does the shape change?
          </p>
        </statement>
        <solution>
          <p>
            (a) The center becomes larger. If took a careful look, we could see that the mean of each distribution is equal to the distribution's degrees of freedom.
          </p>
          <p>
            (b) The variability increases as the degrees of freedom increases.
          </p>
          <p>
            (c) The distribution is very strongly skewed for <m>df=2</m>, and then the distributions become more symmetric for the larger degrees of freedom <m>df=4</m> and <m>df=9</m>. We would see this trend continue if we examined distributions with even more larger degrees of freedom.
          </p>
        </solution>
      </exercise>
      
      <figure xml:id="chiSquareDistributionWithInceasingDF">
        <caption>Three chi-square distributions with varying degrees of freedom.</caption>
        <image source="ch_inference_for_props/chiSquareDistributionWithInceasingDF/chiSquareDistributionWithInceasingDF.png" width="80%">
          <description>Three chi-square distributions are shown with degrees of freedom 2, 4, and 9 on the same plot. The horizontal axis ranges from 0 to 25<mdash/>recall that the chi-square distributions never take values smaller than 0. The chi-square distribution with 2 degrees of freedom starts at a peak at zero and then quickly declines more than halfway by the value of 2 and trails off after a value of about 5. The chi-square distribution with 4 degrees of freedom starts at 0 and quickly rises to a peak at about 2, before gradually declining and then more steeply declining starting at 3, before starting to flatten at about 5 or 6. The distribution has fallen very close to the horizontal axis by a value of 10. The chi-square distribution with 9 degrees of freedom starts at zero before gradually rising up to a peak at about 7 before declining again and trailing off between at around 15.</description>
        </image>
      </figure>
      
      <p>
        <xref ref="chiSquareDistributionWithInceasingDF"/> and Guided Practice<nbsp/><xref ref="exerChiSquareDistributionDescriptionWithMoreDOF"/> demonstrate three general properties of chi-square distributions as the degrees of freedom increases: the distribution becomes more symmetric, the center moves to the right, and the variability inflates.
      </p>
      
      <p>
        Our principal interest in the chi-square distribution is the calculation of p-values, which (as we have seen before) is related to finding the relevant area in the tail of a distribution. The most common ways to do this are using computer software, using a graphing calculator, or using a table. For folks wanting to use the table option, we provide an outline of how to read the chi-square table in Appendix<nbsp/>C, which is also where you may find the table. For the examples below, use your preferred approach to confirm you get the same answers.
      </p>
      
      <example xml:id="ex-chi-square-area-6-25-df3">
        <statement>
          <p>
            <xref ref="chiSquareAreaAbove6Point25WithDF3"/> shows a chi-square distribution with 3 degrees of freedom and an upper shaded tail starting at 6.25. Find the shaded area.
          </p>
        </statement>
        <solution>
          <p>
            Using statistical software or a graphing calculator, we can find that the upper tail area for a chi-square distribution with 3 degrees of freedom (<m>df</m>) and a cutoff of 6.25 is 0.1001. That is, the shaded upper tail of <xref ref="chiSquareAreaAbove6Point25WithDF3"/> has area 0.1.
          </p>
        </solution>
      </example>
      
      <figure xml:id="arrayOfFigureAreasForChiSquareDistribution">
        <caption>Six chi-square distributions with shaded upper tails.</caption>
        
        <sidebyside widths="48% 48%">
          <figure xml:id="chiSquareAreaAbove6Point25WithDF3">
            <caption>Chi-square distribution with 3 degrees of freedom, area above 6.25 shaded.</caption>
            <image source="ch_inference_for_props/arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove6Point25WithDF3.png" width="100%">
              <description>A chi-square distribution with 3 degrees of freedom is shown, with the area above 6.25 shaded. This region appears to be about 10% of the area under the curve.</description>
            </image>
          </figure>
          
          <figure xml:id="chiSquareAreaAbove4Point3WithDF2">
            <caption>2 degrees of freedom, area above 4.3 shaded.</caption>
            <image source="ch_inference_for_props/arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove4Point3WithDF2.png" width="100%">
              <description>A chi-square distribution with 2 degrees of freedom is shown, with the area above 4.3 shaded. This region appears to be about 10% of the area under the curve.</description>
            </image>
          </figure>
        </sidebyside>
        
        <sidebyside widths="48% 48%">
          <figure xml:id="chiSquareAreaAbove5Point1WithDF5">
            <caption>5 degrees of freedom, area above 5.1 shaded.</caption>
            <image source="ch_inference_for_props/arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove5Point1WithDF5.png" width="100%">
              <description>A chi-square distribution with 5 degrees of freedom is shown, with the area above 5.1 shaded. This region appears to be very roughly 50% of the area under the curve.</description>
            </image>
          </figure>
          
          <figure xml:id="chiSquareAreaAbove11Point7WithDF7">
            <caption>7 degrees of freedom, area above 11.7 shaded.</caption>
            <image source="ch_inference_for_props/arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove11Point7WithDF7.png" width="100%">
              <description>A chi-square distribution with 7 degrees of freedom is shown, with the area above 11.7 shaded. This region appears to be about 15% of the area under the curve.</description>
            </image>
          </figure>
        </sidebyside>
        
        <sidebyside widths="48% 48%">
          <figure xml:id="chiSquareAreaAbove10WithDF4">
            <caption>4 degrees of freedom, area above 10 shaded.</caption>
            <image source="ch_inference_for_props/arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove10WithDF4.png" width="100%">
              <description>A chi-square distribution with 4 degrees of freedom is shown, with the area above 10 shaded. This region appears to be about 5% of the area under the curve.</description>
            </image>
          </figure>
          
          <figure xml:id="chiSquareAreaAbove9Point21WithDF3">
            <caption>3 degrees of freedom, area above 9.21 shaded.</caption>
            <image source="ch_inference_for_props/arrayOfFigureAreasForChiSquareDistribution/chiSquareAreaAbove9Point21WithDF3.png" width="100%">
              <description>A chi-square distribution with 3 degrees of freedom is shown, with the area above 9.21 shaded. This region appears to be about 3% of the area under the curve.</description>
            </image>
          </figure>
        </sidebyside>
      </figure>
      
      <example xml:id="ex-chi-square-area-4-3-df2">
        <statement>
          <p>
            <xref ref="chiSquareAreaAbove4Point3WithDF2"/> shows the upper tail of a chi-square distribution with 2 degrees of freedom. The bound for this upper tail is at 4.3. Find the tail area.
          </p>
        </statement>
        <solution>
          <p>
            Using software, we can find that the tail area shaded in <xref ref="chiSquareAreaAbove4Point3WithDF2"/> to be 0.1165. If using a table, we would only be able to find a range of values for the tail area: between 0.1 and 0.2.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-chi-square-area-5-1-df5">
        <statement>
          <p>
            <xref ref="chiSquareAreaAbove5Point1WithDF5"/> shows an upper tail for a chi-square distribution with 5 degrees of freedom and a cutoff of 5.1. Find the tail area.
          </p>
        </statement>
        <solution>
          <p>
            Using software, we would obtain a tail area of 0.4038. If using the table in Appendix<nbsp/>C, we would have identified that the tail area is larger than 0.3 but not be able to give the precise value.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-chi-square-area-11-7-df7">
        <statement>
          <p>
            <xref ref="chiSquareAreaAbove11Point7WithDF7"/> shows a cutoff of 11.7 on a chi-square distribution with 7 degrees of freedom. Find the area of the upper tail.
          </p>
        </statement>
        <solution>
          <p>
            The area is 0.1109. If using a table, we would identify that it falls between 0.1 and 0.2.
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="ex-chi-square-area-10-df4">
        <statement>
          <p>
            <xref ref="chiSquareAreaAbove10WithDF4"/> shows a cutoff of 10 on a chi-square distribution with 4 degrees of freedom. Find the area of the upper tail.
          </p>
        </statement>
        <solution>
          <p>
            Precise value: 0.0404. If using the table: between 0.02 and 0.05.
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="ex-chi-square-area-9-21-df3">
        <statement>
          <p>
            <xref ref="chiSquareAreaAbove9Point21WithDF3"/> shows a cutoff of 9.21 with a chi-square distribution with 3 df. Find the area of the upper tail.
          </p>
        </statement>
        <solution>
          <p>
            Precise value: 0.0266. If using the table: between 0.02 and 0.05.
          </p>
        </solution>
      </exercise>
    </subsection>
    
    <subsection xml:id="pValueForAChiSquareTest">
      <title>Finding a p-value for a chi-square distribution</title>
      
      <p>
        In Section<nbsp/><xref ref="chiSquareTestStatistic"/>, we identified a new test statistic (<m>X^2</m>) within the context of assessing whether there was evidence of racial bias in how jurors were sampled. The null hypothesis represented the claim that jurors were randomly sampled and there was no racial bias. The alternative hypothesis was that there was racial bias in how the jurors were sampled.
      </p>
      
      <p>
        We determined that a large <m>X^2</m> value would suggest strong evidence favoring the alternative hypothesis: that there was racial bias. However, we could not quantify what the chance was of observing such a large test statistic (<m>X^2=5.89</m>) if the null hypothesis actually was true. This is where the chi-square distribution becomes useful. If the null hypothesis was true and there was no racial bias, then <m>X^2</m> would follow a chi-square distribution, with three degrees of freedom in this case. Under certain conditions, the statistic <m>X^2</m> follows a chi-square distribution with <m>k - 1</m> degrees of freedom, where <m>k</m> is the number of bins.
      </p>
      
      <example xml:id="ex-juror-df">
        <statement>
          <p>
            How many categories were there in the juror example? How many degrees of freedom should be associated with the chi-square distribution used for <m>X^2</m>?
          </p>
        </statement>
        <solution>
          <p>
            In the jurors example, there were <m>k=4</m> categories: White, Black, Hispanic, and other. According to the rule above, the test statistic <m>X^2</m> should then follow a chi-square distribution with <m>k-1 = 3</m> degrees of freedom if <m>H_0</m> is true.
          </p>
        </solution>
      </example>
      
      <p>
        Just like we checked sample size conditions to use a normal distribution in earlier sections, we must also check a sample size condition to safely apply the chi-square distribution for <m>X^2</m>. Each expected count must be at least 5. In the juror example, the expected counts were 198, 19.25, 33, and 24.75, all easily above 5, so we can apply the chi-square model to the test statistic, <m>X^2=5.89</m>.
      </p>
      
      <example xml:id="ex-juror-pvalue">
        <statement>
          <p>
            If the null hypothesis is true, the test statistic <m>X^2=5.89</m> would be closely associated with a chi-square distribution with three degrees of freedom. Using this distribution and test statistic, identify the p-value.
          </p>
        </statement>
        <solution>
          <p>
            The chi-square distribution and p-value are shown in <xref ref="jurorHTPValueShown"/>. Because larger chi-square values correspond to stronger evidence against the null hypothesis, we shade the upper tail to represent the p-value. Using statistical software (or the table in Appendix<nbsp/>C), we can determine that the area is 0.1171. Generally we do not reject the null hypothesis with such a large p-value. In other words, the data do not provide convincing evidence of racial bias in the juror selection.
          </p>
        </solution>
      </example>
      
      <figure xml:id="jurorHTPValueShown">
        <caption>The p-value for the juror hypothesis test is shaded in the chi-square distribution with <m>df=3</m>.</caption>
        <image source="ch_inference_for_props/jurorHTPValueShown/jurorHTPValueShown.png" width="55%">
          <description>A chi-square distribution with 3 degrees of freedom is shown, with the area above 5.89 shaded. This region appears to be about 10% of the area under the curve.</description>
        </image>
      </figure>
      
      <assemblage xml:id="assem-chi-square-one-way">
        <title>Chi-square test for one-way table</title>
        <p>
          Suppose we are to evaluate whether there is convincing evidence that a set of observed counts <m>O_1</m>, <m>O_2</m>, ..., <m>O_k</m> in <m>k</m> categories are unusually different from what might be expected under a null hypothesis. Call the <em>expected counts</em> that are based on the null hypothesis <m>E_1</m>, <m>E_2</m>, ..., <m>E_k</m>. If each expected count is at least 5 and the null hypothesis is true, then the test statistic below follows a chi-square distribution with <m>k-1</m> degrees of freedom:
        </p>
        <me>
          X^2 = \frac{(O_1 - E_1)^2}{E_1} + \frac{(O_2 - E_2)^2}{E_2} + \cdots + \frac{(O_k - E_k)^2}{E_k}
        </me>
        <p>
          The p-value for this test statistic is found by looking at the upper tail of this chi-square distribution. We consider the upper tail because larger values of <m>X^2</m> would provide greater evidence against the null hypothesis.
        </p>
      </assemblage>
      
      <assemblage xml:id="assem-chi-square-conditions">
        <title>Conditions for the chi-square test</title>
        <p>
          There are two conditions that must be checked before performing a chi-square test:
        </p>
        <dl>
          <li>
            <title>Independence.</title>
            <p>Each case that contributes a count to the table must be independent of all the other cases in the table.</p>
          </li>
          <li>
            <title>Sample size / distribution.</title>
            <p>Each particular scenario (i.e. cell count) must have at least 5 expected cases.</p>
          </li>
        </dl>
        <p>
          Failing to check conditions may affect the test's error rates.
        </p>
      </assemblage>
      
      <p>
        When examining a table with just two bins, pick a single bin and use the one-proportion methods introduced in Section<nbsp/><xref ref="singleProportion"/>.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-goodness-of-fit-distribution">
      <title>Evaluating goodness of fit for a distribution</title>
      
      <p>
        Section<nbsp/>3.5 would be useful background reading for this example, but it is not a prerequisite.
      </p>
      
      <p>
        We can apply the chi-square testing framework to the second problem in this section: evaluating whether a certain statistical model fits a data set. Daily stock returns from the S&amp;P500 for 10 years can be used to assess whether stock activity each day is independent of the stock's behavior on previous days. This sounds like a very complex question, and it is, but a chi-square test can be used to study the problem. We will label each day as Up or Down (D) depending on whether the market was up or down that day. For example, consider the following changes in price, their new labels of up and down, and then the number of days that must be observed before each Up day:
      </p>
      
      <table xml:id="tab-sp500-example-sequence">
        <title>Example sequence of daily price changes and waiting times.</title>
        <tabular>
          <row>
            <cell>Change in price</cell>
            <cell></cell>
            <cell>2.52</cell>
            <cell>-1.46</cell>
            <cell>0.51</cell>
            <cell>-4.07</cell>
            <cell>3.36</cell>
            <cell>1.10</cell>
            <cell>-5.46</cell>
            <cell>-1.03</cell>
            <cell>-2.99</cell>
            <cell>1.71</cell>
          </row>
          <row>
            <cell>Outcome</cell>
            <cell></cell>
            <cell>Up</cell>
            <cell>D</cell>
            <cell>Up</cell>
            <cell>D</cell>
            <cell>Up</cell>
            <cell>Up</cell>
            <cell>D</cell>
            <cell>D</cell>
            <cell>D</cell>
            <cell>Up</cell>
          </row>
          <row>
            <cell>Days to Up</cell>
            <cell></cell>
            <cell>1</cell>
            <cell>-</cell>
            <cell>2</cell>
            <cell>-</cell>
            <cell>2</cell>
            <cell>1</cell>
            <cell>-</cell>
            <cell>-</cell>
            <cell>-</cell>
            <cell>4</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        If the days really are independent, then the number of days until a positive trading day should follow a geometric distribution. The geometric distribution describes the probability of waiting for the <m>k^{th}</m> trial to observe the first success. Here each up day (Up) represents a success, and down (D) days represent failures. In the data above, it took only one day until the market was up, so the first wait time was 1 day. It took two more days before we observed our next Up trading day, and two more for the third Up day. We would like to determine if these counts (1, 2, 2, 1, 4, and so on) follow the geometric distribution. <xref ref="sAndP500TimeToPosTrade"/> shows the number of waiting days for a positive trading day during 10 years for the S&amp;P500.
      </p>
      
      <table xml:id="sAndP500TimeToPosTrade">
        <title>Observed distribution of the waiting time until a positive trading day for the S&amp;P500.</title>
        <tabular>
          <row bottom="minor">
            <cell>Days</cell>
            <cell></cell>
            <cell>1</cell>
            <cell>2</cell>
            <cell>3</cell>
            <cell>4</cell>
            <cell>5</cell>
            <cell>6</cell>
            <cell>7+</cell>
            <cell></cell>
            <cell>Total</cell>
          </row>
          <row bottom="minor">
            <cell>Observed</cell>
            <cell></cell>
            <cell>717</cell>
            <cell>369</cell>
            <cell>155</cell>
            <cell>69</cell>
            <cell>28</cell>
            <cell>14</cell>
            <cell>10</cell>
            <cell></cell>
            <cell>1362</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        We consider how many days one must wait until observing an Up day on the S&amp;P500 stock index. If the stock activity was independent from one day to the next and the probability of a positive trading day was constant, then we would expect this waiting time to follow a <em>geometric distribution</em>. We can organize this into a hypothesis framework:
      </p>
      <ul>
        <li><m>H_0</m>: The stock market being up or down on a given day is independent from all other days. We will consider the number of days that pass until an Up day is observed. Under this hypothesis, the number of days until an Up day should follow a geometric distribution.</li>
        <li><m>H_A</m>: The stock market being up or down on a given day is not independent from all other days. Since we know the number of days until an Up day would follow a geometric distribution under the null, we look for deviations from the geometric distribution, which would support the alternative hypothesis.</li>
      </ul>
      <p>
        There are important implications in our result for stock traders: if information from past trading days is useful in telling what will happen today, that information may provide an advantage over other traders.
      </p>
      
      <p>
        We consider data for the S&amp;P500 and summarize the waiting times in <xref ref="sAndP500TimeToPosTrade2"/> and <xref ref="geomFitEvaluationForSP500"/>. The S&amp;P500 was positive on 54.5% of those days.
      </p>
      
      <table xml:id="sAndP500TimeToPosTrade2">
        <title>Distribution of the waiting time until a positive trading day. The expected counts based on the geometric model are shown in the last row. To find each expected count, we identify the probability of waiting <m>D</m> days based on the geometric model (<m>P(D) = (1-0.545)^{D-1}(0.545)</m>) and multiply by the total number of streaks, 1362. For example, waiting for three days occurs under the geometric model about <m>0.455^2\times 0.545 = 0.1128 = 11.28\%</m> of the time, which corresponds to <m>0.1128 \times 1362 = 154</m> streaks.</title>
        <tabular>
          <row bottom="minor">
            <cell>Days</cell>
            <cell></cell>
            <cell>1</cell>
            <cell>2</cell>
            <cell>3</cell>
            <cell>4</cell>
            <cell>5</cell>
            <cell>6</cell>
            <cell>7+</cell>
            <cell></cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Observed</cell>
            <cell></cell>
            <cell>717</cell>
            <cell>369</cell>
            <cell>155</cell>
            <cell>69</cell>
            <cell>28</cell>
            <cell>14</cell>
            <cell>10</cell>
            <cell></cell>
            <cell>1362</cell>
          </row>
          <row bottom="minor">
            <cell>Geometric Model</cell>
            <cell></cell>
            <cell>743</cell>
            <cell>338</cell>
            <cell>154</cell>
            <cell>70</cell>
            <cell>32</cell>
            <cell>14</cell>
            <cell>12</cell>
            <cell></cell>
            <cell>1362</cell>
          </row>
        </tabular>
      </table>
      
      <figure xml:id="geomFitEvaluationForSP500">
        <caption>Side-by-side bar plot of the observed and expected counts for each waiting time.</caption>
        <image source="ch_inference_for_props/geomFitEvaluationForSP500/geomFitEvaluationForSP500.png" width="85%">
          <description>A side-by-side bar plot is shown for the variable "Wait Until Positive Day", where the two groups shown for the bars are "Observed counts" and "Expected counts". The horizontal axis shows values 1, 2, 3, 4, 5, 6, and "7+". The bar heights highest for "1" at roughly 715 for Observed and 740 for Expected. The bar heights for "2" are about half as high as at "1", with values of about 370 for Observed and 340 for Expected. The bar heights for "3" are about another half has high at about 150 for each for observed and expected. The values at 5, 6, and 7+ are all relatively small, at or below about 30.</description>
        </image>
      </figure>
      
      <p>
        Because applying the chi-square framework requires expected counts to be at least 5, we have <em>binned</em> together all the cases where the waiting time was at least 7 days to ensure each expected count is well above this minimum. The actual data, shown in the <em>Observed</em> row in <xref ref="sAndP500TimeToPosTrade2"/>, can be compared to the expected counts from the <em>Geometric Model</em> row. The method for computing expected counts is discussed in <xref ref="sAndP500TimeToPosTrade2"/>. In general, the expected counts are determined by (1) identifying the null proportion associated with each bin, then (2) multiplying each null proportion by the total count to obtain the expected counts. That is, this strategy identifies what proportion of the total count we would expect to be in each bin.
      </p>
      
      <example xml:id="ex-sp500-deviations">
        <statement>
          <p>
            Do you notice any unusually large deviations in the graph? Can you tell if these deviations are due to chance just by looking?
          </p>
        </statement>
        <solution>
          <p>
            It is not obvious whether differences in the observed counts and the expected counts from the geometric distribution are significantly different. That is, it is not clear whether these deviations might be due to chance or whether they are so strong that the data provide convincing evidence against the null hypothesis. However, we can perform a chi-square test using the counts in <xref ref="sAndP500TimeToPosTrade2"/>.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-sp500-chi-square-calc">
        <statement>
          <p>
            <xref ref="sAndP500TimeToPosTrade2"/> provides a set of count data for waiting times (<m>O_1=717</m>, <m>O_2=369</m>, ...) and expected counts under the geometric distribution (<m>E_1=743</m>, <m>E_2=338</m>, ...). Compute the chi-square test statistic, <m>X^2</m>.
          </p>
        </statement>
        <solution>
          <p>
            <m>X^2 = \frac{(717-743)^2}{743} + \frac{(369-338)^2}{338} + \cdots + \frac{(10-12)^2}{12} = 4.61</m>
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="ex-sp500-df">
        <statement>
          <p>
            Because the expected counts are all at least 5, we can safely apply the chi-square distribution to <m>X^2</m>. However, how many degrees of freedom should we use?
          </p>
        </statement>
        <solution>
          <p>
            There are <m>k = 7</m> groups, so we use <m>df = k - 1 = 6</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="DNRejectGeomModelForSP500">
        <statement>
          <p>
            If the observed counts follow the geometric model, then the chi-square test statistic <m>X^2 = 4.61</m> would closely follow a chi-square distribution with <m>df = 6</m>. Using this information, compute a p-value.
          </p>
        </statement>
        <solution>
          <p>
            <xref ref="geomFitPValueForSP500"/> shows the chi-square distribution, cutoff, and the shaded p-value. Using software, we can find the p-value: 0.5951. Ultimately, we do not have sufficient evidence to reject the notion that the wait times follow a geometric distribution for the last 10 years of data for the S&amp;P500, i.e. we cannot reject the notion that trading days are independent.
          </p>
        </solution>
      </example>
      
      <figure xml:id="geomFitPValueForSP500">
        <caption>Chi-square distribution with 6 degrees of freedom. The p-value for the stock analysis is shaded.</caption>
        <image source="ch_inference_for_props/geomFitPValueForSP500/geomFitPValueForSP500.png" width="74%">
          <description>A chi-square distribution with 6 degrees of freedom is shown, with the area above 4.61 shaded. This region appears to be about 60% of the area under the curve.</description>
        </image>
      </figure>
      
      <example xml:id="ex-sp500-interpretation">
        <statement>
          <p>
            In Example<nbsp/><xref ref="DNRejectGeomModelForSP500"/>, we did not reject the null hypothesis that the trading days are independent during the last 10 years of data. Why is this so important?
          </p>
        </statement>
        <solution>
          <p>
            It may be tempting to think the market is "due" for an Up day if there have been several consecutive days where it has been down. However, we haven't found strong evidence that there's any such property where the market is "due" for a correction. At the very least, the analysis suggests any dependence between days is very weak.
          </p>
        </solution>
      </example>
    </subsection>
    
    <exercises>
      <title>Section 6.3 Exercises</title>
      
      <exercise xml:id="tf_chisq_1">
        <title>True or false, Part I</title>
        <statement>
          <p>
            Determine if the statements below are true or false. For each false statement, suggest an alternative wording to make it a true statement.
          </p>
          <ol>
            <li>The chi-square distribution, just like the normal distribution, has two parameters, mean and standard deviation.</li>
            <li>The chi-square distribution is always right skewed, regardless of the value of the degrees of freedom parameter.</li>
            <li>The chi-square statistic is always positive.</li>
            <li>As the degrees of freedom increases, the shape of the chi-square distribution becomes more skewed.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="tf_chisq_2">
        <title>True or false, Part II</title>
        <statement>
          <p>
            Determine if the statements below are true or false. For each false statement, suggest an alternative wording to make it a true statement.
          </p>
          <ol>
            <li>As the degrees of freedom increases, the mean of the chi-square distribution increases.</li>
            <li>If you found <m>\chi^2 = 10</m> with <m>df = 5</m> you would fail to reject <m>H_0</m> at the 5% significance level.</li>
            <li>When finding the p-value of a chi-square test, we always shade the tail areas in both tails.</li>
            <li>As the degrees of freedom increases, the variability of the chi-square distribution decreases.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="opensource_text_chisq_GOF">
        <title>Open source textbook</title>
        <statement>
          <p>
            A professor using an open source introductory statistics book predicts that 60% of the students will purchase a hard copy of the book, 25% will print it out from the web, and 15% will read it online. At the end of the semester he asks his students to complete a survey where they indicate what format of the book they used. Of the 126 students, 71 said they bought a hard copy of the book, 30 said they printed it out from the web, and 25 said they read it online.
          </p>
          <ol>
            <li>State the hypotheses for testing if the professor's predictions were inaccurate.</li>
            <li>How many students did the professor expect to buy the book, print the book, and read the book exclusively online?</li>
            <li>This is an appropriate setting for a chi-square test. List the conditions required for a test and verify they are satisfied.</li>
            <li>Calculate the chi-squared statistic, the degrees of freedom associated with it, and the p-value.</li>
            <li>Based on the p-value calculated in part (d), what is the conclusion of the hypothesis test? Interpret your conclusion in this context.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="barking_deer_chisq_GOF">
        <title>Barking deer</title>
        <statement>
          <p>
            Microhabitat factors associated with forage and bed sites of barking deer in Hainan Island, China were examined. In this region woods make up 4.8% of the land, cultivated grass plot makes up 14.7%, and deciduous forests make up 39.6%. Of the 426 sites where the deer forage, 4 were categorized as woods, 16 as cultivated grassplot, and 61 as deciduous forests. The table below summarizes these data.
          </p>
          <table>
            <title>Barking deer forage sites by habitat type</title>
            <tabular>
              <row bottom="minor">
                <cell>Woods</cell>
                <cell>Cultivated grassplot</cell>
                <cell>Deciduous forests</cell>
                <cell>Other</cell>
                <cell>Total</cell>
              </row>
              <row>
                <cell>4</cell>
                <cell>16</cell>
                <cell>61</cell>
                <cell>345</cell>
                <cell>426</cell>
              </row>
            </tabular>
          </table>
          <ol>
            <li>Write the hypotheses for testing if barking deer prefer to forage in certain habitats over others.</li>
            <li>What type of test can we use to answer this research question?</li>
            <li>Check if the assumptions and conditions required for this test are satisfied.</li>
            <li>Do these data provide convincing evidence that barking deer prefer to forage in certain habitats over others? Conduct an appropriate hypothesis test to answer this research question.</li>
          </ol>
        </statement>
      </exercise>
      
    </exercises>
    
  </section>
  
  <!-- Section 6.4: Testing for independence in two-way tables -->
  <section xml:id="sec-chi-square-independence">
    <title>Testing for independence in two-way tables</title>
    
    <introduction>
      <p>
        We all buy used products <mdash/> cars, computers, textbooks, and so on <mdash/> and we sometimes assume the sellers of those products will be forthright about any underlying problems with what they're selling. This is not something we should take for granted. Researchers recruited 219 participants in a study where they would sell a used iPod<fn>For readers not as old as the authors, an iPod is basically an iPhone without any cellular service, assuming it was one of the later generations. Earlier generations were more basic.</fn> that was known to have frozen twice in the past. The participants were incentivized to get as much money as they could for the iPod since they would receive a 5% cut of the sale on top of $10 for participating. The researchers wanted to understand what types of questions would elicit the seller to disclose the freezing issue.
      </p>
      
      <p>
        Unbeknownst to the participants who were the sellers in the study, the buyers were collaborating with the researchers to evaluate the influence of different questions on the likelihood of getting the sellers to disclose the past issues with the iPod. The scripted buyers started with <q>Okay, I guess I'm supposed to go first. So you've had the iPod for 2 years <ellipsis/></q> and ended with one of three questions:
      </p>
      
      <ul>
        <li>General: What can you tell me about it?</li>
        <li>Positive Assumption: It doesn't have any problems, does it?</li>
        <li>Negative Assumption: What problems does it have?</li>
      </ul>
      
      <p>
        The question is the treatment given to the sellers, and the response is whether the question prompted them to disclose the freezing issue with the iPod. The results are shown in <xref ref="table-ipod-ask-data-summary"/>, and the data suggest that asking <em>What problems does it have?</em> was the most effective at getting the seller to disclose the past freezing issues. However, you should also be asking yourself: could we see these results due to chance alone, or is this in fact evidence that some questions are more effective for getting at the truth?
      </p>
      
      <table xml:id="table-ipod-ask-data-summary">
        <title>Summary of the iPod study, where a question was posed to the study participant who acted as the seller</title>
        <tabular>
          <row bottom="minor">
            <cell></cell>
            <cell>General</cell>
            <cell>Positive Assumption</cell>
            <cell>Negative Assumption</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Disclose Problem</cell>
            <cell>2</cell>
            <cell>23</cell>
            <cell>36</cell>
            <cell>61</cell>
          </row>
          <row>
            <cell>Hide Problem</cell>
            <cell>71</cell>
            <cell>50</cell>
            <cell>37</cell>
            <cell>158</cell>
          </row>
          <row bottom="minor">
            <cell>Total</cell>
            <cell>73</cell>
            <cell>73</cell>
            <cell>73</cell>
            <cell>219</cell>
          </row>
        </tabular>
      </table>
      
      <assemblage>
        <title>Differences of one-way tables vs two-way tables</title>
        <p>
          A one-way table describes counts for each outcome in a single variable. A two-way table describes counts for <em>combinations</em> of outcomes for two variables. When we consider a two-way table, we often would like to know, are these variables related in any way? That is, are they dependent (versus independent)?
        </p>
      </assemblage>
      
      <p>
        The hypothesis test for the iPod experiment is really about assessing whether there is statistically significant evidence of the success each question had on getting the participant to disclose the problem with the iPod. In other words, the goal is to check whether the buyer's question was independent of whether the seller disclosed a problem.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-expected-counts-two-way">
      <title>Expected counts in two-way tables</title>
      
      <p>
        Like with one-way tables, we will need to compute estimated counts for each cell in a two-way table.
      </p>
      
      <example xml:id="ex-ipod-compute-exp-aa">
        <title>Computing expected counts for the General group</title>
        <statement>
          <p>
            From the experiment, we can compute the proportion of all sellers who disclosed the freezing problem as <m>61/219 = 0.2785</m>. If there really is no difference among the questions and 27.85% of sellers were going to disclose the freezing problem no matter the question that was put to them, how many of the 73 people in the General group would we have expected to disclose the freezing problem?
          </p>
        </statement>
        <solution>
          <p>
            We would predict that <m>0.2785 \times 73 = 20.33</m> sellers would disclose the problem. Obviously we observed fewer than this, though it is not yet clear if that is due to chance variation or whether that is because the questions vary in how effective they are at getting to the truth.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="exercise-ipod-compute-exp-bb">
        <statement>
          <p>
            If the questions were actually equally effective, meaning about 27.85% of respondents would disclose the freezing issue regardless of what question they were asked, about how many sellers would we expect to <em>hide</em> the freezing problem from the Positive Assumption group?
          </p>
        </statement>
        <solution>
          <p>
            We would expect <m>(1 - 0.2785) \times 73 = 52.67</m>. It is okay that this result, like the result from <xref ref="ex-ipod-compute-exp-aa"/>, is a fraction.
          </p>
        </solution>
      </exercise>
      
      <p>
        We can compute the expected number of sellers who we would expect to disclose or hide the freezing issue for all groups, if the questions had no impact on what they disclosed, using the same strategy employed in <xref ref="ex-ipod-compute-exp-aa"/> and <xref ref="exercise-ipod-compute-exp-bb"/>. These expected counts were used to construct <xref ref="table-ipod-ask-expected"/>, which is the same as <xref ref="table-ipod-ask-data-summary"/>, except now the expected counts have been added in parentheses.
      </p>
      
      <table xml:id="table-ipod-ask-expected">
        <title>The observed counts and the (expected counts)</title>
        <tabular>
          <row bottom="minor">
            <cell></cell>
            <cell>General</cell>
            <cell>Positive Assumption</cell>
            <cell>Negative Assumption</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Disclose Problem</cell>
            <cell>2 (20.33)</cell>
            <cell>23 (20.33)</cell>
            <cell>36 (20.33)</cell>
            <cell>61</cell>
          </row>
          <row>
            <cell>Hide Problem</cell>
            <cell>71 (52.67)</cell>
            <cell>50 (52.67)</cell>
            <cell>37 (52.67)</cell>
            <cell>158</cell>
          </row>
          <row bottom="minor">
            <cell>Total</cell>
            <cell>73</cell>
            <cell>73</cell>
            <cell>73</cell>
            <cell>219</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        The examples and exercises above provided some help in computing expected counts. In general, expected counts for a two-way table may be computed using the row totals, column totals, and the table total. For instance, if there was no difference between the groups, then about 27.85% of each column should be in the first row:
      </p>
      
      <md>
        <mrow>0.2785 \times (\text{column 1 total}) \amp= 20.33</mrow>
        <mrow>0.2785 \times (\text{column 2 total}) \amp= 20.33</mrow>
        <mrow>0.2785 \times (\text{column 3 total}) \amp= 20.33</mrow>
      </md>
      
      <p>
        Looking back to how 0.2785 was computed <mdash/> as the fraction of sellers who disclosed the freezing issue (<m>61/219</m>) <mdash/> these three expected counts could have been computed as
      </p>
      
      <md>
        <mrow>\left(\frac{\text{row 1 total}}{\text{table total}}\right) \text{(column 1 total)} \amp= 20.33</mrow>
        <mrow>\left(\frac{\text{row 1 total}}{\text{table total}}\right) \text{(column 2 total)} \amp= 20.33</mrow>
        <mrow>\left(\frac{\text{row 1 total}}{\text{table total}}\right) \text{(column 3 total)} \amp= 20.33</mrow>
      </md>
      
      <p>
        This leads us to a general formula for computing expected counts in a two-way table when we would like to test whether there is strong evidence of an association between the column variable and row variable.
      </p>
      
      <assemblage xml:id="assem-expected-counts-two-way">
        <title>Computing expected counts in a two-way table</title>
        <p>
          To identify the expected count for the <m>i^{th}</m> row and <m>j^{th}</m> column, compute
        </p>
        <me>
          \text{Expected Count}_{\text{row }i,\text{ col }j} = \frac{(\text{row }i\text{ total}) \times (\text{column }j\text{ total})}{\text{table total}}
        </me>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-test-two-way">
      <title>The chi-square test for two-way tables</title>
      
      <p>
        The chi-square test statistic for a two-way table is found the same way it is found for a one-way table. For each table count, compute
      </p>
      
      <md>
        <mrow>\text{General formula:} \quad \amp \frac{(\text{observed count } - \text{expected count})^2}{\text{expected count}}</mrow>
        <mrow>\text{Row 1, Col 1:} \quad \amp \frac{(2 - 20.33)^2}{20.33} = 16.53</mrow>
        <mrow>\text{Row 1, Col 2:} \quad \amp \frac{(23 - 20.33)^2}{20.33} = 0.35</mrow>
        <mrow>\amp \vdots</mrow>
        <mrow>\text{Row 2, Col 3:} \quad \amp \frac{(37 - 52.67)^2}{52.67} = 4.66</mrow>
      </md>
      
      <p>
        Adding the computed value for each cell gives the chi-square test statistic <m>X^2</m>:
      </p>
      
      <me>
        X^2 = 16.53 + 0.35 + \cdots + 4.66 = 40.13
      </me>
      
      <p>
        Just like before, this test statistic follows a chi-square distribution. However, the degrees of freedom are computed a little differently for a two-way table.<fn>Recall: in the one-way table, the degrees of freedom was the number of cells minus 1.</fn> For two-way tables, the degrees of freedom is equal to
      </p>
      
      <me>
        df = \text{(number of rows minus 1)}\times \text{(number of columns minus 1)}
      </me>
      
      <p>
        In our example, the degrees of freedom parameter is
      </p>
      
      <me>
        df = (2-1)\times (3-1) = 2
      </me>
      
      <p>
        If the null hypothesis is true (i.e. the questions had no impact on the sellers in the experiment), then the test statistic <m>X^2 = 40.13</m> closely follows a chi-square distribution with 2 degrees of freedom. Using this information, we can compute the p-value for the test, which is depicted in <xref ref="fig-ipod-chi-sq-tail"/>.
      </p>
      
      <assemblage xml:id="assem-df-two-way">
        <title>Computing degrees of freedom for a two-way table</title>
        <p>
          When applying the chi-square test to a two-way table, we use
        </p>
        <me>
          df = (R-1)\times (C-1)
        </me>
        <p>
          where <m>R</m> is the number of rows in the table and <m>C</m> is the number of columns.
        </p>
      </assemblage>
      
      <p>
        When analyzing 2-by-2 contingency tables, one guideline is to use the two-proportion methods introduced in Section<nbsp/>6.2.
      </p>
      
      <figure xml:id="fig-ipod-chi-sq-tail">
        <caption>Visualization of the p-value for <m>X^2 = 40.13</m> when <m>df = 2</m></caption>
        <image source="ch_inference_for_props/iPodChiSqTail/iPodChiSqTail.png" width="65%"/>
      </figure>
      
      <example xml:id="ex-ipod-pvalue">
        <title>Finding the p-value for the iPod experiment</title>
        <statement>
          <p>
            Find the p-value and draw a conclusion about whether the question affects the seller's likelihood of reporting the freezing problem.
          </p>
        </statement>
        <solution>
          <p>
            Using a computer, we can compute a very precise value for the tail area above <m>X^2 = 40.13</m> for a chi-square distribution with 2 degrees of freedom: 0.000000002. (If using the table in Appendix<nbsp/>C, we would identify the p-value is smaller than 0.001.) Using a significance level of <m>\alpha=0.05</m>, the null hypothesis is rejected since the p-value is smaller. That is, the data provide convincing evidence that the question asked did affect a seller's likelihood to tell the truth about problems with the iPod.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-diabetes-hypotheses">
        <title>Diabetes treatment study hypotheses</title>
        <statement>
          <p>
            <xref ref="table-diabetes-summary"/> summarizes the results of an experiment evaluating three treatments for Type<nbsp/>2 Diabetes in patients aged 10-17 who were being treated with metformin. The three treatments considered were continued treatment with metformin (met), treatment with metformin combined with rosiglitazone (rosi), or a lifestyle intervention program. Each patient had a primary outcome, which either lacked glycemic control (failure) or did not lack that control (success). What are appropriate hypotheses for this test?
          </p>
        </statement>
        <solution>
          <p>
            <ul>
              <li><m>H_0</m>: There is no difference in the effectiveness of the three treatments.</li>
              <li><m>H_A</m>: There is some difference in effectiveness between the three treatments, e.g. perhaps the rosi treatment performed better than lifestyle.</li>
            </ul>
          </p>
        </solution>
      </example>
      
      <table xml:id="table-diabetes-summary">
        <title>Results for the Type<nbsp/>2 Diabetes study</title>
        <tabular>
          <row bottom="minor">
            <cell></cell>
            <cell>Failure</cell>
            <cell>Success</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>lifestyle</cell>
            <cell>109</cell>
            <cell>125</cell>
            <cell>234</cell>
          </row>
          <row>
            <cell>met</cell>
            <cell>120</cell>
            <cell>112</cell>
            <cell>232</cell>
          </row>
          <row>
            <cell>rosi</cell>
            <cell>90</cell>
            <cell>143</cell>
            <cell>233</cell>
          </row>
          <row bottom="minor">
            <cell>Total</cell>
            <cell>319</cell>
            <cell>380</cell>
            <cell>699</cell>
          </row>
        </tabular>
      </table>
      
      <exercise xml:id="exercise-diabetes-expected">
        <statement>
          <p>
            A chi-square test for a two-way table may be used to test the hypotheses in <xref ref="ex-diabetes-hypotheses"/>. As a first step, compute the expected values for each of the six table cells.
          </p>
        </statement>
        <solution>
          <p>
            The expected count for row one / column one is found by multiplying the row one total (234) and column one total (319), then dividing by the table total (699): <m>\frac{234\times 319}{699} = 106.8</m>. Similarly for the second column and the first row: <m>\frac{234\times 380}{699} = 127.2</m>. Row 2: 105.9 and 126.1. Row 3: 106.3 and 126.7.
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="exercise-diabetes-chi-square">
        <statement>
          <p>
            Compute the chi-square test statistic for the data in <xref ref="table-diabetes-summary"/>.
          </p>
        </statement>
        <solution>
          <p>
            For each cell, compute <m>\frac{(\text{obs} - \text{exp})^2}{\text{exp}}</m>. For instance, the first row and first column: <m>\frac{(109-106.8)^2}{106.8} = 0.05</m>. Adding the results of each cell gives the chi-square test statistic: <m>X^2 = 0.05 + \cdots + 2.11 = 8.16</m>.
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="exercise-diabetes-conclusion">
        <statement>
          <p>
            Because there are 3 rows and 2 columns, the degrees of freedom for the test is <m>df = (3 - 1) \times (2 - 1) = 2</m>. Use <m>X^2 = 8.16</m>, <m>df = 2</m>, and evaluate whether to reject the null hypothesis using a significance level of 0.05.
          </p>
        </statement>
        <solution>
          <p>
            If using a computer, we can identify the p-value as 0.017. That is, we reject the null hypothesis because the p-value is less than 0.05, and we conclude that at least one of the treatments is more or less effective than the others at treating Type<nbsp/>2 Diabetes for glycemic control.
          </p>
        </solution>
      </exercise>
    </subsection>
    
    <exercises>
      <title>Section Exercises</title>
      
      <exercise xml:id="exercise-quitters">
        <title>Quitters</title>
        <statement>
          <p>
            Does being part of a support group affect the ability of people to quit smoking? A county health department enrolled 300 smokers in a randomized experiment. 150 participants were assigned to a group that used a nicotine patch and met weekly with a support group; the other 150 received the patch and did not meet with a support group. At the end of the study, 40 of the participants in the patch plus support group had quit smoking while only 30 smokers had quit in the other group.
          </p>
          <ol>
            <li>Create a two-way table presenting the results of this study.</li>
            <li>
              <p>
                Answer each of the following questions under the null hypothesis that being part of a support group does not affect the ability of people to quit smoking, and indicate whether the expected values are higher or lower than the observed values.
              </p>
              <ol>
                <li>How many subjects in the <q>patch + support</q> group would you expect to quit?</li>
                <li>How many subjects in the <q>patch only</q> group would you expect to not quit?</li>
              </ol>
            </li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="exercise-full-body-scan-part-ii">
        <title>Full body scan, Part II</title>
        <statement>
          <p>
            The table below summarizes a data set we first encountered in an earlier exercise regarding views on full-body scans and political affiliation. The differences in each political group may be due to chance. Complete the following computations under the null hypothesis of independence between an individual's party affiliation and their support of full-body scans. It may be useful to first add on an extra column for row totals before proceeding with the computations.
          </p>
          
          <table>
            <title>Full-body scan data by party affiliation</title>
            <tabular>
              <row bottom="minor">
                <cell></cell>
                <cell></cell>
                <cell colspan="3" halign="center">Party Affiliation</cell>
              </row>
              <row bottom="minor">
                <cell></cell>
                <cell></cell>
                <cell>Republican</cell>
                <cell>Democrat</cell>
                <cell>Independent</cell>
              </row>
              <row>
                <cell></cell>
                <cell>Should</cell>
                <cell>264</cell>
                <cell>299</cell>
                <cell>351</cell>
              </row>
              <row>
                <cell>Answer</cell>
                <cell>Should not</cell>
                <cell>38</cell>
                <cell>55</cell>
                <cell>77</cell>
              </row>
              <row>
                <cell></cell>
                <cell>Don't know/No answer</cell>
                <cell>16</cell>
                <cell>15</cell>
                <cell>22</cell>
              </row>
              <row bottom="minor">
                <cell></cell>
                <cell>Total</cell>
                <cell>318</cell>
                <cell>369</cell>
                <cell>450</cell>
              </row>
            </tabular>
          </table>
          
          <ol>
            <li>How many Republicans would you expect to not support the use of full-body scans?</li>
            <li>How many Democrats would you expect to support the use of full-body scans?</li>
            <li>How many Independents would you expect to not know or not answer?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="exercise-offshore-drilling-part-iii">
        <title>Offshore drilling, Part III</title>
        <statement>
          <p>
            The table below summarizes a data set we first encountered in an earlier exercise that examines the responses of a random sample of college graduates and non-graduates on the topic of oil drilling. Complete a chi-square test for these data to check whether there is a statistically significant difference in responses from college graduates and non-graduates.
          </p>
          
          <table>
            <title>Offshore drilling data by college graduate status</title>
            <tabular>
              <row bottom="minor">
                <cell></cell>
                <cell colspan="2" halign="center">College Grad</cell>
              </row>
              <row bottom="minor">
                <cell></cell>
                <cell>Yes</cell>
                <cell>No</cell>
              </row>
              <row>
                <cell>Support</cell>
                <cell>154</cell>
                <cell>132</cell>
              </row>
              <row>
                <cell>Oppose</cell>
                <cell>180</cell>
                <cell>126</cell>
              </row>
              <row>
                <cell>Do not know</cell>
                <cell>104</cell>
                <cell>131</cell>
              </row>
              <row bottom="minor">
                <cell>Total</cell>
                <cell>438</cell>
                <cell>389</cell>
              </row>
            </tabular>
          </table>
        </statement>
      </exercise>
      
      <exercise xml:id="exercise-parasitic-worm">
        <title>Parasitic worm</title>
        <statement>
          <p>
            Lymphatic filariasis is a disease caused by a parasitic worm. Complications of the disease can lead to extreme swelling and other complications. Here we consider results from a randomized experiment that compared three different drug treatment options to clear people of this parasite, which people are working to eliminate entirely. The results for the second year of the study are given below:
          </p>
          
          <table>
            <title>Parasitic worm treatment results</title>
            <tabular>
              <row bottom="minor">
                <cell></cell>
                <cell>Clear at Year 2</cell>
                <cell>Not Clear at Year 2</cell>
              </row>
              <row>
                <cell>Three drugs</cell>
                <cell>52</cell>
                <cell>2</cell>
              </row>
              <row>
                <cell>Two drugs</cell>
                <cell>31</cell>
                <cell>24</cell>
              </row>
              <row>
                <cell>Two drugs annually</cell>
                <cell>42</cell>
                <cell>14</cell>
              </row>
            </tabular>
          </table>
          
          <ol>
            <li>Set up hypotheses for evaluating whether there is any difference in the performance of the treatments, and also check conditions.</li>
            <li>
              <p>
                Statistical software was used to run a chi-square test, which output:
              </p>
              <md>
                <mrow>X^2 = 23.7 \qquad df = 2 \qquad \text{p-value} = 7.2\text{e-}6</mrow>
              </md>
              <p>
                Use these results to evaluate the hypotheses from part (a), and provide a conclusion in the context of the problem.
              </p>
            </li>
          </ol>
        </statement>
      </exercise>
    </exercises>
  </section>
  
  <!-- Section 6.5: Chapter review -->
  <section xml:id="sec-ch06-review">
    <title>Chapter 6 Review Exercises</title>
    
    <p>
      This chapter covered inference for categorical data. Key concepts include confidence intervals and hypothesis tests for a single proportion, sample size calculations for proportions, comparing two proportions, the pooled proportion for hypothesis testing, chi-square goodness of fit tests, and chi-square tests for independence in two-way tables.
    </p>
    
    <exercises>
      <title>Chapter 6 Review Exercises</title>
      
      <exercise xml:id="ex-active-learning">
        <statement>
          <p>
            A teacher wanting to increase the active learning component of her course is concerned about student reactions to changes she is planning to make. She conducts a survey in her class, asking students whether they believe more active learning in the classroom (hands on exercises) instead of traditional lecture will help improve their learning. She does this at the beginning and end of the semester and wants to evaluate whether students' opinions have changed over the semester. Can she use the methods we learned in this chapter for this analysis? Explain your reasoning.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-website-experiment">
        <statement>
          <p>
            The OpenIntro website occasionally experiments with design and link placement. We conducted one experiment testing three different placements of a download link for this textbook on the book's main page to see which location, if any, led to the most downloads. The number of site visitors included in the experiment was 701 and is captured in one of the response combinations in the following table:
          </p>
          <table>
            <tabular halign="center">
              <row bottom="minor">
                <cell></cell>
                <cell>Download</cell>
                <cell>No Download</cell>
              </row>
              <row>
                <cell>Position 1</cell>
                <cell>13.8%</cell>
                <cell>18.3%</cell>
              </row>
              <row>
                <cell>Position 2</cell>
                <cell>14.6%</cell>
                <cell>18.5%</cell>
              </row>
              <row bottom="minor">
                <cell>Position 3</cell>
                <cell>12.1%</cell>
                <cell>22.7%</cell>
              </row>
            </tabular>
          </table>
          <ol>
            <li>Calculate the actual number of site visitors in each of the six response categories.</li>
            <li>Each individual in the experiment had an equal chance of being in any of the three experiment groups. However, we see that there are slightly different totals for the groups. Is there any evidence that the groups were actually imbalanced? Make sure to clearly state hypotheses, check conditions, calculate the appropriate test statistic and the p-value, and make your conclusion in context of the data.</li>
            <li>Complete an appropriate hypothesis test to check whether there is evidence that there is a higher rate of site visitors clicking on the textbook link in any of the three groups.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-shipping-gifts">
        <statement>
          <p>
            A local news survey asked 500 randomly sampled Los Angeles residents which shipping carrier they prefer to use for shipping holiday gifts. The table below shows the distribution of responses by age group as well as the expected counts for each cell (shown in parentheses).
          </p>
          <table>
            <tabular halign="center">
              <row bottom="minor">
                <cell></cell>
                <cell></cell>
                <cell colspan="2">18-34</cell>
                <cell colspan="2">35-54</cell>
                <cell colspan="2">55+</cell>
                <cell>Total</cell>
              </row>
              <row>
                <cell>Shipping</cell>
                <cell>USPS</cell>
                <cell>72</cell>
                <cell>(81)</cell>
                <cell>97</cell>
                <cell>(102)</cell>
                <cell>76</cell>
                <cell>(62)</cell>
                <cell>245</cell>
              </row>
              <row>
                <cell>Method</cell>
                <cell>UPS</cell>
                <cell>52</cell>
                <cell>(53)</cell>
                <cell>76</cell>
                <cell>(68)</cell>
                <cell>34</cell>
                <cell>(41)</cell>
                <cell>162</cell>
              </row>
              <row>
                <cell></cell>
                <cell>FedEx</cell>
                <cell>31</cell>
                <cell>(21)</cell>
                <cell>24</cell>
                <cell>(27)</cell>
                <cell>9</cell>
                <cell>(16)</cell>
                <cell>64</cell>
              </row>
              <row>
                <cell></cell>
                <cell>Something else</cell>
                <cell>7</cell>
                <cell>(5)</cell>
                <cell>6</cell>
                <cell>(7)</cell>
                <cell>3</cell>
                <cell>(4)</cell>
                <cell>16</cell>
              </row>
              <row>
                <cell></cell>
                <cell>Not sure</cell>
                <cell>3</cell>
                <cell>(5)</cell>
                <cell>6</cell>
                <cell>(5)</cell>
                <cell>4</cell>
                <cell>(3)</cell>
                <cell>13</cell>
              </row>
              <row bottom="minor">
                <cell></cell>
                <cell>Total</cell>
                <cell colspan="2">165</cell>
                <cell colspan="2">209</cell>
                <cell colspan="2">126</cell>
                <cell>500</cell>
              </row>
            </tabular>
          </table>
          <ol>
            <li>State the null and alternative hypotheses for testing for independence of age and preferred shipping method for holiday gifts among Los Angeles residents.</li>
            <li>Are the conditions for inference using a chi-square test satisfied?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-civil-war">
        <statement>
          <p>
            A national survey conducted among a simple random sample of 1,507 adults shows that 56% of Americans think the Civil War is still relevant to American politics and political life.
          </p>
          <ol>
            <li>Conduct a hypothesis test to determine if these data provide strong evidence that the majority of the Americans think the Civil War is still relevant.</li>
            <li>Interpret the p-value in this context.</li>
            <li>Calculate a 90% confidence interval for the proportion of Americans who think the Civil War is still relevant. Interpret the interval in this context, and comment on whether or not the confidence interval agrees with the conclusion of the hypothesis test.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-college-smokers">
        <statement>
          <p>
            We are interested in estimating the proportion of students at a university who smoke. Out of a random sample of 200 students from this university, 40 students smoke.
          </p>
          <ol>
            <li>Calculate a 95% confidence interval for the proportion of students at this university who smoke, and interpret this interval in context. (Reminder: Check conditions.)</li>
            <li>If we wanted the margin of error to be no larger than 2% at a 95% confidence level for the proportion of students who smoke, how big of a sample would we need?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-acetaminophen">
        <statement>
          <p>
            It is believed that large doses of acetaminophen (the active ingredient in over the counter pain relievers like Tylenol) may cause damage to the liver. A researcher wants to conduct a study to estimate the proportion of acetaminophen users who have liver damage. For participating in this study, he will pay each subject $20 and provide a free medical consultation if the patient has liver damage.
          </p>
          <ol>
            <li>If he wants to limit the margin of error of his 98% confidence interval to 2%, what is the minimum amount of money he needs to set aside to pay his subjects?</li>
            <li>The amount you calculated in part (a) is substantially over his budget so he decides to use fewer subjects. How will this affect the width of his confidence interval?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-life-after-college">
        <statement>
          <p>
            We are interested in estimating the proportion of graduates at a mid-sized university who found a job within one year of completing their undergraduate degree. Suppose we conduct a survey and find out that 348 of the 400 randomly sampled graduates found jobs. The graduating class under consideration included over 4500 students.
          </p>
          <ol>
            <li>Describe the population parameter of interest. What is the value of the point estimate of this parameter?</li>
            <li>Check if the conditions for constructing a confidence interval based on these data are met.</li>
            <li>Calculate a 95% confidence interval for the proportion of graduates who found a job within one year of completing their undergraduate degree at this university, and interpret it in the context of the data.</li>
            <li>What does <q>95% confidence</q> mean?</li>
            <li>Now calculate a 99% confidence interval for the same parameter and interpret it in the context of the data.</li>
            <li>Compare the widths of the 95% and 99% confidence intervals. Which one is wider? Explain.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-diabetes-unemployment">
        <statement>
          <p>
            A Gallup poll surveyed Americans about their employment status and whether or not they have diabetes. The survey results indicate that 1.5% of the 47,774 employed (full or part time) and 2.5% of the 5,855 unemployed 18-29 year olds have diabetes.
          </p>
          <ol>
            <li>Create a two-way table presenting the results of this study.</li>
            <li>State appropriate hypotheses to test for difference in proportions of diabetes between employed and unemployed Americans.</li>
            <li>The sample difference is about 1%. If we completed the hypothesis test, we would find that the p-value is very small (about 0), meaning the difference is statistically significant. Use this result to explain the difference between statistically significant and practically significant findings.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-rock-paper-scissors">
        <statement>
          <p>
            Rock-paper-scissors is a hand game played by two or more people where players choose to sign either rock, paper, or scissors with their hands. For your statistics class project, you want to evaluate whether players choose between these three options randomly, or if certain options are favored above others. You ask two friends to play rock-paper-scissors and count the times each option is played. The following table summarizes the data:
          </p>
          <table>
            <tabular halign="center">
              <row bottom="minor">
                <cell>Rock</cell>
                <cell>Paper</cell>
                <cell>Scissors</cell>
              </row>
              <row>
                <cell>43</cell>
                <cell>21</cell>
                <cell>35</cell>
              </row>
            </tabular>
          </table>
          <p>
            Use these data to evaluate whether players choose between these three options randomly, or if certain options are favored above others. Make sure to clearly outline each step of your analysis, and interpret your results in context of the data and the research question.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-healthcare-law">
        <statement>
          <p>
            On June 28, 2012 the U.S. Supreme Court upheld the much debated 2010 healthcare law, declaring it constitutional. A Gallup poll released the day after this decision indicates that 46% of 1,012 Americans agree with this decision. At a 95% confidence level, this sample has a 3% margin of error. Based on this information, determine if the following statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>We are 95% confident that between 43% and 49% of Americans in this sample support the decision of the U.S. Supreme Court on the 2010 healthcare law.</li>
            <li>We are 95% confident that between 43% and 49% of Americans support the decision of the U.S. Supreme Court on the 2010 healthcare law.</li>
            <li>If we considered many random samples of 1,012 Americans, and we calculated the sample proportions of those who support the decision of the U.S. Supreme Court, 95% of those sample proportions will be between 43% and 49%.</li>
            <li>The margin of error at a 90% confidence level would be higher than 3%.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-mobile-browsing">
        <statement>
          <p>
            A survey of 2,254 American adults indicates that 17% of cell phone owners browse the internet exclusively on their phone rather than a computer or other device.
          </p>
          <ol>
            <li>According to an online article, a report from a mobile research company indicates that 38 percent of Chinese mobile web users only access the internet through their cell phones. Conduct a hypothesis test to determine if these data provide strong evidence that the proportion of Americans who only use their cell phones to access the internet is different than the Chinese proportion of 38%.</li>
            <li>Interpret the p-value in this context.</li>
            <li>Calculate a 95% confidence interval for the proportion of Americans who access the internet on their cell phones, and interpret the interval in this context.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-coffee-depression">
        <statement>
          <p>
            Researchers conducted a study investigating the relationship between caffeinated coffee consumption and risk of depression in women. They collected data on 50,739 women free of depression symptoms at the start of the study in the year 1996, and these women were followed through 2006. The researchers used questionnaires to collect data on caffeinated coffee consumption, asked each individual about physician-diagnosed depression, and also asked about the use of antidepressants. The table below shows the distribution of incidences of depression by amount of caffeinated coffee consumption.
          </p>
          <table>
            <tabular halign="center">
              <row bottom="minor">
                <cell></cell>
                <cell></cell>
                <cell><m>\le</m> 1 cup/week</cell>
                <cell>2-6 cups/week</cell>
                <cell>1 cup/day</cell>
                <cell>2-3 cups/day</cell>
                <cell><m>\ge</m> 4 cups/day</cell>
                <cell>Total</cell>
              </row>
              <row>
                <cell>Clinical</cell>
                <cell>Yes</cell>
                <cell>670</cell>
                <cell>373</cell>
                <cell>905</cell>
                <cell>564</cell>
                <cell>95</cell>
                <cell>2,607</cell>
              </row>
              <row>
                <cell>depression</cell>
                <cell>No</cell>
                <cell>11,545</cell>
                <cell>6,244</cell>
                <cell>16,329</cell>
                <cell>11,726</cell>
                <cell>2,288</cell>
                <cell>48,132</cell>
              </row>
              <row bottom="minor">
                <cell></cell>
                <cell>Total</cell>
                <cell>12,215</cell>
                <cell>6,617</cell>
                <cell>17,234</cell>
                <cell>12,290</cell>
                <cell>2,383</cell>
                <cell>50,739</cell>
              </row>
            </tabular>
          </table>
          <ol>
            <li>What type of test is appropriate for evaluating if there is an association between coffee intake and depression?</li>
            <li>Write the hypotheses for the test you identified in part (a).</li>
            <li>Calculate the overall proportion of women who do and do not suffer from depression.</li>
            <li>Identify the expected count for the highlighted cell (the cell with 373), and calculate the contribution of this cell to the test statistic, i.e. <m>(Observed - Expected)^2 / Expected</m>.</li>
            <li>The test statistic is <m>\chi^2 = 20.93</m>. What is the p-value?</li>
            <li>What is the conclusion of the hypothesis test?</li>
            <li>One of the authors of this study was quoted on the NYTimes as saying it was <q>too early to recommend that women load up on extra coffee</q> based on just this study. Do you agree with this statement? Explain your reasoning.</li>
          </ol>
        </statement>
      </exercise>
    </exercises>
  </section>
</chapter>
