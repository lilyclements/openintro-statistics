<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="ch-inference-for-props" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Inference for Categorical Data</title>
  
  <introduction>
    <p>
      In this chapter, we apply the methods and ideas from Chapter 5 in several contexts for
      categorical data. We'll start by revisiting what we learned for a single proportion, where
      the normal distribution can be used to model the uncertainty in the sample proportion. Next,
      we apply these same ideas to analyze the difference of two proportions using the normal model.
      Later in the chapter, we apply inference techniques to contingency tables; while we will use
      a different distribution in this context, the core ideas of hypothesis testing remain the same.
    </p>
  </introduction>
  
  <!-- Section 6.1: Inference for a single proportion -->
  <section xml:id="singleProportion">
    <title>Inference for a single proportion</title>
    
    <introduction>
      <p>
        We encountered inference methods for a single proportion in Chapter 5, exploring point estimates, confidence intervals, and hypothesis tests. In this section, we'll do a review of these topics and also how to choose an appropriate sample size when collecting data for single proportion contexts.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-sample-prop-normal">
      <title>Identifying when the sample proportion is nearly normal</title>
      
      <p>
        A sample proportion <m>\hat{p}</m> can be modeled using a normal distribution when the sample observations are independent and the sample size is sufficiently large.
      </p>
      
      <assemblage xml:id="assem-sampling-dist-p-hat">
        <title>Sampling distribution of <m>\hat{p}</m></title>
        <p>
          The sampling distribution for <m>\hat{p}</m> based on a sample of size <m>n</m> from a population with a true proportion <m>p</m> is nearly normal when:
        </p>
        <ol>
          <li>
            <p>
              The sample's observations are independent, e.g. are from a simple random sample.
            </p>
          </li>
          <li>
            <p>
              We expected to see at least 10 successes and 10 failures in the sample, i.e. <m>np\geq10</m> and <m>n(1-p)\geq10</m>. This is called the <term>success-failure condition</term>.
            </p>
          </li>
        </ol>
        <p>
          When these conditions are met, then the sampling distribution of <m>\hat{p}</m> is nearly normal with mean <m>p</m> and standard error <m>SE = \sqrt{\frac{p(1-p)}{n}}</m>.
        </p>
      </assemblage>
      
      <p>
        Typically we don't know the true proportion <m>p</m>, so we substitute some value to check conditions and estimate the standard error. For confidence intervals, the sample proportion <m>\hat{p}</m> is used to check the success-failure condition and compute the standard error. For hypothesis tests, typically the null value<mdash/>that is, the proportion claimed in the null hypothesis<mdash/>is used in place of <m>p</m>.
      </p>
    </subsection>
    
    <subsection xml:id="confIntForPropSection">
      <title>Confidence intervals for a proportion</title>
      
      <p>
        A confidence interval provides a range of plausible values for the parameter <m>p</m>, and when <m>\hat{p}</m> can be modeled using a normal distribution, the confidence interval for <m>p</m> takes the form
      </p>
      <md>
        <mrow>\hat{p} \pm z^{\star} \times SE</mrow>
      </md>
      
      <example xml:id="ex-payday-regulation-normal">
        <statement>
          <p>
            A simple random sample of 826 payday loan borrowers was surveyed to better understand their interests around regulation and costs. 70% of the responses supported new regulations on payday lenders. Is it reasonable to model <m>\hat{p} = 0.70</m> using a normal distribution?
          </p>
        </statement>
        <solution>
          <p>
            The data are a random sample, so the observations are independent and representative of the population of interest.
          </p>
          <p>
            We also must check the success-failure condition, which we do using <m>\hat{p}</m> in place of <m>p</m> when computing a confidence interval:
          </p>
          <md>
            <mrow>\text{Support: } np \amp\approx 826 \times 0.70 = 578</mrow>
            <mrow>\text{Not: } n(1-p) \amp\approx 826 \times (1 - 0.70) = 248</mrow>
          </md>
          <p>
            Since both values are at least 10, we can use the normal distribution to model <m>\hat{p}</m>.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="seOfPropOfPDBorrowersSupportReg">
        <statement>
          <p>
            Estimate the standard error of <m>\hat{p} = 0.70</m>. Because <m>p</m> is unknown and the standard error is for a confidence interval, use <m>\hat{p}</m> in place of <m>p</m> in the formula.
          </p>
        </statement>
        <solution>
          <p>
            <m>SE = \sqrt{\frac{p(1-p)}{n}} \approx \sqrt{\frac{0.70(1-0.70)}{826}} = 0.016</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-payday-ci">
        <statement>
          <p>
            Construct a 95% confidence interval for <m>p</m>, the proportion of payday borrowers who support increased regulation for payday lenders.
          </p>
        </statement>
        <solution>
          <p>
            Using the point estimate 0.70, <m>z^{\star} = 1.96</m> for a 95% confidence interval, and the standard error <m>SE = 0.016</m> from Guided Practice <xref ref="seOfPropOfPDBorrowersSupportReg"/>, the confidence interval is
          </p>
          <md>
            <mrow>\text{point estimate} \pm z^{\star} \times SE \quad\to\quad 0.70 \pm 1.96 \times 0.016 \quad\to\quad (0.669, 0.731)</mrow>
          </md>
          <p>
            We are 95% confident that the true proportion of payday borrowers who supported regulation at the time of the poll was between 0.669 and 0.731.
          </p>
        </solution>
      </example>
      
      <assemblage xml:id="assem-ci-single-proportion">
        <title>Confidence interval for a single proportion</title>
        <p>
          Once you've determined a one-proportion confidence interval would be helpful for an application, there are four steps to constructing the interval:
        </p>
        <dl>
          <li>
            <title>Prepare.</title>
            <p>
              Identify <m>\hat{p}</m> and <m>n</m>, and determine what confidence level you wish to use.
            </p>
          </li>
          <li>
            <title>Check.</title>
            <p>
              Verify the conditions to ensure <m>\hat{p}</m> is nearly normal. For one-proportion confidence intervals, use <m>\hat{p}</m> in place of <m>p</m> to check the success-failure condition.
            </p>
          </li>
          <li>
            <title>Calculate.</title>
            <p>
              If the conditions hold, compute <m>SE</m> using <m>\hat{p}</m>, find <m>z^{\star}</m>, and construct the interval.
            </p>
          </li>
          <li>
            <title>Conclude.</title>
            <p>
              Interpret the confidence interval in the context of the problem.
            </p>
          </li>
        </dl>
      </assemblage>
      
      <p>
        For additional one-proportion confidence interval examples, see Section 5.2.
      </p>
    </subsection>
    
    <subsection xml:id="htForPropSection">
      <title>Hypothesis testing for a proportion</title>
      
      <p>
        One possible regulation for payday lenders is that they would be required to do a credit check and evaluate debt payments against the borrower's finances. We would like to know: would borrowers support this form of regulation?
      </p>
      
      <exercise xml:id="paydayCC_hypotheses_gp">
        <statement>
          <p>
            Set up hypotheses to evaluate whether borrowers have a majority support or majority opposition for this type of regulation.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: <m>p = 0.50</m>. <m>H_A</m>: <m>p \neq 0.50</m>.
          </p>
        </solution>
      </exercise>
      
      <p>
        To apply the normal distribution framework in the context of a hypothesis test for a proportion, the independence and success-failure conditions must be satisfied. In a hypothesis test, the success-failure condition is checked using the null proportion: we verify <m>np_0</m> and <m>n(1-p_0)</m> are at least 10, where <m>p_0</m> is the null value.
      </p>
      
      <exercise xml:id="paydayCC_conditions_gp">
        <statement>
          <p>
            Do payday loan borrowers support a regulation that would require lenders to pull their credit report and evaluate their debt payments? From a random sample of 826 borrowers, 51% said they would support such a regulation. Is it reasonable to model <m>\hat{p} = 0.51</m> using a normal distribution for a hypothesis test here?
          </p>
        </statement>
        <solution>
          <p>
            Independence holds since the poll is based on a random sample. The success-failure condition also holds, which is checked using the null value (<m>p_0 = 0.5</m>) from <m>H_0</m>: <m>np_0 = 826 \times 0.5 = 413</m>, <m>n(1-p_0) = 826 \times 0.5 = 413</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-payday-ht">
        <statement>
          <p>
            Using the hypotheses and data from Guided Practice <xref ref="paydayCC_hypotheses_gp"/> and <xref ref="paydayCC_conditions_gp"/>, evaluate whether the poll provides convincing evidence that a majority of payday loan borrowers support a new regulation that would require lenders to pull credit reports and evaluate debt payments.
          </p>
        </statement>
        <solution>
          <p>
            With hypotheses already set up and conditions checked, we can move onto calculations. The standard error in the context of a one-proportion hypothesis test is computed using the null value, <m>p_0</m>:
          </p>
          <md>
            <mrow>SE = \sqrt{\frac{p_0(1-p_0)}{n}} = \sqrt{\frac{0.5(1-0.5)}{826}} = 0.017</mrow>
          </md>
          <p>
            A picture of the normal model is shown below with the p-value represented by the shaded region.
          </p>
          <figure xml:id="fig-payday-cc-norm-pvalue">
            <caption>A normal distribution is shown with a center of 0.5 and a standard deviation of 0.017. Two tails are shaded: The region above 0.51 and a region in the corresponding lower tail. Visually, it looks like a little over half of the area under the normal curve is shaded.</caption>
            <image source="ch_inference_for_props/paydayCC_norm_pvalue" width="50%">
              <description>Normal distribution curve showing the p-value for the payday credit check hypothesis test</description>
            </image>
          </figure>
          <p>
            Based on the normal model, the test statistic can be computed as the Z-score of the point estimate:
          </p>
          <md>
            <mrow>Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.51 - 0.50}{0.017} = 0.59</mrow>
          </md>
          <p>
            The single tail area is 0.2776, and the p-value, represented by both tail areas together, is 0.5552. Because the p-value is larger than 0.05, we do not reject <m>H_0</m>. The poll does not provide convincing evidence that a majority of payday loan borrowers support or oppose regulations around credit checks and evaluation of debt payments.
          </p>
        </solution>
      </example>
      
      <assemblage xml:id="assem-ht-single-proportion">
        <title>Hypothesis testing for a single proportion</title>
        <p>
          Once you've determined a one-proportion hypothesis test is the correct procedure, there are four steps to completing the test:
        </p>
        <dl>
          <li>
            <title>Prepare.</title>
            <p>
              Identify the parameter of interest, list hypotheses, identify the significance level, and identify <m>\hat{p}</m> and <m>n</m>.
            </p>
          </li>
          <li>
            <title>Check.</title>
            <p>
              Verify conditions to ensure <m>\hat{p}</m> is nearly normal under <m>H_0</m>. For one-proportion hypothesis tests, use the null value to check the success-failure condition.
            </p>
          </li>
          <li>
            <title>Calculate.</title>
            <p>
              If the conditions hold, compute the standard error, again using <m>p_0</m>, compute the Z-score, and identify the p-value.
            </p>
          </li>
          <li>
            <title>Conclude.</title>
            <p>
              Evaluate the hypothesis test by comparing the p-value to <m>\alpha</m>, and provide a conclusion in the context of the problem.
            </p>
          </li>
        </dl>
      </assemblage>
      
      <p>
        For additional one-proportion hypothesis test examples, see Section 5.3.
      </p>
      
      <p>
        <alert>Calculator Videos:</alert> confidence intervals and hypothesis tests for a single proportion
      </p>
    </subsection>
    
    <subsection xml:id="subsec-conditions-not-met">
      <title>When one or more conditions aren't met</title>
      
      <p>
        We've spent a lot of time discussing conditions for when <m>\hat{p}</m> can be reasonably modeled by a normal distribution. What happens when the success-failure condition fails? What about when the independence condition fails? In either case, the general ideas of confidence intervals and hypothesis tests remain the same, but the strategy or technique used to generate the interval or p-value change.
      </p>
      
      <p>
        When the success-failure condition isn't met for a hypothesis test, we can simulate the null distribution of <m>\hat{p}</m> using the null value, <m>p_0</m>. The simulation concept is similar to the ideas used in the malaria case study presented in Section 5.1, and an online section outlines this strategy:
      </p>
      <p>
        <url href="https://www.openintro.org/r?go=stat_sim_prop_ht">www.openintro.org/r?go=stat_sim_prop_ht</url>
      </p>
      <p>
        For a confidence interval when the success-failure condition isn't met, we can use what's called the <term>Clopper-Pearson interval</term>. The details are beyond the scope of this book. However, there are many internet resources covering this topic.
      </p>
      
      <p>
        The independence condition is a more nuanced requirement. When it isn't met, it is important to understand how and why it isn't met. For example, if we took a cluster sample (see Section 1.3), suitable statistical methods are available but would be beyond the scope of even most second or third courses in statistics. On the other hand, we'd be stretched to find any method that we could confidently apply to correct the inherent biases of data from a convenience sample.
      </p>
      
      <p>
        While this book is scoped to well-constrained statistical problems, do remember that this is just the first book in what is a large library of statistical methods that are suitable for a very wide range of data and contexts.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-choosing-sample-size">
      <title>Choosing a sample size when estimating a proportion</title>
      
      <p>
        When collecting data, we choose a sample size suitable for the purpose of the study. Often times this means choosing a sample size large enough that the <term>margin of error</term><mdash/>which is the part we add and subtract from the point estimate in a confidence interval<mdash/>is sufficiently small that the sample is useful. For example, our task might be to find a sample size <m>n</m> so that the sample proportion is within <m>\pm 0.04</m> of the actual proportion in a 95% confidence interval.
      </p>
      
      <example xml:id="ex-stadium-sample-size">
        <statement>
          <p>
            A university newspaper is conducting a survey to determine what fraction of students support a $200 per year increase in fees to pay for a new football stadium. How big of a sample is required to ensure the margin of error is smaller than 0.04 using a 95% confidence level?
          </p>
        </statement>
        <solution>
          <p>
            The margin of error for a sample proportion is
          </p>
          <md>
            <mrow>z^{\star} \sqrt{\frac{p(1-p)}{n}}</mrow>
          </md>
          <p>
            Our goal is to find the smallest sample size <m>n</m> so that this margin of error is smaller than <m>0.04</m>. For a 95% confidence level, the value <m>z^{\star}</m> corresponds to 1.96:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{p(1-p)}{n}} \lt 0.04</mrow>
          </md>
          <p>
            There are two unknowns in the equation: <m>p</m> and <m>n</m>. If we have an estimate of <m>p</m>, perhaps from a prior survey, we could enter in that value and solve for <m>n</m>. If we have no such estimate, we must use some other value for <m>p</m>. It turns out that the margin of error is largest when <m>p</m> is 0.5, so we typically use this <em>worst case value</em> if no estimate of the proportion is available:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{0.5(1-0.5)}{n}} \amp\lt 0.04</mrow>
            <mrow>1.96^2\times \frac{0.5(1-0.5)}{n} \amp\lt 0.04^2</mrow>
            <mrow>1.96^2\times \frac{0.5(1-0.5)}{0.04^2} \amp\lt n</mrow>
            <mrow>600.25 \amp\lt n</mrow>
          </md>
          <p>
            We would need over 600.25 participants, which means we need 601 participants or more, to ensure the sample proportion is within 0.04 of the true proportion with 95% confidence.
          </p>
        </solution>
      </example>
      
      <p>
        When an estimate of the proportion is available, we use it in place of the worst case proportion value, 0.5.
      </p>
      
      <exercise xml:id="tire_failure_rate_3_samp_size_calc">
        <statement>
          <p>
            A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate what proportion of these tires will be rejected through quality control. The quality control team has monitored the last three tire models produced by the factory, failing 1.7% of tires in the first model, 6.2% of the second model, and 1.3% of the third model. The manager would like to examine enough tires to estimate the failure rate of the new tire model to within about 1% with a 90% confidence level. There are three different failure rates to choose from. Perform the sample size computation for each separately, and identify three sample sizes to consider.
          </p>
        </statement>
        <solution>
          <p>
            For a 90% confidence interval, <m>z^{\star} = 1.6449</m>, and since an estimate of the proportion 0.017 is available, we'll use it in the margin of error formula:
          </p>
          <md>
            <mrow>1.6449\times \sqrt{\frac{0.017(1-0.017)}{n}} \amp\lt 0.01</mrow>
            <mrow>\text{to} \quad \frac{0.017(1-0.017)}{n} \amp\lt \left(\frac{0.01}{1.6449}\right)^2</mrow>
            <mrow>\text{to} \quad 452.15 \amp\lt n</mrow>
          </md>
          <p>
            For sample size calculations, we always round up, so the first tire model suggests 453 tires would be sufficient.
          </p>
          <p>
            A similar computation can be accomplished using 0.062 and 0.013 for <m>p</m>, and you should verify that using these proportions results in minimum sample sizes of 1574 and 348 tires, respectively.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-tire-which-sample-size">
        <statement>
          <p>
            The sample sizes vary widely in Guided Practice <xref ref="tire_failure_rate_3_samp_size_calc"/>. Which of the three would you suggest using? What would influence your choice?
          </p>
        </statement>
        <solution>
          <p>
            We could examine which of the old models is most like the new model, then choose the corresponding sample size. Or if two of the previous estimates are based on small samples while the other is based on a larger sample, we might consider the value corresponding to the larger sample. There are also other reasonable approaches.
          </p>
          <p>
            Also observe that the success-failure condition would need to be checked in the final sample. For instance, if we sampled <m>n = 1584</m> tires and found a failure rate of 0.5%, the normal approximation would not be reasonable, and we would require more advanced statistical methods for creating the confidence interval.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-payday-monthly-sample">
        <statement>
          <p>
            Suppose we want to continually track the support of payday borrowers for regulation on lenders, where we would conduct a new poll every month. Running such frequent polls is expensive, so we decide a wider margin of error of 5% for each individual survey would be acceptable. Based on the original sample of borrowers where 70% supported some form of regulation, how big should our monthly sample be for a margin of error of 0.05 with 95% confidence?
          </p>
        </statement>
        <solution>
          <p>
            We complete the same computations as before, except now we use <m>0.70</m> instead of <m>0.5</m> for <m>p</m>:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{p(1-p)}{n}} \approx 1.96\times \sqrt{\frac{0.70(1-0.70)}{n}} \amp\leq 0.05</mrow>
            <mrow>\text{to} \quad n \amp\geq 322.7</mrow>
          </md>
          <p>
            A sample size of 323 or more would be reasonable. (Reminder: always round up for sample size calculations!) Given that we plan to track this poll over time, we also may want to periodically repeat these calculations to ensure that we're being thoughtful in our sample size recommendations in case the baseline rate fluctuates.
          </p>
        </solution>
      </exercise>
    </subsection>
  </section>
  
  <!-- Section 7.2: Difference of two proportions -->
  <section xml:id="sec-difference-two-proportions">
    <title>Difference of Two Proportions</title>
    
    <introduction>
      <p>
        We now consider a different scenario: comparing proportions from two independent groups.
        For example, we might compare the proportion of patients who recover in a treatment group
        versus a control group, or compare the proportion of voters supporting a candidate across
        two different regions.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-sampling-dist-diff-props">
      <title>Sampling Distribution of a Difference of Proportions</title>
      
      <p>
        When we have two independent samples, we're often interested in the difference between
        sample proportions: <m>\hat{p}_1 - \hat{p}_2</m>. This difference estimates the difference
        in population proportions: <m>p_1 - p_2</m>.
      </p>
      
      <theorem xml:id="thm-diff-proportions">
        <title>Sampling Distribution of <m>\hat{p}_1 - \hat{p}_2</m></title>
        <statement>
          <p>
            When the following conditions are satisfied, the sampling distribution of
            <m>\hat{p}_1 - \hat{p}_2</m> is nearly normal with:
          </p>
          <md>
            \text{Mean} = p_1 - p_2 \qquad SE = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
          </md>
          <p>
            <alert>Conditions:</alert>
          </p>
          <ol>
            <li><alert>Independence:</alert> The data in each group must be independent, and the
                two groups must be independent of each other.</li>
            <li><alert>Success-failure condition:</alert> The success-failure condition must hold
                for each sample: <m>n_1p_1 \geq 10</m>, <m>n_1(1-p_1) \geq 10</m>,
                <m>n_2p_2 \geq 10</m>, and <m>n_2(1-p_2) \geq 10</m>.</li>
          </ol>
        </statement>
      </theorem>
    </subsection>
    
    <subsection xml:id="subsec-ci-diff-proportions">
      <title>Confidence Interval for <m>p_1 - p_2</m></title>
      
      <p>
        A confidence interval for the difference <m>p_1 - p_2</m> is:
      </p>
      
      <md>
        (\hat{p}_1 - \hat{p}_2) \pm z^* \times SE
      </md>
      
      <p>
        where the standard error is:
      </p>
      
      <md>
        SE = \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}
      </md>
      
      <p>
        Note that we use the sample proportions <m>\hat{p}_1</m> and <m>\hat{p}_2</m> in the
        standard error formula.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-ht-diff-proportions">
      <title>Hypothesis Test for <m>H_0: p_1 = p_2</m></title>
      
      <p>
        When testing <m>H_0: p_1 = p_2</m> (or equivalently, <m>H_0: p_1 - p_2 = 0</m>), we use a
        <term>pooled proportion</term> to compute the standard error.
      </p>
      
      <definition xml:id="def-pooled-proportion">
        <statement>
          <p>
            The <term>pooled proportion</term> is used when testing the null hypothesis that two
            proportions are equal:
          </p>
          <md>
            \hat{p}_{pool} = \frac{\text{total number of successes}}{\text{total number of observations}} = \frac{x_1 + x_2}{n_1 + n_2}
          </md>
          <p>
            where <m>x_1</m> and <m>x_2</m> are the number of successes in each sample.
          </p>
        </statement>
      </definition>
      
      <p>
        The test statistic is:
      </p>
      
      <md>
        Z = \frac{(\hat{p}_1 - \hat{p}_2) - 0}{\sqrt{\hat{p}_{pool}(1-\hat{p}_{pool})\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}
      </md>
      
      <important>
        <p>
          <alert>Remember:</alert> Use the pooled proportion in the standard error for hypothesis
          tests, but use the individual sample proportions for confidence intervals.
        </p>
      </important>
    </subsection>
  </section>
  
  <!-- Section 7.3: Testing for goodness of fit using chi-square -->
  <section xml:id="sec-chi-square-gof">
    <title>Testing for Goodness of Fit Using Chi-Square</title>
    
    <introduction>
      <p>
        Sometimes we want to evaluate whether the observed distribution of a categorical variable
        matches a hypothesized distribution. For example: Does the distribution of blood types in a
        sample match the known distribution in the general population? Do observed frequencies of
        outcomes match those expected if a die is fair? These questions can be answered using a
        <term>chi-square goodness of fit test</term>.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-gof-test-intro">
      <title>Goodness of Fit Test</title>
      
      <p>
        In a goodness of fit test, we compare observed counts to expected counts under a null
        hypothesis. The test statistic measures how far the observed counts are from the expected counts.
      </p>
      
      <definition xml:id="def-chi-square-statistic">
        <statement>
          <p>
            The <term>chi-square test statistic</term> for goodness of fit is:
          </p>
          <md>
            \chi^2 = \sum \frac{(\text{observed} - \text{expected})^2}{\text{expected}} = \sum \frac{(O - E)^2}{E}
          </md>
          <p>
            where the sum is taken over all categories.
          </p>
        </statement>
      </definition>
      
      <p>
        The chi-square statistic measures the total deviation between observed and expected counts.
        Large values of <m>\chi^2</m> indicate a poor fit between the data and the null hypothesis.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-distribution">
      <title>The Chi-Square Distribution</title>
      
      <p>
        When the sample size is large enough, the chi-square test statistic follows a
        <term>chi-square distribution</term>.
      </p>
      
      <definition xml:id="def-chi-square-dist">
        <statement>
          <p>
            The <term>chi-square distribution</term> is a right-skewed distribution that starts at
            zero. It has one parameter: <term>degrees of freedom (df)</term>. For a goodness of fit
            test with <m>k</m> categories:
          </p>
          <md>
            df = k - 1
          </md>
        </statement>
      </definition>
      
      <p>
        <alert>Conditions for the chi-square goodness of fit test:</alert>
      </p>
      
      <ol>
        <li><alert>Independence:</alert> The observations must be independent.</li>
        <li><alert>Sample size:</alert> Each expected count must be at least 5.</li>
      </ol>
      
      <p>
        The p-value for a chi-square test is always found in the upper tail of the chi-square
        distribution, since large values of <m>\chi^2</m> provide evidence against <m>H_0</m>.
      </p>
    </subsection>
  </section>
  
  <!-- Section 7.4: Testing for independence in two-way tables -->
  <section xml:id="sec-chi-square-independence">
    <title>Testing for Independence in Two-Way Tables</title>
    
    <introduction>
      <p>
        A two-way table (also called a <term>contingency table</term>) summarizes data for two
        categorical variables. We often want to know: Are these two variables independent, or is
        there an association between them?
      </p>
    </introduction>
    
    <subsection xml:id="subsec-two-way-tables">
      <title>Two-Way Tables and Expected Counts</title>
      
      <p>
        In a two-way table, we organize data by two categorical variables. To test for independence,
        we compare observed counts to expected counts under the assumption that the variables are
        independent.
      </p>
      
      <assemblage xml:id="assem-expected-counts">
        <title>Computing Expected Counts</title>
        <p>
          If two variables are independent, the expected count for a cell in row <m>i</m> and
          column <m>j</m> is:
        </p>
        <md>
          E_{ij} = \frac{(\text{row } i \text{ total}) \times (\text{column } j \text{ total})}{\text{table total}}
        </md>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-test-independence">
      <title>The Chi-Square Test for Independence</title>
      
      <p>
        The chi-square test for independence uses the same test statistic as the goodness of fit test:
      </p>
      
      <md>
        \chi^2 = \sum_{all\text{ }cells} \frac{(O - E)^2}{E}
      </md>
      
      <p>
        However, the degrees of freedom are calculated differently:
      </p>
      
      <md>
        df = (\text{number of rows} - 1) \times (\text{number of columns} - 1)
      </md>
      
      <p>
        <alert>Hypotheses:</alert>
      </p>
      
      <ul>
        <li><m>H_0</m>: The two variables are independent.</li>
        <li><m>H_A</m>: The two variables are not independent (they are associated).</li>
      </ul>
      
      <p>
        <alert>Conditions:</alert>
      </p>
      
      <ol>
        <li><alert>Independence:</alert> Each case that contributes a count to the table must be
            independent of all other cases.</li>
        <li><alert>Sample size:</alert> Each expected count must be at least 5.</li>
      </ol>
      
      <important>
        <p>
          The chi-square test for independence tells us <em>whether</em> there is an association,
          but it doesn't tell us the nature or strength of that association. If the test is
          significant, examine the table and consider computing row or column proportions to
          understand the relationship.
        </p>
      </important>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-limitations">
      <title>Limitations of Chi-Square Tests</title>
      
      <p>
        Important considerations when using chi-square tests:
      </p>
      
      <ul>
        <li>Chi-square tests can only establish whether an association exists; they do not
            determine causation.</li>
        <li>The test requires all expected counts to be at least 5. If this condition is not met,
            consider combining categories or using an alternative test (such as Fisher's exact test).</li>
        <li>Large sample sizes can make even trivial differences statistically significant. Always
            consider practical significance alongside statistical significance.</li>
        <li>Chi-square tests work with counts, not percentages or proportions. Make sure your data
            are in the correct form.</li>
      </ul>
    </subsection>
  </section>
  
  <!-- Section 7.5: Chapter review -->
  <section xml:id="sec-ch07-review">
    <title>Chapter 7 Review Exercises</title>
    
    <p>
      This chapter covered inference for categorical data. Key concepts include:
    </p>
    
    <ul>
      <li>Confidence intervals and hypothesis tests for a single proportion</li>
      <li>Sample size calculations for proportions</li>
      <li>Comparing two proportions using confidence intervals and hypothesis tests</li>
      <li>The pooled proportion for hypothesis testing</li>
      <li>Chi-square goodness of fit tests for comparing observed and expected distributions</li>
      <li>Chi-square tests for independence in two-way tables</li>
      <li>Computing expected counts and degrees of freedom for chi-square tests</li>
    </ul>
    
    <p>
      Additional exercises for practicing these concepts are available in the accompanying
      exercise materials.
    </p>
  </section>
</chapter>
