<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="ch-foundations-for-inference" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Foundations for Inference</title>
  
  <introduction>
    <p>
      Statistical inference is primarily concerned with understanding and quantifying the
      uncertainty of parameter estimates. While the equations and details change depending on
      the setting, the foundations for inference are the same throughout all of statistics.
    </p>
    
    <p>
      We start with a familiar topic: the idea of using a sample proportion to estimate
      a population proportion. Next, we create what's called a <term>confidence interval</term>,
      which is a range of plausible values where we may find the true population value.
      Finally, we introduce the <term>hypothesis testing framework</term>, which allows us to
      formally evaluate claims about the population, such as whether a survey provides strong
      evidence that a candidate has the support of a majority of the voting population.
    </p>
  </introduction>

  <!-- Section 5.1: Point estimates and sampling variability -->
  <section xml:id="sec-point-estimates">
    <title>Point Estimates and Sampling Variability</title>
    
    <introduction>
      <p>
        Companies such as Pew Research frequently conduct polls as a way to understand the
        state of public opinion or knowledge on many topics, including politics, scientific
        understanding, brand recognition, and more. The ultimate goal in taking a poll is
        generally to use the responses to estimate the opinion or knowledge of the broader
        population.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-point-estimates-error">
      <title>Point Estimates and Error</title>
      
      <p>
        Suppose a poll suggested the US President's approval rating is 45%. We would consider
        45% to be a <term>point estimate</term> of the approval rating we might see if we
        collected responses from the entire population. This entire-population response
        proportion is generally referred to as the <term>parameter of interest</term>.
      </p>
      
      <p>
        When the parameter is a proportion, it is often denoted by <m>p</m>, and we often
        refer to the sample proportion as <m>\hat{p}</m> (pronounced <em>p-hat</em>). Unless
        we collect responses from every individual in the population, <m>p</m> remains
        unknown, and we use <m>\hat{p}</m> as our estimate of <m>p</m>. The difference we
        observe from the poll versus the parameter is called the <term>error</term> in the
        estimate.
      </p>
      
      <p>
        Generally, the error consists of two aspects: <term>sampling error</term> and
        <term>bias</term>.
      </p>
      
      <definition xml:id="def-sampling-error">
        <statement>
          <p>
            <term>Sampling error</term>, sometimes called <em>sampling uncertainty</em>,
            describes how much an estimate will tend to vary from one sample to the next.
            For instance, the estimate from one sample might be 1% too low while in another
            it may be 3% too high. The <term>sample size</term> is often represented by the
            letter <m>n</m>.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-bias">
        <statement>
          <p>
            <term>Bias</term> describes a systematic tendency to over- or under-estimate
            the true population value. We try to minimize bias through thoughtful data
            collection procedures.
          </p>
        </statement>
      </definition>
    </subsection>
    
    <subsection xml:id="subsec-variability-point-estimate">
      <title>Understanding the Variability of a Point Estimate</title>
      
      <p>
        To understand how a sample proportion behaves, consider a scenario where the
        proportion of American adults who support expanding solar energy is <m>p = 0.88</m>.
        If we were to take a poll of 1000 American adults on this topic, how close might we
        expect the sample proportion to be to 0.88?
      </p>
      
      <p>
        We can simulate responses we would get from a simple random sample of 1000 American
        adults through the following steps:
      </p>
      
      <ol>
        <li>Create a set of entries representing all American adults, where 88% say "support"
            and 12% say "not".</li>
        <li>Mix up the entries and pull out 1000 entries to represent our sample.</li>
        <li>Compute the fraction that say "support".</li>
      </ol>
      
      <p>
        If we conduct this simulation 10,000 times, we create a <term>sampling distribution</term>
        of the sample proportions. <xref ref="fig-sampling-distribution-solar"/> shows a histogram
        of the results from such a simulation.
      </p>
      
      <figure xml:id="fig-sampling-distribution-solar">
        <caption>A histogram of 10,000 sample proportions, where each sample includes 1,000 respondents from a population where <m>p = 0.88</m>.</caption>
        <image source="images/ch_foundations_for_inf/figures/sampling_10k_prop_88p/sampling_10k_prop_88p.pdf" width="70%">
          <description>Histogram showing distribution of sample proportions centered at 0.88</description>
        </image>
      </figure>
      
      <p>
        This distribution has important characteristics:
      </p>
      
      <ul>
        <li><strong>Center:</strong> The center of the distribution equals the population proportion, <m>p = 0.88</m>.</li>
        <li><strong>Spread:</strong> The standard deviation, which describes the typical deviation from the mean,
            is called the <term>standard error (SE)</term>. For this simulation, <m>SE = 0.0103</m>.</li>
        <li><strong>Shape:</strong> The distribution is approximately normal (bell-shaped).</li>
      </ul>
      
      <assemblage xml:id="note-standard-error-vs-sd">
        <title>Standard error versus standard deviation</title>
        <p>
          The term <term>standard error</term> refers to the standard deviation associated with
          an estimate. It describes the typical deviation we expect to see in estimates from one
          sample to another. The term <term>standard deviation</term> refers to the variability
          in the data or population.
        </p>
      </assemblage>
      
      <p>
        <xref ref="fig-normal-approximation-solar"/> shows the normal approximation to the
        sampling distribution, illustrating that about 95% of the sample proportions fall
        within 2 standard errors of the true proportion.
      </p>
      
      <figure xml:id="fig-normal-approximation-solar">
        <caption>The sampling distribution from <xref ref="fig-sampling-distribution-solar"/>, shown with its mean and standard error, and the normal curve.</caption>
        <image source="images/ch_foundations_for_inf/figures/p-hat_from_86_and_90/p-hat_from_86_and_90.pdf" width="70%">
          <description>Normal distribution with shaded middle region showing 95% of values</description>
        </image>
      </figure>
      
      <important>
        <p>
          Sampling distributions are never observed in practice, but we keep them in mind
          as they help us understand and characterize the point estimates we do observe.
        </p>
      </important>
      
      <example xml:id="ex-smaller-sample-size">
        <title>Effect of smaller sample size</title>
        <statement>
          <p>
            If we used a much smaller sample size of <m>n = 50</m>, would you guess that
            the standard error for <m>\hat{p}</m> would be larger or smaller than when we
            used <m>n = 1000</m>?
          </p>
        </statement>
        <solution>
          <p>
            Intuitively, it seems like more data is better than less data, and generally
            that is correct! The typical error when <m>p = 0.88</m> and <m>n = 50</m>
            would be larger than the error we would expect when <m>n = 1000</m>.
          </p>
          <p>
            This highlights an important property we will see again and again: a bigger
            sample tends to provide a more precise point estimate than a smaller sample.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-central-limit-theorem">
      <title>Central Limit Theorem</title>
      
      <p>
        The examples in the previous subsection highlight three important properties of the
        sampling distribution of a sample proportion:
      </p>
      
      <ol>
        <li>The mean of the sampling distribution is <m>p</m>.</li>
        <li>The standard deviation of the sampling distribution, called the standard error,
            can be calculated as <m>SE = \sqrt{\frac{p(1-p)}{n}}</m>.</li>
        <li>When the sample size is sufficiently large, the sampling distribution is
            approximately normal.</li>
      </ol>
      
      <theorem xml:id="thm-central-limit-theorem">
        <title>Central Limit Theorem for proportions</title>
        <statement>
          <p>
            When observations are independent and the sample size is sufficiently large,
            the sample proportion <m>\hat{p}</m> will tend to follow a normal distribution with:
          </p>
          <md>
            <mrow>\text{Mean:}\amp\ \mu_{\hat{p}} = p</mrow>
            <mrow>\text{Standard Error:}\amp\ SE_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}</mrow>
          </md>
        </statement>
      </theorem>
      
      <p>
        The Central Limit Theorem is incredibly important and provides a foundation for much
        of statistics. Be mindful of the two technical conditions:
      </p>
      
      <ol>
        <li><strong>Independence</strong>: The observations must be independent. This is
            satisfied for a random sample from a population.</li>
        <li><strong>Success-failure condition</strong>: The sample size must be sufficiently
            large. We consider the sample size large enough when <m>np \geq 10</m> and
            <m>n(1-p) \geq 10</m>.</li>
      </ol>
      
      <p>
        It's important to understand what happens when these conditions are not met.
        <xref ref="fig-sampling-10-prop-25"/> shows what happens when the success-failure
        condition is violated. The distribution on the left is from simulations when
        <m>n = 10</m> and <m>p = 0.25</m>. Notice that <m>np = 10 \times 0.25 = 2.5</m>,
        which is less than 10, so the success-failure condition is not met. The distribution
        is noticeably skewed and does not resemble a normal distribution. The distribution
        on the right shows a normal distribution with the same mean and standard deviation
        for comparison - the fit is poor, highlighting why the success-failure condition
        is important.
      </p>
      
      <figure xml:id="fig-sampling-10-prop-25">
        <caption>Left: 10,000 simulations of <m>\hat{p}</m> when <m>n = 10</m> and <m>p = 0.25</m>. The success-failure condition is not met (<m>np = 2.5 &lt; 10</m>), resulting in a skewed distribution. Right: A normal distribution with the same mean (0.25) and standard deviation (0.137) for comparison.</caption>
        <image source="images/ch_foundations_for_inf/figures/sampling_10_prop_25p/sampling_10_prop_25p.pdf" width="80%">
          <description>Two side-by-side plots showing a skewed sampling distribution when success-failure condition fails versus a normal curve</description>
        </image>
      </figure>
      
      <example xml:id="ex-confirm-clt-applies">
        <title>Confirming the Central Limit Theorem applies</title>
        <statement>
          <p>
            Earlier we estimated the mean and standard error of <m>\hat{p}</m> using
            simulated data when <m>p = 0.88</m> and <m>n = 1000</m>. Confirm that the
            Central Limit Theorem applies and the sampling distribution is approximately
            normal.
          </p>
        </statement>
        <solution>
          <ol>
            <li>
              <p>
                <strong>Independence.</strong> There are <m>n = 1000</m> observations for
                each sample proportion <m>\hat{p}</m>, and each of those observations are
                independent draws. The most common way for observations to be considered
                independent is if they are from a simple random sample.
              </p>
            </li>
            <li>
              <p>
                <strong>Success-failure condition.</strong> We can confirm the sample size
                is sufficiently large by checking the success-failure condition and
                confirming the two calculated values are greater than 10:
                <md>
                  <mrow>np \amp= 1000 \times 0.88 = 880 \geq 10 \checkmark</mrow>
                  <mrow>n(1-p) \amp= 1000 \times 0.12 = 120 \geq 10 \checkmark</mrow>
                </md>
              </p>
            </li>
          </ol>
          <p>
            The independence and success-failure conditions are both satisfied, so the
            Central Limit Theorem applies, and it's reasonable to model <m>\hat{p}</m>
            using a normal distribution.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-se-calculation">
        <title>Computing mean and standard error</title>
        <statement>
          <p>
            Compute the theoretical mean and standard error of <m>\hat{p}</m> when
            <m>p = 0.88</m> and <m>n = 1000</m>, according to the Central Limit Theorem.
          </p>
        </statement>
        <solution>
          <p>
            The mean of <m>\hat{p}</m> is simply the population proportion:
            <me>\mu_{\hat{p}} = 0.88</me>
          </p>
          <p>
            The standard error of <m>\hat{p}</m> is calculated using:
            <md>
              <mrow>SE_{\hat{p}} \amp= \sqrt{\frac{p(1-p)}{n}}</mrow>
              <mrow>\amp= \sqrt{\frac{0.88 \times 0.12}{1000}}</mrow>
              <mrow>\amp= 0.0103</mrow>
            </md>
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-normal-prob-sample-prop">
        <title>Normal probability for sample proportion</title>
        <statement>
          <p>
            Estimate how frequently the sample proportion <m>\hat{p}</m> should be within
            0.02 (2%) of the population value, <m>p = 0.88</m>. Based on the previous
            examples, we know that the distribution is approximately
            <m>N(\mu_{\hat{p}} = 0.88, SE_{\hat{p}} = 0.0103)</m>.
          </p>
        </statement>
        <solution>
          <p>
            We would like to understand the fraction of <m>\hat{p}</m>'s between 0.86 and
            0.90. With <m>\mu_{\hat{p}} = 0.88</m> and <m>SE_{\hat{p}} = 0.0103</m>, we
            can compute the Z-score for both the left and right cutoffs:
            <md>
              <mrow>Z_{0.86} \amp= \frac{0.86 - 0.88}{0.0103} = -1.94 \approx -2</mrow>
              <mrow>Z_{0.90} \amp= \frac{0.90 - 0.88}{0.0103} = 1.94 \approx 2</mrow>
            </md>
          </p>
          <p>
            We can use either statistical software, a graphing calculator, or a table to
            find the areas in the tails, and in any case we will find that they are each
            0.0228. The total tail areas are <m>2 \times 0.0228 = 0.0456</m>, which
            leaves the shaded area of 0.9544. That is, about 95.44% of the sampling
            distribution is within <m>\pm 0.02</m> of the population proportion,
            <m>p = 0.88</m>.
          </p>
        </solution>
      </example>
      
      <p>
        <xref ref="fig-clt-grid"/> shows how the sampling distribution changes with different
        values of <m>p</m> and <m>n</m>. Notice that:
      </p>
      
      <ul>
        <li>Larger sample sizes produce narrower, more precise distributions.</li>
        <li>The distribution becomes more symmetric when <m>p</m> is near 0.5.</li>
        <li>All distributions are centered at their respective <m>p</m> values.</li>
      </ul>
      
      <figure xml:id="fig-clt-grid">
        <caption>Sampling distributions for different values of <m>p</m> and <m>n</m> with smaller sample sizes. Rows represent <m>p = 0.10, 0.20, 0.50, 0.80, 0.90</m>. Columns represent <m>n = 10</m> and <m>n = 25</m>.</caption>
        <image source="images/ch_foundations_for_inf/figures/clt_prop_grid/clt_prop_grid_1.pdf" width="80%">
          <description>Grid of sampling distributions showing effect of sample size and proportion for n=10 and n=25</description>
        </image>
      </figure>
      
      <figure xml:id="fig-clt-grid-2">
        <caption>Sampling distributions for different values of <m>p</m> and <m>n</m> with larger sample sizes. Rows represent <m>p = 0.10, 0.20, 0.50, 0.80, 0.90</m>. Columns represent <m>n = 50, 100, 250</m>. Notice that as sample size increases, the distributions become more symmetric and closely resemble the normal distribution, with smaller standard deviations.</caption>
        <image source="images/ch_foundations_for_inf/figures/clt_prop_grid/clt_prop_grid_2.pdf" width="90%">
          <description>Grid of sampling distributions showing effect of sample size and proportion for n=50, n=100, and n=250, demonstrating convergence to normal distribution</description>
        </image>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-clt-real-world">
      <title>Applying the Central Limit Theorem to Real-World Settings</title>
      
      <p>
        In practice, we don't know the population proportion <m>p</m>, which creates a
        challenge: we can't calculate the standard error exactly because it requires <m>p</m>.
        However, we can use the <term>substitution approximation</term> (also called the
        <em>plug-in principle</em>) where we use <m>\hat{p}</m> in place of <m>p</m>:
      </p>
      
      <md>
        <mrow>SE_{\hat{p}} \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</mrow>
      </md>
      
      <p>
        This approximation works well when the sample size is reasonably large. We also
        use <m>\hat{p}</m> in place of <m>p</m> when checking the success-failure condition
        in real applications.
      </p>
      
      <assemblage xml:id="conditions-for-CLT">
        <title>Conditions for using the Central Limit Theorem for proportions</title>
        <p>
          To apply the Central Limit Theorem for a sample proportion, the following
          conditions should be met:
        </p>
        <ol>
          <li><strong>Independence</strong>: The observations are independent, typically
              satisfied by random sampling or random assignment.</li>
          <li><strong>Success-failure condition</strong>: We expect at least 10 successes
              and 10 failures in our sample: <m>n\hat{p} \geq 10</m> and
              <m>n(1-\hat{p}) \geq 10</m>.</li>
        </ol>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-extending-framework">
      <title>Extending the Framework for Other Statistics</title>
      
      <p>
        The strategy of using a sample statistic to estimate a parameter is quite common and
        can be applied to other statistics besides a proportion. For instance, to estimate
        the average salary for graduates from a particular college, we could survey a random
        sample of recent graduates and use the sample mean <m>\bar{x}</m> to estimate the
        population mean <m>\mu</m>.
      </p>
      
      <p>
        The principles and general ideas are the same across different contexts:
      </p>
      
      <ul>
        <li>A point estimate from a sample is used to estimate an unknown parameter.</li>
        <li>The sampling distribution describes how the estimate varies from sample to sample.</li>
        <li>The standard error quantifies the typical deviation in the estimates.</li>
        <li>Under certain conditions, the Central Limit Theorem tells us the sampling
            distribution is approximately normal.</li>
      </ul>
      
      <p>
        While this chapter emphasizes a single proportion context, these methods will be
        applied to many different contexts throughout this book.
      </p>
    </subsection>
    
    <exercises>
      <title>Section 5.1 Exercises</title>
      
      <exercise xml:id="ex-identify-parameter-1">
        <statement>
          <p>
            For each of the following situations, state whether the parameter of interest
            is a mean or a proportion. It may be helpful to examine whether individual
            responses are numerical or categorical.
          </p>
          <ol>
            <li>In a survey, one hundred college students are asked how many hours per week
                they spend on the Internet.</li>
            <li>In a survey, one hundred college students are asked: "What percentage of
                the time you spend on the Internet is part of your course work?"</li>
            <li>In a survey, one hundred college students are asked whether or not they
                cited information from Wikipedia in their papers.</li>
            <li>In a survey, one hundred college students are asked what percentage of
                their total weekly spending is on alcoholic beverages.</li>
            <li>In a sample of one hundred recent college graduates, it is found that 85
                percent expect to get a job within one year of their graduation date.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-identify-parameter-2">
        <statement>
          <p>
            For each of the following situations, state whether the parameter of interest
            is a mean or a proportion.
          </p>
          <ol>
            <li>A poll shows that 64% of Americans personally worry a great deal about
                federal spending and the budget deficit.</li>
            <li>A survey reports that local TV news has shown a 17% increase in revenue
                within a two year period while newspaper revenues decreased by 6.4% during
                this time period.</li>
            <li>In a survey, high school and college students are asked whether or not
                they use geolocation services on their smart phones.</li>
            <li>In a survey, smart phone users are asked whether or not they use a
                web-based taxi service.</li>
            <li>In a survey, smart phone users are asked how many times they used a
                web-based taxi service over the last year.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-quality-control">
        <statement>
          <p>
            As part of a quality control process for computer chips, an engineer at a
            factory randomly samples 212 chips during a week of production to test the
            current rate of chips with severe defects. She finds that 27 of the chips
            are defective.
          </p>
          <ol>
            <li>What population is under consideration in the data set?</li>
            <li>What parameter is being estimated?</li>
            <li>What is the point estimate for the parameter?</li>
            <li>What is the name of the statistic we use to measure the uncertainty of
                the point estimate?</li>
            <li>Compute this value for this context.</li>
            <li>The historical rate of defects is 10%. Should the engineer be surprised
                by the observed rate of defects during the current week?</li>
            <li>Suppose the true population value was found to be 10%. If we use this
                proportion to recompute the value in part (e) using <m>p = 0.1</m>
                instead of <m>\hat{p}</m>, does the resulting value change much?</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-unexpected-expense">
        <statement>
          <p>
            In a random sample of 765 adults in the United States, 322 say they could not
            cover a $400 unexpected expense without borrowing money or going into debt.
          </p>
          <ol>
            <li>What population is under consideration in the data set?</li>
            <li>What parameter is being estimated?</li>
            <li>What is the point estimate for the parameter?</li>
            <li>What is the name of the statistic we use to measure the uncertainty of
                the point estimate?</li>
            <li>Compute the value from part (d) for this context.</li>
            <li>A cable news pundit thinks the value is actually 50%. Should she be
                surprised by the data?</li>
            <li>Suppose the true population value was found to be 40%. If we use this
                proportion to recompute the value in part (e) using <m>p = 0.4</m>
                instead of <m>\hat{p}</m>, does the resulting value change much?</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-repeated-water-samples">
        <statement>
          <p>
            A nonprofit wants to understand the fraction of households that have elevated
            levels of lead in their drinking water. They expect at least 5% of homes will
            have elevated levels of lead, but not more than about 30%. They randomly
            sample 800 homes and work with the owners to retrieve water samples, and they
            compute the fraction of these homes with elevated lead levels. They repeat
            this 1,000 times and build a distribution of sample proportions.
          </p>
          <ol>
            <li>What is this distribution called?</li>
            <li>Would you expect the shape of this distribution to be symmetric, right
                skewed, or left skewed? Explain your reasoning.</li>
            <li>If the proportions are distributed around 8%, what is the variability
                of the distribution?</li>
            <li>What is the formal name of the value you computed in (c)?</li>
            <li>Suppose the researchers' budget is reduced, and they are only able to
                collect 250 observations per sample, but they can still collect 1,000
                samples. They build a new distribution of sample proportions. How will
                the variability of this new distribution compare to the variability of
                the distribution when each sample contained 800 observations?</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-repeated-student-samples">
        <statement>
          <p>
            Of all freshman at a large college, 16% made the dean's list in the current
            year. As part of a class project, students randomly sample 40 students and
            check if those students made the list. They repeat this 1,000 times and
            build a distribution of sample proportions.
          </p>
          <ol>
            <li>What is this distribution called?</li>
            <li>Would you expect the shape of this distribution to be symmetric, right
                skewed, or left skewed? Explain your reasoning.</li>
            <li>Calculate the variability of this distribution.</li>
            <li>What is the formal name of the value you computed in (c)?</li>
            <li>Suppose the students decide to sample again, this time collecting 90
                students per sample, and they again collect 1,000 samples. They build a
                new distribution of sample proportions. How will the variability of this
                new distribution compare to the variability of the distribution when each
                sample contained 40 observations?</li>
          </ol>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 5.2: Confidence intervals for a proportion -->
  <section xml:id="sec-confidence-intervals">
    <title>Confidence Intervals for a Proportion</title>
    
    <introduction>
      <p>
        The sample proportion <m>\hat{p}</m> provides a single plausible value for the
        population proportion <m>p</m>. However, the sample proportion isn't perfect and
        will have some standard error associated with it. When stating an estimate for the
        population proportion, it is better practice to provide a plausible range of values
        instead of supplying just the point estimate.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-capturing-parameter">
      <title>Capturing the Population Parameter</title>
      
      <p>
        A <term>confidence interval</term> is a range of plausible values where we are
        likely to find the population parameter. Using a confidence interval is like fishing
        with a net instead of a spear: we have a good chance of catching the fish.
      </p>
      
      <p>
        If we took many samples and built a confidence interval from each sample using the
        same method, we'd expect that some of the intervals would contain the parameter and
        some wouldn't. A <em>95% confidence interval</em> means that if we were to repeat
        the process many times, about 95% of the intervals would contain the true parameter.
      </p>
      
      <figure xml:id="fig-25-confidence-intervals">
        <caption>25 confidence intervals constructed from 25 different samples. The red intervals do not contain the true population proportion <m>p</m>.</caption>
        <image source="images/ch_foundations_for_inf/figures/95PercentConfidenceInterval/95PercentConfidenceInterval.pdf" width="75%">
          <description>Visualization of 25 confidence intervals, most containing the true parameter</description>
        </image>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-95-ci">
      <title>Constructing a 95% Confidence Interval</title>
      
      <p>
        Our sample proportion <m>\hat{p}</m> is the most plausible value of the population
        proportion, so it makes sense to build a confidence interval around this point estimate.
        The standard error provides a guide for how large we should make the confidence interval.
      </p>
      
      <p>
        In a normal distribution, approximately 95% of the data is within 1.96 standard
        deviations of the mean. Using this principle, we can construct a confidence interval
        that extends 1.96 standard errors from the sample proportion:
      </p>
      
      <md>
        <mrow>\text{95% CI} \amp= \text{point estimate} \pm 1.96 \times SE</mrow>
        <mrow>\amp= \hat{p} \pm 1.96 \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</mrow>
      </md>
      
      <definition xml:id="def-95-ci">
        <title>95% Confidence Interval for a proportion</title>
        <statement>
          <p>
            A 95% confidence interval for a population proportion is:
          </p>
          <me>\hat{p} \pm 1.96 \times SE_{\hat{p}}</me>
          <p>
            where <m>SE_{\hat{p}} = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</m>.
          </p>
          <p>
            This confidence interval accounts for sampling error but not bias.
          </p>
        </statement>
      </definition>
      
      <example xml:id="ex-solar-95-ci">
        <title>95% CI for solar energy support</title>
        <statement>
          <p>
            In a Pew Research poll, 887 out of 1000 American adults (88.7%) supported
            expanding the use of solar energy. Compute and interpret a 95% confidence
            interval for the population proportion.
          </p>
        </statement>
        <solution>
          <p>
            First, we verify the conditions. The observations are from a random sample,
            so they are independent. We check the success-failure condition:
            <md>
              <mrow>n\hat{p} \amp= 1000 \times 0.887 = 887 \geq 10</mrow>
              <mrow>n(1-\hat{p}) \amp= 1000 \times 0.113 = 113 \geq 10</mrow>
            </md>
            Both are greater than 10, so the conditions are met.
          </p>
          <p>
            The standard error is:
            <md>
              <mrow>SE_{\hat{p}} \amp= \sqrt{\frac{0.887 \times 0.113}{1000}}</mrow>
              <mrow>\amp= 0.0101</mrow>
            </md>
          </p>
          <p>
            The 95% confidence interval is:
            <md>
              <mrow>0.887 \pm 1.96 \times 0.0101 \amp= 0.887 \pm 0.0198</mrow>
              <mrow>\amp= (0.8672, 0.9068)</mrow>
            </md>
          </p>
          <p>
            <strong>Interpretation:</strong> We are 95% confident that between 86.7% and
            90.7% of American adults support expanding the use of solar energy.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-changing-confidence">
      <title>Changing the Confidence Level</title>
      
      <p>
        We can create confidence intervals with different confidence levels. The multiplier
        we use depends on how confident we want to be:
      </p>
      
      <table xml:id="table-z-star-values">
        <title>Common confidence levels and corresponding <m>z^*</m> values</title>
        <tabular>
          <row header="yes">
            <cell>Confidence Level</cell>
            <cell><m>z^*</m> value</cell>
          </row>
          <row>
            <cell>90%</cell>
            <cell>1.65</cell>
          </row>
          <row>
            <cell>95%</cell>
            <cell>1.96</cell>
          </row>
          <row>
            <cell>99%</cell>
            <cell>2.58</cell>
          </row>
        </tabular>
      </table>
      
      <definition xml:id="def-general-ci">
        <title>General form of a confidence interval</title>
        <statement>
          <p>
            For a point estimate that closely follows a normal model with standard error
            <m>SE</m>, a confidence interval for the population parameter is:
          </p>
          <me>\text{point estimate} \pm z^* \times SE</me>
          <p>
            where <m>z^*</m> corresponds to the confidence level selected.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-margin-of-error">
        <title>Margin of Error</title>
        <statement>
          <p>
            In a confidence interval, <m>z^* \times SE</m> is called the <term>margin of error</term>.
            It represents how far above and below the point estimate the confidence interval extends.
          </p>
        </statement>
      </definition>
      
      <figure xml:id="fig-choosing-z-star">
        <caption>The area between <m>-z^*</m> and <m>z^*</m> in the standard normal distribution for common confidence levels.</caption>
        <image source="images/ch_foundations_for_inf/figures/choosingZForCI/choosingZForCI.pdf" width="70%">
          <description>Normal curve showing z-star values for different confidence levels</description>
        </image>
      </figure>
      
      <example xml:id="ex-solar-90-ci">
        <title>90% CI for solar energy support</title>
        <statement>
          <p>
            Use the data from <xref ref="ex-solar-95-ci"/> to create a 90% confidence
            interval for the proportion of American adults that support expanding the use
            of solar power. We have already verified conditions for normality.
          </p>
        </statement>
        <solution>
          <p>
            We first find <m>z^*</m> such that 90% of the distribution falls between
            <m>-z^*</m> and <m>z^*</m> in the standard normal distribution. We can do
            this using a graphing calculator, statistical software, or a probability table
            by looking for an upper tail of 5% (the other 5% is in the lower tail):
            <m>z^* = 1.65</m>.
          </p>
          <p>
            The 90% confidence interval can then be computed as:
            <md>
              <mrow>\hat{p} \pm 1.65 \times SE_{\hat{p}} \amp= 0.887 \pm 1.65 \times 0.0100</mrow>
              <mrow>\amp= 0.887 \pm 0.0165</mrow>
              <mrow>\amp= (0.8705, 0.9034)</mrow>
            </md>
          </p>
          <p>
            <strong>Interpretation:</strong> We are 90% confident that 87.1% to 90.3% of
            American adults supported the expansion of solar power in 2018.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-ci-procedure">
      <title>Confidence Interval Procedure for a Single Proportion</title>
      
      <assemblage xml:id="ci-procedure">
        <title>Four-step confidence interval procedure</title>
        <ol>
          <li><strong>Prepare:</strong> Identify <m>\hat{p}</m> and <m>n</m>, and determine
              what confidence level you wish to use.</li>
          <li><strong>Check:</strong> Verify the conditions to ensure <m>\hat{p}</m> is
              nearly normal. For one-proportion confidence intervals, use <m>\hat{p}</m>
              in place of <m>p</m> to check the success-failure condition.</li>
          <li><strong>Calculate:</strong> If the conditions hold, compute <m>SE</m> using
              <m>\hat{p}</m>, find <m>z^*</m>, and construct the interval.</li>
          <li><strong>Conclude:</strong> Interpret the confidence interval in the context
              of the problem.</li>
        </ol>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-more-case-studies">
      <title>More Case Studies</title>
      
      <p>
        Let's apply the confidence interval procedure to two more real-world examples
        to solidify our understanding.
      </p>
      
      <example xml:id="ex-ebola-quarantine">
        <title>Ebola quarantine support in New York</title>
        <statement>
          <p>
            In New York City on October 23, 2014, a doctor who had recently been treating
            Ebola patients in Guinea went to the hospital with a slight fever and was
            subsequently diagnosed with Ebola. Soon thereafter, an NBC 4 New York/The Wall
            Street Journal/Marist Poll found that 82% of New Yorkers favored a "mandatory
            21-day quarantine for anyone who has come in contact with an Ebola patient."
            This poll included responses of 1,042 New York adults between October 26-28, 2014.
          </p>
          <ol>
            <li>What is the point estimate, and is it reasonable to use a normal distribution
                to model it?</li>
            <li>Estimate the standard error of <m>\hat{p} = 0.82</m>.</li>
            <li>Construct a 95% confidence interval for the proportion of New York adults
                who supported the quarantine policy.</li>
          </ol>
        </statement>
        <solution>
          <ol>
            <li>
              <p>
                The point estimate, based on a sample of size <m>n = 1042</m>, is
                <m>\hat{p} = 0.82</m>. To check whether <m>\hat{p}</m> can be reasonably
                modeled using a normal distribution, we check independence (the poll is
                based on a simple random sample) and the success-failure condition:
                <md>
                  <mrow>n\hat{p} \amp= 1042 \times 0.82 = 854 \geq 10 \checkmark</mrow>
                  <mrow>n(1-\hat{p}) \amp= 1042 \times 0.18 = 188 \geq 10 \checkmark</mrow>
                </md>
                With the conditions met, we can model <m>\hat{p}</m> using a normal
                distribution.
              </p>
            </li>
            <li>
              <p>
                Using the substitution approximation <m>p \approx \hat{p} = 0.82</m>:
                <md>
                  <mrow>SE_{\hat{p}} \amp= \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</mrow>
                  <mrow>\amp= \sqrt{\frac{0.82 \times 0.18}{1042}}</mrow>
                  <mrow>\amp= 0.012</mrow>
                </md>
              </p>
            </li>
            <li>
              <p>
                Using <m>SE = 0.012</m>, <m>\hat{p} = 0.82</m>, and <m>z^* = 1.96</m>:
                <md>
                  <mrow>0.82 \pm 1.96 \times 0.012 \amp= 0.82 \pm 0.024</mrow>
                  <mrow>\amp= (0.796, 0.844)</mrow>
                </md>
                <strong>Interpretation:</strong> We are 95% confident that between 79.6%
                and 84.4% of New York adults in October 2014 supported a quarantine for
                anyone who had come into contact with an Ebola patient.
              </p>
            </li>
          </ol>
        </solution>
      </example>
      
      <exercise xml:id="ex-wind-turbines-guided">
        <title>Wind turbine support</title>
        <statement>
          <p>
            In the same Pew Research poll about solar energy, they also inquired about
            other forms of energy, and 84.8% of the 1,000 respondents supported expanding
            the use of wind turbines.
          </p>
          <ol>
            <li>Is it reasonable to model the proportion of US adults who support expanding
                wind turbines using a normal distribution?</li>
            <li>Create a 99% confidence interval for the level of American support for
                expanding the use of wind turbines for power generation.</li>
          </ol>
        </statement>
        <hint>
          <p>
            For part (b), recall that for a 99% confidence interval, <m>z^* = 2.58</m>.
          </p>
        </hint>
        <answer>
          <ol>
            <li>
              <p>
                Yes. The survey was a random sample and the success-failure counts are
                both <m>\geq 10</m>: <m>n\hat{p} = 1000 \times 0.848 = 848</m> and
                <m>n(1-\hat{p}) = 1000 \times 0.152 = 152</m>.
              </p>
            </li>
            <li>
              <p>
                The standard error is:
                <me>SE = \sqrt{\frac{0.848 \times 0.152}{1000}} = 0.0114</me>
                The 99% confidence interval is:
                <md>
                  <mrow>0.848 \pm 2.58 \times 0.0114 \amp= 0.848 \pm 0.029</mrow>
                  <mrow>\amp= (0.819, 0.877)</mrow>
                </md>
                We are 99% confident that between 81.9% and 87.7% of American adults
                support expanding the use of wind turbines.
              </p>
            </li>
          </ol>
        </answer>
      </exercise>
    </subsection>
    
    <subsection xml:id="subsec-interpreting-ci">
      <title>Interpreting Confidence Intervals</title>
      
      <p>
        When interpreting a confidence interval, remember:
      </p>
      
      <ul>
        <li>The statement is about the <em>population parameter</em>, not about individual
            observations or future samples.</li>
        <li>A 95% confidence interval means that if we repeated the sampling process many
            times, about 95% of the intervals would contain the true parameter.</li>
        <li>We don't know if our particular interval contains the parameter, but we can
            be 95% confident that it does.</li>
      </ul>
      
      <important>
        <p>
          Remember that these methods only address sampling error, not bias. If data is
          collected in a way that systematically under- or over-estimates the population
          parameter, these techniques will not fix that problem.
        </p>
      </important>
    </subsection>
    
    <subsection xml:id="subsec-interpreting-cis">
      <title>Interpreting Confidence Intervals</title>
      
      <p>
        When we interpret confidence intervals, we must be careful to use precise language.
        In each of the examples, we described the confidence intervals by putting them into
        the context of the data:
      </p>
      
      <ul>
        <li><strong>Solar.</strong> We are 90% confident that 87.1% to 90.3% of American
            adults support the expansion of solar power in 2018.</li>
        <li><strong>Ebola.</strong> We are 95% confident that the proportion of New York
            adults in October 2014 who supported a quarantine for anyone who had come into
            contact with an Ebola patient was between 79.6% and 84.4%.</li>
      </ul>
      
      <p>
        Notice that the statements are always about the <em>population parameter</em>, which
        considers all American adults for the energy polls or all New York adults for the
        quarantine poll.
      </p>
      
      <warning>
        <title>Common mistakes when interpreting confidence intervals</title>
        <p>
          <strong>Mistake 1: Probability interpretation.</strong> A confidence interval does
          not mean there's a 95% probability the parameter is in the interval. The parameter
          is fixed; either it's in the interval or it's not. The 95% refers to the long-run
          success rate of the method, not the probability for any particular interval.
        </p>
        <p>
          <strong>Mistake 2: About the sample.</strong> A confidence interval is only about
          the population parameter, not about individual observations or the sample
          proportion. It says nothing about where future point estimates will fall.
        </p>
      </warning>
    </subsection>
    
    <exercises>
      <title>Section 5.2 Exercises</title>
      
      <exercise xml:id="ex-ebola-ci">
        <statement>
          <p>
            In response to the Ebola outbreak in 2014, a poll found that 82% of 1,042
            American adults supported mandatory quarantine for anyone who had contact
            with an Ebola patient. Construct and interpret a 95% confidence interval
            for the proportion of all American adults who supported this policy.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-wind-turbines-99-ci">
        <statement>
          <p>
            In a survey of 1,000 adults, 848 supported expanding the use of wind energy.
            Construct and interpret a 99% confidence interval for the proportion of all
            adults who support expanding wind energy.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-chronic-illness-intro">
        <statement>
          <p>
            In 2013, the Pew Research Foundation reported that "45% of U.S. adults report
            that they live with one or more chronic conditions". However, this value was
            based on a sample, so it may not be a perfect estimate for the population
            parameter of interest on its own. The study reported a standard error of
            about 1.2%, and a normal model may reasonably be used in this setting. Create
            a 95% confidence interval for the proportion of U.S. adults who live with one
            or more chronic conditions. Also interpret the confidence interval in the
            context of the study.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-twitter-users-intro">
        <statement>
          <p>
            A poll conducted in 2013 found that 52% of U.S. adult Twitter users get at
            least some news on Twitter. The standard error for this estimate was 2.4%,
            and a normal distribution may be used to model the sample proportion.
            Construct a 99% confidence interval for the fraction of U.S. adult Twitter
            users who get some news on Twitter, and interpret the confidence interval in
            context.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-chronic-illness-tf">
        <statement>
          <p>
            In 2013, the Pew Research Foundation reported that "45% of U.S. adults report
            that they live with one or more chronic conditions", and the standard error
            for this estimate is 1.2%. Identify each of the following statements as true
            or false. Provide an explanation to justify each of your answers.
          </p>
          <ol>
            <li>We can say with certainty that the confidence interval from the chronic
                illness exercise contains the true percentage of U.S. adults who suffer
                from a chronic illness.</li>
            <li>If we repeated this study 1,000 times and constructed a 95% confidence
                interval for each study, then approximately 950 of those confidence
                intervals would contain the true fraction of U.S. adults who suffer from
                chronic illnesses.</li>
            <li>The poll provides statistically significant evidence (at the
                <m>\alpha = 0.05</m> level) that the percentage of U.S. adults who
                suffer from chronic illnesses is below 50%.</li>
            <li>Since the standard error is 1.2%, only 1.2% of people in the study
                communicated uncertainty about their answer.</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-twitter-users-tf">
        <statement>
          <p>
            A poll conducted in 2013 found that 52% of U.S. adult Twitter users get at
            least some news on Twitter, and the standard error for this estimate was
            2.4%. Identify each of the following statements as true or false. Provide an
            explanation to justify each of your answers.
          </p>
          <ol>
            <li>The data provide statistically significant evidence that more than half
                of U.S. adult Twitter users get some news through Twitter. Use a
                significance level of <m>\alpha = 0.01</m>.</li>
            <li>Since the standard error is 2.4%, we can conclude that 97.6% of all
                U.S. adult Twitter users were included in the study.</li>
            <li>If we want to reduce the standard error of the estimate, we should
                collect less data.</li>
            <li>If we construct a 90% confidence interval for the percentage of U.S.
                adult Twitter users who get some news through Twitter, this confidence
                interval will be wider than a corresponding 99% confidence interval.</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-er-wait-intro">
        <statement>
          <p>
            A hospital administrator hoping to improve wait times decides to estimate the
            average emergency room waiting time at her hospital. She collects a simple
            random sample of 64 patients and determines the time (in minutes) between
            when they checked in to the ER until they were first seen by a doctor. A 95%
            confidence interval based on this sample is (128 minutes, 147 minutes), which
            is based on the normal model for the mean. Determine whether the following
            statements are true or false, and explain your reasoning.
          </p>
          <ol>
            <li>We are 95% confident that the average waiting time of these 64 emergency
                room patients is between 128 and 147 minutes.</li>
            <li>We are 95% confident that the average waiting time of all patients at
                this hospital's emergency room is between 128 and 147 minutes.</li>
            <li>95% of random samples have a sample mean between 128 and 147 minutes.</li>
            <li>A 99% confidence interval would be narrower than the 95% confidence
                interval since we need to be more sure of our estimate.</li>
            <li>The margin of error is 9.5 and the sample mean is 137.5.</li>
            <li>In order to decrease the margin of error of a 95% confidence interval to
                half of what it is now, we would need to double the sample size.</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-mental-health">
        <statement>
          <p>
            The General Social Survey asked the question: "For how many days during the
            past 30 days was your mental health, which includes stress, depression, and
            problems with emotions, not good?" Based on responses from 1,151 US
            residents, the survey reported a 95% confidence interval of 3.40 to 4.24 days
            in 2010.
          </p>
          <ol>
            <li>Interpret this interval in context of the data.</li>
            <li>What does "95% confident" mean? Explain in the context of the
                application.</li>
            <li>Suppose the researchers think a 99% confidence level would be more
                appropriate for this interval. Will this new interval be smaller or wider
                than the 95% confidence interval?</li>
            <li>If a new survey were to be done with 500 Americans, do you think the
                standard error of the estimate would be larger, smaller, or about the same.</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-website-registration">
        <statement>
          <p>
            A website is trying to increase registration for first-time visitors,
            exposing 1% of these visitors to a new site design. Of 752 randomly sampled
            visitors over a month who saw the new design, 64 registered.
          </p>
          <ol>
            <li>Check any conditions required for constructing a confidence
                interval.</li>
            <li>Compute the standard error.</li>
            <li>Construct and interpret a 90% confidence interval for the fraction of
                first-time visitors of the site who would register under the new design
                (assuming stable behaviors by new visitors over time).</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-store-coupon">
        <statement>
          <p>
            A store randomly samples 603 shoppers over the course of a year and finds
            that 142 of them made their visit because of a coupon they'd received in the
            mail. Construct a 95% confidence interval for the fraction of all shoppers
            during the year whose visit was because of a coupon they'd received in the
            mail.
          </p>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 5.3: Hypothesis testing for a proportion -->
  <section xml:id="sec-hypothesis-testing">
    <title>Hypothesis Testing for a Proportion</title>
    
    <introduction>
      <p>
        The hypothesis testing framework is used to rigorously evaluate competing ideas and
        claims. In this section, we'll explore how to formally test claims about population
        proportions using data from samples.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-ht-framework">
      <title>Hypothesis Testing Framework</title>
      
      <p>
        In hypothesis testing, we consider two competing hypotheses:
      </p>
      
      <definition xml:id="def-null-hypothesis">
        <title>Null Hypothesis</title>
        <statement>
          <p>
            The <term>null hypothesis</term> (<m>H_0</m>) often represents a skeptical
            perspective or a claim to be tested. It typically represents a position of
            no difference or no effect.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-alternative-hypothesis">
        <title>Alternative Hypothesis</title>
        <statement>
          <p>
            The <term>alternative hypothesis</term> (<m>H_A</m>) represents an alternative
            claim under consideration. It is often represented by a range of possible
            parameter values and is what the researcher hopes to show evidence for.
          </p>
        </statement>
      </definition>
      
      <p>
        Our job as data scientists is to play the role of a skeptic: before we buy into the
        alternative hypothesis, we need to see strong supporting evidence. Even if we fail to
        reject the null hypothesis, we typically do not accept it as true; failing to find
        strong evidence for the alternative hypothesis is not equivalent to accepting the
        null hypothesis.
      </p>
      
      <definition xml:id="def-null-value">
        <title>Null Value</title>
        <statement>
          <p>
            The <term>null value</term> is the value of the parameter under the null
            hypothesis. It is common to label the null value with a subscript 0. For example,
            if the null hypothesis is <m>p = 0.5</m>, then the null value is <m>p_0 = 0.5</m>.
          </p>
        </statement>
      </definition>
      
      <example xml:id="ex-coal-hypotheses">
        <title>Setting up hypotheses for coal energy</title>
        <statement>
          <p>
            Pew Research asked a random sample of 1,000 American adults whether they
            supported the increased usage of coal to produce energy. Set up hypotheses
            to evaluate whether a majority of American adults support or oppose the
            increased usage of coal.
          </p>
        </statement>
        <solution>
          <p>
            The uninteresting result is that there is no majority either way: half support
            and half oppose. The alternative hypothesis would be that there is a majority
            support or oppose (though we don't know which).
          </p>
          <p>
            If <m>p</m> represents the proportion supporting, we write the hypotheses as:
          </p>
          <md>
            <mrow>H_0: \amp\ p = 0.5 \quad \text{(no majority either way)}</mrow>
            <mrow>H_A: \amp\ p \neq 0.5 \quad \text{(there is a majority)}</mrow>
          </md>
          <p>
            In this case, the null value is <m>p_0 = 0.5</m>. This is a <em>two-sided</em>
            test because the alternative hypothesis includes values both less than and
            greater than 0.5.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-ht-confidence-intervals">
      <title>Testing Hypotheses Using Confidence Intervals</title>
      
      <p>
        We can use confidence intervals to evaluate hypothesis tests. If the null value
        falls within the confidence interval, we cannot say the null value is implausible,
        so we cannot reject the null hypothesis. If the null value falls outside the
        confidence interval, it is implausible and we reject the null hypothesis.
      </p>
      
      <example xml:id="ex-coal-ci-test">
        <title>Testing coal hypothesis using confidence interval</title>
        <statement>
          <p>
            In the Pew Research poll, 370 out of 1,000 respondents (37%) supported
            expanding coal energy. Does this provide evidence that a majority opposes
            coal energy expansion? Use a 95% confidence interval.
          </p>
        </statement>
        <solution>
          <p>
            First, construct a 95% confidence interval:
            <md>
              <mrow>SE \amp= \sqrt{\frac{0.37 \times 0.63}{1000}} = 0.0153</mrow>
              <mrow>CI \amp= 0.37 \pm 1.96 \times 0.0153</mrow>
              <mrow>\amp= (0.340, 0.400)</mrow>
            </md>
          </p>
          <p>
            The null value <m>p_0 = 0.5</m> is not in this interval (34.0% to 40.0%).
            Therefore, we reject the null hypothesis. We have strong evidence that a
            majority of American adults oppose expanding coal energy production.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-rosling-infant-vaccination">
        <title>Infant vaccination knowledge using CI</title>
        <statement>
          <p>
            The Rosling Foundation studies public knowledge about global health and
            development. In one study, 50 college-educated adults were asked: "What
            percentage of 1-year-old children in the world today have been vaccinated
            against some disease?" The choices were: (A) 20%, (B) 50%, or (C) 80%.
            Only 12 out of 50 respondents (24%) chose the correct answer (C: 80%).
          </p>
          <p>
            If respondents were simply guessing among the three options, we would
            expect about 33.3% to get it right by chance. Does the data provide
            strong evidence that college-educated adults perform differently than
            random guessing? Test using a 95% confidence interval.
          </p>
        </statement>
        <solution>
          <p>
            First, check conditions. The data come from a simple random sample
            (independence), and <m>n\hat{p} = 50 \times 0.24 = 12 \geq 10</m> and
            <m>n(1-\hat{p}) = 50 \times 0.76 = 38 \geq 10</m> (success-failure).
            Conditions are met.
          </p>
          <p>
            Calculate the standard error:
            <me>SE = \sqrt{\frac{0.24 \times 0.76}{50}} = 0.060</me>
          </p>
          <p>
            Construct the 95% confidence interval:
            <md>
              <mrow>0.24 \pm 1.96 \times 0.060 \amp= 0.24 \pm 0.118</mrow>
              <mrow>\amp= (0.122, 0.358)</mrow>
            </md>
          </p>
          <p>
            The null value is <m>p_0 = 0.333</m> (33.3%), which falls within the
            confidence interval of 12.2% to 35.8%. Therefore, we cannot reject the
            null hypothesis. The data do not provide sufficient evidence that
            college-educated adults perform differently than random guessing on this
            question.
          </p>
          <p>
            <strong>Important note:</strong> Failing to reject <m>H_0</m> does not
            mean we've proven the null hypothesis is true. Perhaps there was an
            actual difference, but we were not able to detect it with the relatively
            small sample of 50 respondents.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-decision-errors">
      <title>Decision Errors in Hypothesis Testing</title>
      
      <p>
        Hypothesis tests are not flawless: we can make an incorrect decision based on the data.
      </p>
      
      <definition xml:id="def-type-1-error">
        <title>Type 1 Error</title>
        <statement>
          <p>
            A <term>Type 1 Error</term> is rejecting the null hypothesis when <m>H_0</m>
            is actually true. This is a false positive.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-type-2-error">
        <title>Type 2 Error</title>
        <statement>
          <p>
            A <term>Type 2 Error</term> is failing to reject the null hypothesis when the
            alternative hypothesis is actually true. This is a false negative.
          </p>
        </statement>
      </definition>
      
      <table xml:id="table-decision-errors">
        <title>Four possible outcomes in hypothesis testing</title>
        <tabular>
          <row header="yes">
            <cell></cell>
            <cell><m>H_0</m> is true</cell>
            <cell><m>H_A</m> is true</cell>
          </row>
          <row>
            <cell>Reject <m>H_0</m></cell>
            <cell>Type 1 Error</cell>
            <cell>Correct Decision</cell>
          </row>
          <row>
            <cell>Do not reject <m>H_0</m></cell>
            <cell>Correct Decision</cell>
            <cell>Type 2 Error</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        If we reduce how often we make one type of error, we generally make more of the
        other type. The balance is controlled by the significance level.
      </p>
      
      <definition xml:id="def-significance-level">
        <title>Significance Level</title>
        <statement>
          <p>
            The <term>significance level</term> <m>\alpha</m> indicates how often we
            incorrectly reject <m>H_0</m> when it is true. The traditional significance
            level is <m>\alpha = 0.05</m>.
          </p>
        </statement>
      </definition>
    </subsection>
    
    <subsection xml:id="subsec-p-values">
      <title>Formal Testing Using P-values</title>
      
      <definition xml:id="def-p-value">
        <title>P-value</title>
        <statement>
          <p>
            The <term>p-value</term> is the probability of observing data at least as
            favorable to the alternative hypothesis as our current data set, if the null
            hypothesis were true. We typically use a summary statistic of the data, such
            as the sample proportion, to help compute the p-value.
          </p>
        </statement>
      </definition>
      
      <p>
        When evaluating hypotheses for proportions using the p-value method, we use the
        null value <m>p_0</m> (not <m>\hat{p}</m>) when checking the success-failure
        condition and computing the standard error:
      </p>
      
      <me>SE_{\hat{p}} = \sqrt{\frac{p_0(1-p_0)}{n}}</me>
      
      <important>
        <p>
          When using the p-value method to evaluate a hypothesis test, check the
          success-failure condition using the null value <m>p_0</m> instead of using
          the sample proportion. We're supposing the null hypothesis is true, which is
          different from the confidence interval approach.
        </p>
      </important>
      
      <p>
        To compute a p-value:
      </p>
      
      <ol>
        <li>Calculate the Z-score (standardized test statistic):
            <me>Z = \frac{\hat{p} - p_0}{SE_{\hat{p}}}</me></li>
        <li>Find the probability of observing a Z-score at least as extreme as the
            one calculated, using the standard normal distribution.</li>
        <li>For a two-sided test, double the tail probability.</li>
      </ol>
      
      <example xml:id="ex-coal-p-value">
        <title>P-value for coal energy test</title>
        <statement>
          <p>
            Using the coal energy data (<m>\hat{p} = 0.37</m>, <m>n = 1000</m>), compute
            the p-value for testing <m>H_0: p = 0.5</m> versus <m>H_A: p \neq 0.5</m>.
          </p>
        </statement>
        <solution>
          <p>
            First, check conditions using <m>p_0 = 0.5</m>:
            <md>
              <mrow>np_0 \amp= 1000 \times 0.5 = 500 \geq 10 \checkmark</mrow>
              <mrow>n(1-p_0) \amp= 1000 \times 0.5 = 500 \geq 10 \checkmark</mrow>
            </md>
          </p>
          <p>
            Calculate the standard error using <m>p_0</m>:
            <me>SE = \sqrt{\frac{0.5 \times 0.5}{1000}} = 0.0158</me>
          </p>
          <p>
            Compute the Z-score:
            <me>Z = \frac{0.37 - 0.5}{0.0158} = -8.23</me>
          </p>
          <p>
            This is an extremely large Z-score in magnitude. The probability of observing
            a Z-score this extreme (in either tail) is essentially 0. Therefore,
            <m>p\text{-value} &lt; 0.0001</m>.
          </p>
          <p>
            Since the p-value is much less than 0.05, we reject <m>H_0</m>. We have
            extremely strong evidence that a majority of American adults oppose expanding
            coal energy production.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-nuclear-arms-reduction">
        <title>Nuclear arms reduction support</title>
        <statement>
          <p>
            A Gallup poll conducted in March 2013 found that 56% of a simple random
            sample of 1,028 US adults supported nuclear arms reduction. Does this
            provide convincing evidence that a majority of Americans supported nuclear
            arms reduction at the 5% significance level?
          </p>
        </statement>
        <solution>
          <p>
            Set up hypotheses. We want to test whether a majority (more than 50%)
            support nuclear arms reduction:
            <md>
              <mrow>H_0: \amp\  p = 0.50 \quad \text{(no majority)}</mrow>
              <mrow>H_A: \amp\  p \neq 0.50 \quad \text{(there is a majority)}</mrow>
            </md>
          </p>
          <p>
            <strong>Check conditions:</strong>
          </p>
          <ul>
            <li><strong>Independence:</strong> The poll was a simple random sample,
                so observations are independent.</li>
            <li><strong>Success-failure:</strong> Using the null proportion <m>p_0 = 0.5</m>:
                <m>np_0 = n(1-p_0) = 1028 \times 0.5 = 514 \geq 10</m>. <m>\checkmark</m></li>
          </ul>
          <p>
            <strong>Calculate:</strong> Compute the standard error using <m>p_0 = 0.5</m>:
            <me>SE = \sqrt{\frac{0.5 \times 0.5}{1028}} = 0.0156</me>
          </p>
          <p>
            Calculate the test statistic:
            <me>Z = \frac{0.56 - 0.50}{0.0156} = 3.85</me>
          </p>
          <p>
            For this two-sided test, we need to find the probability in both tails.
            A Z-score of 3.85 is extremely large. Looking at a standard normal table,
            the upper tail area is approximately 0.0001. Doubling this for the two-sided
            test: <m>p\text{-value} = 2 \times 0.0001 = 0.0002</m>.
          </p>
          <p>
            <strong>Conclude:</strong> Since <m>p\text{-value} = 0.0002 &lt; 0.05</m>,
            we reject <m>H_0</m>. The poll provides convincing evidence that a majority
            of Americans supported nuclear arms reduction efforts in March 2013.
          </p>
        </solution>
      </example>
      
      <figure xml:id="fig-nuclear-arms-p-value">
        <caption>The sampling distribution centered at the null value <m>p_0 = 0.5</m> for the nuclear arms test. The tails beyond the observed proportion show the p-value.</caption>
        <image source="images/ch_foundations_for_inf/figures/nuclearArmsReduction/nuclearArmsReductionPValue.pdf" width="70%">
          <description>Normal distribution centered at 0.5 showing tail areas for nuclear arms test</description>
        </image>
      </figure>
      
      <figure xml:id="fig-coal-p-value">
        <caption>The p-value for the coal energy test, shown as the tail areas beyond the observed Z-score.</caption>
        <image source="images/ch_foundations_for_inf/figures/normal_dist_mean_500_se_016/normal_dist_mean_500_se_016.pdf" width="70%">
          <description>Normal distribution showing extremely small tail areas for coal test</description>
        </image>
      </figure>
      
      <assemblage xml:id="ht-procedure">
        <title>Four-step hypothesis test procedure</title>
        <ol>
          <li><strong>Prepare:</strong> Identify the parameter of interest, list
              hypotheses, identify the significance level, and identify <m>\hat{p}</m>
              and <m>n</m>.</li>
          <li><strong>Check:</strong> Verify conditions to ensure <m>\hat{p}</m> is
              nearly normal under <m>H_0</m>. For one-proportion hypothesis tests, use
              the null value to check the success-failure condition.</li>
          <li><strong>Calculate:</strong> If the conditions hold, compute the standard
              error using <m>p_0</m>, compute the Z-score, and identify the p-value.</li>
          <li><strong>Conclude:</strong> Evaluate the hypothesis test by comparing the
              p-value to <m>\alpha</m>, and provide a conclusion in the context of the
              problem.</li>
        </ol>
      </assemblage>
      
      <p>
        Decision rule:
      </p>
      
      <ul>
        <li>If <m>p\text{-value} &lt; \alpha</m>, reject <m>H_0</m> and conclude there
            is strong evidence for <m>H_A</m>.</li>
        <li>If <m>p\text{-value} \geq \alpha</m>, do not reject <m>H_0</m> and conclude
            there is insufficient evidence for <m>H_A</m>.</li>
      </ul>
    </subsection>
    
    <subsection xml:id="subsec-significance-level">
      <title>Choosing a Significance Level</title>
      
      <p>
        Choosing a significance level for a test is important in many contexts. The
        traditional level is <m>\alpha = 0.05</m>, but it can be helpful to adjust the
        significance level based on the application:
      </p>
      
      <ul>
        <li>If making a Type 1 Error is dangerous or especially costly, choose a small
            significance level (e.g., 0.01).</li>
        <li>If a Type 2 Error is relatively more dangerous or costly, choose a higher
            significance level (e.g., 0.10).</li>
      </ul>
      
      <p>
        For medical testing, we might use <m>\alpha = 0.01</m> to reduce false positives.
        For preliminary screening, we might use <m>\alpha = 0.10</m> to catch more
        potential cases.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-one-sided-tests">
      <title>One-Sided Hypothesis Tests (Special Topic)</title>

      <p>
        So far we've only considered what are called <term>two-sided hypothesis
        tests</term>, where we care about detecting whether <m>p</m> is either above or
        below some null value <m>p_0</m>. There is a second type of hypothesis test
        called a <term>one-sided hypothesis test</term>.
      </p>

      <p>
        For a one-sided hypothesis test, the hypotheses take one of the following forms:
      </p>

      <ol>
        <li>There's only value in detecting if the population parameter is
            <em>less than</em> some value <m>p_0</m>. In this case, the alternative
            hypothesis is written as <m>p &lt; p_0</m> for some null value <m>p_0</m>.</li>
        <li>There's only value in detecting if the population parameter is
            <em>more than</em> some value <m>p_0</m>: In this case, the alternative
            hypothesis is written as <m>p &gt; p_0</m>.</li>
      </ol>

      <p>
        While we adjust the form of the alternative hypothesis, we continue to write the
        null hypothesis using an equals-sign in the one-sided hypothesis test case.
      </p>

      <p>
        In the entire hypothesis testing procedure, there is only one difference in
        evaluating a one-sided hypothesis test vs a two-sided hypothesis test: how to
        compute the p-value. In a one-sided hypothesis test, we compute the p-value as
        the tail area in the <em>direction of the alternative hypothesis only</em>,
        meaning it is represented by a single tail area. Herein lies the reason why
        one-sided tests are sometimes interesting: if we don't have to double the tail
        area to get the p-value, then the p-value is smaller and the level of evidence
        required to identify an interesting finding in the direction of the alternative
        hypothesis goes down. However, one-sided tests aren't all sunshine and rainbows:
        the heavy price paid is that any interesting findings in the opposite direction
        must be disregarded.
      </p>

      <example xml:id="ex-stents-two-sided-important">
        <statement>
          <p>
            In Section <xref ref="subsec-ht-framework"/>, we encountered an example where
            doctors were interested in determining whether stents would help people who
            had a high risk of stroke. The researchers believed the stents would help.
            Unfortunately, the data showed the opposite: patients who received stents
            actually did worse. Why was using a two-sided test so important in this
            context?
          </p>
        </statement>
        <solution>
          <p>
            Before the study, researchers had reason to believe that stents would help
            patients since existing research suggested stents helped in patients with
            heart attacks. It would surely have been tempting to use a one-sided test in
            this situation, and had they done this, they would have limited their ability
            to identify potential harm to patients.
          </p>
        </solution>
      </example>

      <p>
        This example highlights that using a one-sided hypothesis creates a risk of
        overlooking data supporting the opposite conclusion. We could have made a similar
        error when reviewing the Roslings' question data in this section; if we had a
        pre-conceived notion that college-educated people wouldn't do worse than random
        guessing and so used a one-sided test, we would have missed the really
        interesting finding that many people have incorrect knowledge about global public
        health.
      </p>

      <p>
        When might a one-sided test be appropriate to use? <em>Very rarely.</em> Should
        you ever find yourself considering using a one-sided test, carefully answer the
        following question:
      </p>

      <blockquote>
        <p>
          <em>What would I, or others, conclude if the data happens to go clearly in the
          opposite direction than my alternative hypothesis?</em>
        </p>
      </blockquote>

      <p>
        If you or others would find any value in making a conclusion about the data that
        goes in the opposite direction of a one-sided test, then a two-sided hypothesis
        test should actually be used. These considerations can be subtle, so exercise
        caution. We will only apply two-sided tests in the rest of this book.
      </p>

      <example xml:id="ex-why-not-choose-direction-after">
        <statement>
          <p>
            Why can't we simply run a one-sided test that goes in the direction of the
            data?
          </p>
        </statement>
        <solution>
          <p>
            We've been building a careful framework that controls for the Type 1 Error,
            which is the significance level <m>\alpha</m> in a hypothesis test. We'll use
            the <m>\alpha = 0.05</m> below to keep things simple.
          </p>
          <p>
            Imagine we could pick the one-sided test after we saw the data. What will go
            wrong?
          </p>
          <ul>
            <li>If <m>\hat{p}</m> is <em>smaller</em> than the null value, then a
                one-sided test where <m>p &lt; p_0</m> would mean that any observation in
                the <em>lower</em> 5% tail of the null distribution would lead to us
                rejecting <m>H_0</m>.</li>
            <li>If <m>\hat{p}</m> is <em>larger</em> than the null value, then a
                one-sided test where <m>p &gt; p_0</m> would mean that any observation in
                the <em>upper</em> 5% tail of the null distribution would lead to us
                rejecting <m>H_0</m>.</li>
          </ul>
          <p>
            Then if <m>H_0</m> were true, there's a 10% chance of being in one of the two
            tails, so our testing error is actually <m>\alpha = 0.10</m>, not 0.05. That
            is, not being careful about when to use one-sided tests effectively
            undermines the methods we're working so hard to develop and utilize.
          </p>
        </solution>
      </example>

      <warning>
        <p>
          Use one-sided tests only when you have a strong reason to care about
          deviations in only one direction. If you're unsure, use a two-sided test.
        </p>
      </warning>
    </subsection>

    <subsection xml:id="subsec-statistical-vs-practical">
      <title>Statistical Significance versus Practical Significance</title>

      <p>
        When the sample size becomes larger, point estimates become more precise and any
        real differences in the mean and null value become easier to detect and
        recognize. Even a very small difference would likely be detected if we took a
        large enough sample. Sometimes researchers will take such large samples that even
        the slightest difference is detected, even differences where there is no
        practical value. In such cases, we still say the difference is
        <term>statistically significant</term>, but it is not <term>practically
        significant</term>.
      </p>

      <p>
        For example, an online experiment might identify that placing additional ads on a
        movie review website statistically significantly increases viewership of a TV
        show by 0.001%, but this increase might not have any practical value.
      </p>

      <p>
        One role of a data scientist in conducting a study often includes planning the
        size of the study. The data scientist might first consult experts or scientific
        literature to learn what would be the smallest meaningful difference from the
        null value. She also would obtain other information, such as a very rough
        estimate of the true proportion <m>p</m>, so that she could roughly estimate the
        standard error. From here, she can suggest a sample size that is sufficiently
        large that, if there is a real difference that is meaningful, we could detect it.
        While larger sample sizes may still be used, these calculations are especially
        helpful when considering costs or potential risks, such as possible health
        impacts to volunteers in a medical study.
      </p>
    </subsection>
    
    <exercises>
      <title>Section 5.3 Exercises</title>
      
      <exercise xml:id="ex-nuclear-arms">
        <statement>
          <p>
            A Gallup poll of 1,028 adults found that 56% favored a nuclear arms reduction
            treaty. Does this provide strong evidence that a majority of American adults
            favor such a treaty? Conduct a hypothesis test using <m>\alpha = 0.05</m>.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-type-errors-vaccine">
        <statement>
          <p>
            Consider a hypothesis test for whether a new vaccine is effective at reducing
            infection rates compared to a placebo. Describe what a Type 1 Error and a
            Type 2 Error would mean in this context, and discuss which might be more
            serious.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-identify-hypotheses-1">
        <statement>
          <p>
            Write the null and alternative hypotheses in words and then symbols for each
            of the following situations.
          </p>
          <ol>
            <li>A tutoring company would like to understand if most students tend to
                improve their grades (or not) after they use their services. They sample
                200 of the students who used their service in the past year and ask them
                if their grades have improved or declined from the previous year.</li>
            <li>Employers at a firm are worried about the effect of March Madness, a
                basketball championship held each spring in the US, on employee
                productivity. They estimate that on a regular business day employees
                spend on average 15 minutes of company time checking personal email,
                making personal phone calls, etc. They also collect data on how much
                company time employees spend on such non-business activities during March
                Madness. They want to determine if these data provide convincing evidence
                that employee productivity changed during March Madness.</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-identify-hypotheses-2">
        <statement>
          <p>
            Write the null and alternative hypotheses in words and using symbols for
            each of the following situations.
          </p>
          <ol>
            <li>Since 2008, chain restaurants in California have been required to
                display calorie counts of each menu item. Prior to menus displaying
                calorie counts, the average calorie intake of diners at a restaurant was
                1100 calories. After calorie counts started to be displayed on menus, a
                nutritionist collected data on the number of calories consumed at this
                restaurant from a random sample of diners. Do these data provide
                convincing evidence of a difference in the average calorie intake of
                diners at this restaurant?</li>
            <li>The state of Wisconsin would like to understand the fraction of its
                adult residents that consumed alcohol in the last year, specifically if
                the rate is different from the national rate of 70%. To help them answer
                this question, they conduct a random sample of 852 residents and ask them
                about their alcohol consumption.</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-online-communication">
        <statement>
          <p>
            A study suggests that 60% of college students spend 10 or more hours per week
            communicating with others online. You believe that this is incorrect and
            decide to collect your own sample for a hypothesis test. You randomly sample
            160 students from your dorm and find that 70% spent 10 or more hours a week
            communicating with others online. A friend of yours, who offers to help you
            with the hypothesis test, comes up with the following set of hypotheses.
            Indicate any errors you see.
          </p>
          <md>
            <mrow>H_0: \amp\ \hat{p} &lt; 0.6</mrow>
            <mrow>H_A: \amp\ \hat{p} &gt; 0.7</mrow>
          </md>
        </statement>
      </exercise>

      <exercise xml:id="ex-married-at-25">
        <statement>
          <p>
            A study suggests that 25% of 25 year olds have gotten married. You
            believe that this is incorrect and decide to collect your own sample for a
            hypothesis test. From a random sample of 25 year olds in census data with
            size 776, you find that 24% of them are married. A friend of yours offers to
            help you with setting up the hypothesis test and comes up with the following
            hypotheses. Indicate any errors you see.
          </p>
          <md>
            <mrow>H_0: \amp\ \hat{p} = 0.24</mrow>
            <mrow>H_A: \amp\ \hat{p} \neq 0.24</mrow>
          </md>
        </statement>
      </exercise>

      <exercise xml:id="ex-cyberbullying-rates">
        <statement>
          <p>
            Teens were surveyed about cyberbullying, and 54% to 64% reported
            experiencing cyberbullying (95% confidence interval). Answer the following
            questions based on this interval.
          </p>
          <ol>
            <li>A newspaper claims that a majority of teens have experienced
                cyberbullying. Is this claim supported by the confidence interval?
                Explain your reasoning.</li>
            <li>A researcher conjectured that 70% of teens have experienced
                cyberbullying. Is this claim supported by the confidence interval?
                Explain your reasoning.</li>
            <li>Without actually calculating the interval, determine if the claim of the
                researcher from part (b) would be supported based on a 90% confidence
                interval?</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-er-wait-ci-ht">
        <statement>
          <p>
            The ER wait time exercise provides a 95% confidence interval for the mean
            waiting time at an emergency room (ER) of (128 minutes, 147 minutes). Answer
            the following questions based on this interval.
          </p>
          <ol>
            <li>A local newspaper claims that the average waiting time at this ER
                exceeds 3 hours. Is this claim supported by the confidence interval?
                Explain your reasoning.</li>
            <li>The Dean of Medicine at this hospital claims the average wait time is
                2.2 hours. Is this claim supported by the confidence interval? Explain
                your reasoning.</li>
            <li>Without actually calculating the interval, determine if the claim of the
                Dean from part (b) would be supported based on a 99% confidence
                interval?</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-minimum-wage-1">
        <statement>
          <p>
            Do a majority of US adults believe raising the minimum wage will help the
            economy, or is there a majority who do not believe this? A Rasmussen Reports
            survey of a random sample of 1,000 US adults found that 42% believe it will
            help the economy. Conduct an appropriate hypothesis test to help answer the
            research question.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-getting-enough-sleep">
        <statement>
          <p>
            400 students were randomly sampled from a large university, and 289 said they
            did not get enough sleep. Conduct a hypothesis test to check whether this
            represents a statistically significant difference from 50%, and use a
            significance level of 0.01.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-working-backwards-1">
        <statement>
          <p>
            You are given the following hypotheses:
          </p>
          <md>
            <mrow>H_0: \amp\ p = 0.3</mrow>
            <mrow>H_A: \amp\ p \neq 0.3</mrow>
          </md>
          <p>
            We know the sample size is 90. For what sample proportion would the p-value
            be equal to 0.05? Assume that all conditions necessary for inference are
            satisfied.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-working-backwards-2">
        <statement>
          <p>
            You are given the following hypotheses:
          </p>
          <md>
            <mrow>H_0: \amp\ p = 0.9</mrow>
            <mrow>H_A: \amp\ p \neq 0.9</mrow>
          </md>
          <p>
            We know that the sample size is 1,429. For what sample proportion would the
            p-value be equal to 0.01? Assume that all conditions necessary for inference
            are satisfied.
          </p>
        </statement>
      </exercise>

      <exercise xml:id="ex-testing-fibromyalgia">
        <statement>
          <p>
            A patient named Diana was diagnosed with Fibromyalgia, a long-term syndrome
            of body pain, and was prescribed anti-depressants. Being the skeptic that she
            is, Diana didn't initially believe that anti-depressants would help her
            symptoms. However after a couple months of being on the medication she
            decides that the anti-depressants are working, because she feels like her
            symptoms are in fact getting better.
          </p>
          <ol>
            <li>Write the hypotheses in words for Diana's skeptical position when she
                started taking the anti-depressants.</li>
            <li>What is a Type 1 Error in this context?</li>
            <li>What is a Type 2 Error in this context?</li>
          </ol>
        </statement>
      </exercise>

      <exercise xml:id="ex-which-is-higher">
        <statement>
          <p>
            In each part below, there is a value of interest and two scenarios (I and
            II). For each part, report if the value of interest is larger under scenario
            I, scenario II, or whether the value is equal under the scenarios.
          </p>
          <ol>
            <li>The standard error of <m>\hat{p}</m> when (I) <m>n = 125</m> or
                (II) <m>n = 500</m>.</li>
            <li>The margin of error of a confidence interval when the confidence level is
                (I) 90% or (II) 80%.</li>
            <li>The p-value for a Z-statistic of 2.5 calculated based on a (I) sample
                with <m>n = 500</m> or based on a (II) sample with <m>n = 1000</m>.</li>
            <li>The probability of making a Type 2 Error when the alternative hypothesis
                is true and the significance level is (I) 0.05 or (II) 0.10.</li>
          </ol>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 5.4: Chapter 5 review exercises -->
  <section xml:id="sec-ch05-review">
    <title>Chapter 5 Review Exercises</title>
    
    <p>
      This chapter introduced the foundational concepts of statistical inference:
    </p>
    
    <ul>
      <li><strong>Point estimates</strong> provide single best guesses for population
          parameters, but come with sampling error.</li>
      <li><strong>Confidence intervals</strong> provide a range of plausible values for
          parameters, accounting for sampling variability.</li>
      <li><strong>Hypothesis tests</strong> allow us to formally evaluate claims about
          population parameters using sample data.</li>
    </ul>
    
    <p>
      These methods all rely on the Central Limit Theorem, which tells us that sample
      proportions follow an approximately normal distribution when certain conditions
      are met. The same framework extends to other parameters beyond proportions.
    </p>
    
    <exercises>
      <title>Review Exercises</title>
      
      <exercise>
        <statement>
          <p>
            A university wants to estimate the proportion of its students who are
            satisfied with campus dining options. A random sample of 500 students
            finds that 340 are satisfied.
          </p>
          <ol>
            <li>Calculate a 90% confidence interval for the true proportion of
                satisfied students.</li>
            <li>Interpret this interval in context.</li>
            <li>Would a 95% confidence interval be wider or narrower? Why?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise>
        <statement>
          <p>
            A political candidate claims that more than 60% of voters in a district
            support her platform. A poll of 400 randomly selected voters finds that
            252 support her platform.
          </p>
          <ol>
            <li>Set up appropriate hypotheses to test the candidate's claim.</li>
            <li>Calculate the p-value for this test.</li>
            <li>What conclusion would you draw at the <m>\alpha = 0.05</m> level?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise>
        <statement>
          <p>
            Explain the difference between a confidence interval and a hypothesis test.
            When would you use each method?
          </p>
        </statement>
      </exercise>
      
      <exercise>
        <statement>
          <p>
            A researcher wants to estimate a population proportion with a margin of
            error no larger than 3% at the 95% confidence level. What sample size
            is required? (Hint: Use <m>\hat{p} = 0.5</m> for the most conservative
            estimate.)
          </p>
        </statement>
      </exercise>
    </exercises>
  </section>
</chapter>
